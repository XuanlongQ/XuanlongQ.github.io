{"meta":{"title":"XuanLong's Blog","subtitle":"校屌我弱，毕业艰辛，回家种地","description":"于我而言，社交生活不是必须的","author":"XuanLong","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"在Ubuntu14.04下搭建NS-2.34","slug":"run_ns_2.34_ubuntu_14.04","date":"2017-12-22T08:44:47.601Z","updated":"2017-12-22T11:54:10.426Z","comments":true,"path":"2017/12/22/run_ns_2.34_ubuntu_14.04/","link":"","permalink":"http://yoursite.com/2017/12/22/run_ns_2.34_ubuntu_14.04/","excerpt":"","text":"因为pFrabic是在ns2.34上实现的，所以会出现包的回退。所以写一下搭建的过程。 ubuntu14.04 不要update！不要update！不要update！ 1.首先去下载ns-2.34. 2.安装前配置环境123$sudo apt-get install build－essential$sudo apt-get install tcl8.4 tcl8.4-dev tk8.4 tk8.4-dev$sduo apt-get install libxmu-dev libxmu-headers 3.在终端进行解压123$tar xvfz ns-allinone-2.34.tar.gz$cd /ns-allinone-2.34$./install 4.由于ns-2.34会出现报错，按以下逐次解决 problem statement(1) otcl.o：在函数‘Otcl_Init’中：/home/xuanlong/ns-allinone-2.34/otcl-1.13/otcl.c:2284：对‘stack_chk_fail_local’未定义的引用ld: libotcl.so: hidden symbol `stack_chk_fail_local’ isn’t definedld: 最终连接失败: 错误的值make: * [libotcl.so] 错误 1otcl-1.13 make failed! Exiting … 修改： 在终端输入以下命令12$ cd otcl-1.13 $ sudo gedit configure.in 把77行的SHLIB_LD=”ld -shared”，改为SHLIB_LD=”gcc -shared”，保存退出。 然后 $ sudo gedit configure 在键盘按Ctrl+F，输入SHLIB_LD=”ld -shared”，点击查找，在6300行找到SHLIB_LD=”ld - shared”，改为SHLIB_LD=”gcc -shared”,保存退出。 (2)tools/ranvar.cc: In member function ‘virtual double GammaRandomVariable::value()’:tools/ranvar.cc:219:70: error: cannot call constructor ‘GammaRandomVariable::GammaRandomVariable’ directly [-fpermissive] return GammaRandomVariable::GammaRandomVariable(1.0 + alpha, beta).value() pow (u, 1.0 / alpha_); ^tools/ranvar.cc:219:70: error: for a function-style cast, remove the redundant ‘::GammaRandomVariable’ [-fpermissive]make: ** [tools/ranvar.o] 错误 1Ns make failed! 解决：这是由于gcc版本提高后对类内部函数调用的简化造成的不兼容，解决方法如下： 在ns-allinone-2.34/ns-2.34/tools文件夹下，找到报错提示中的ranvar.cc文件，打开找到对应的219行删除::GaammaRandomVariable，保存， 即：将219行的 return GammaRandomVariable::GammaRandomVariable(1.0 + alpha,beta).value() * pow (u, 1.0 / alpha_); 改为： return GammaRandomVariable(1.0 + alpha, beta).value() * pow(u, 1.0 / alpha_); 然后保存退出，重新安装ns2. (3)In file included from mac/mac-802_11Ext.cc:66:0:mac/mac-802_11Ext.h: In member function ‘u_int32_t PHY_MIBExt::getHdrLen11()’:mac/mac-802_11Ext.h:175:19: error: expected primary-expression before ‘struct’ return(offsetof(struct hdr_mac802_11, dh_body[0]) ^mac/mac-802_11Ext.h:175:41: error: ‘dh_body’ was not declared in this scope return(offsetof(struct hdr_mac802_11, dh_body[0]) ^mac/mac-802_11Ext.h:175:51: error: ‘offsetof’ was not declared in this scope return(offsetof(struct hdr_mac802_11, dh_body[0]) ^mac/mac-802_11Ext.h:177:3: warning: control reaches end of non-void function [-Wreturn-type] } ^make: * [mac/mac-802_11Ext.o] 错误 1Ns make failed! 解决：下面是网上找得关于本问题的解决方案： If you get error like: mac/mac-802_11Ext.h: In member function ‘u_int32_tPHY_MIBExt::getHdrLen11()’:mac/mac-802_11Ext.h:176:19: error: expected primary-expressionbefore ‘struct’mac/mac-802_11Ext.h:176:41: error: ‘dh_body’ was not declared inthis scopemac/mac-802_11Ext.h:176:51: error: ‘offsetof’ was not declared inthis scope open that file and add 1$ #include &lt;cstddef&gt; //只要添加这个头文件就行 to the header files.在ns-allinone-2.34\\ns-2.34\\mac\\mac-802_11Ext.h文件添加#include然后重新安装，就OK了。 (4)mobile/nakagami.cc:183:73: error: for a function-style cast, remove the redundant ‘::ErlangRandomVariable’ [-fpermissive]mobile/nakagami.cc:185:67: error: cannot call constructor ‘GammaRandomVariable::GammaRandomVariable’ directly [-fpermissive] resultPower = GammaRandomVariable::GammaRandomVariable(m, Pr/m).value(); ^mobile/nakagami.cc:185:67: error: for a function-style cast, remove the redundant ‘::GammaRandomVariable’ [-fpermissive]make: * [mobile/nakagami.o] 错误 1Ns make failed! 解决： 在ns-allinone-2.34/ ns-2.34/mobile文件夹下，找到报错提示中的nakagami.cc文件，打开找到对应的183行删除::ErlangRandomVariable，保存， 即：将183行的 resultPower = ErlangRandomVariable::ErlangRandomVariable(Pr/m,int_m).value(); 改为： resultPower = ErlangRandomVariable(Pr/m, int_m).value(); 在ns-allinone-2.34/ ns-2.34/mobile文件夹下，找到报错提示中的nakagami.cc文件，打开找到对应的185行删除::GammaRandomVariable，保存， 即：将185行的 resultPower = GammaRandomVariable::GammaRandomVariable(m,Pr/m).value(); 改为： resultPower = GammaRandomVariable(m, Pr/m).value(); 重新在ns目录下键入$./install安装，再次出现同类问题时，仿照此次解决方法，找到对应的文件和行数，修改即可。直到安装成功。 (5)linkstate/ls.cc:396:28: required from herelinkstate/ls.h:137:58: error: ‘erase’ was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive] void eraseAll() { erase(baseMap::begin(), baseMap::end()); } ^linkstate/ls.h:137:58: note: declarations in dependent base ‘std::map","categories":[],"tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"}]},{"title":"FCT的调研文章总结","slug":"FCT","date":"2017-12-20T14:46:08.164Z","updated":"2017-12-20T14:46:11.140Z","comments":true,"path":"2017/12/20/FCT/","link":"","permalink":"http://yoursite.com/2017/12/20/FCT/","excerpt":"","text":"文章基本上都出自SIGCOMM、NSDI等系列的文章里面 文章1.M. Al-Fares, S. Radhakrishnan, B. Raghavan, N. Huang, and A. Vahdat. Hedera: dynamic flow scheduling for data center networks. In Proc. of NSDI, 2010. 这篇在专栏里说过很多次了，可以说是开山之作，（探测大流、估计流需求、调度） 2.M. Alizadeh, A. Greenberg, D. A. Maltz, J. Padhye, P. Patel, B. Prabhakar, S. Sengupta, and M. Sridharan. Data center TCP (DCTCP). In Proc. of SIGCOMM, 2010. 这篇主要通过ECN标记来调控拥塞 3.M. Alizadeh, A. Kabbani, T. Edsall, B. Prabhakar, A. Vahdat, and M. Yasuda. Less is more: trading a little bandwidth for ultra-low latency in the data center. In Proc. of NSDI, 2012. 这篇讲述短流优先级提升整个流性能，做法集合了DCTCP、PQ、Packet Pacing(Hardware pace) 4.M. Alizadeh, S. Yang, M. Sharif, S. Katti, N. McKeown, B. Prabhakar, and S. Shenker. pFabric: Minimal Near-Optimal Datacenter Transport In Proc. of SIGCOMM, 2013. 这篇主要是在选择端口时不让他产生拥塞，在黑盒内部使用的是贪心算法 5.C.-Y. Hong, M. Caesar, and P. B. Godfrey. Finishing Flows Quickly with Preemptive Scheduling. In Proc. of SIGCOMM, 2012. 这篇就是论文中常见的PDQ机制，但是对于短流而言一定要回传SYN和FIN是否会影响性能要做不同场景不同的判断 6.C. Raiciu, S. Barre, C. Pluntke, A. Greenhalgh, D. Wischik, and M. Handley. Improving datacenter performance and robustness with multipath TCP. In Proc. of the SIGCOMM, 2011. 这篇是MPTCP的优化 7.B. Vamanan, J. Hasan, and T. N. Vijaykumar. Deadline-Aware Datacenter TCP(D2TCP). In Proc. of SIGCOMM, 2012 Meet deadline不是很少见，主要是和DCTCP结合起来 8.V. Vasudevan, A. Phanishayee, H. Shah, E. Krevat, D. G. Andersen, G. R. Ganger, G. A. Gibson, and B. Mueller. Safe and effective fine-grained TCP transmissions for datacenter communication. In Proc. of SIGCOMM, 2009. 这篇我记得主要是讲算法的？（时间太久远了）但是当时看了很久，也是很经典的细粒度流控文章，可以看看。 C. Wilson, H. Ballani, T. Karagiannis, and A. Rowtron. Better never than late: meeting deadlines in datacenter networks. In Proc. of SIGCOMM, 2011. 首次完整的论证了短流的重要性 10.D. Zats, T. Das, P. Mohan, D. Borthakur, and R. H. Katz. DeTail: Reducing the Flow Completion Time Tail in Datacenter Networks. In Proc. of SIGCOMM, 2012. Detail本身是比较难以重复的，他在整个架构的每一个部分都有优化 总结关于短流比较火的时候就在10-12这段时间，疯狂占据NSDI和SIGCOMM，但是很少有人接着做下去的,比如Less is more 后面就没有后续的工作了，单纯的从流量调度想去创新太难了，还是要结合实际场景。 Resource1.ACM Digital Library.2.IEEE Xplore Digital Library.","categories":[],"tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"}]},{"title":"收录下看到的不错有干货的Blog","slug":"interesting blog","date":"2017-10-29T08:57:57.327Z","updated":"2017-12-22T08:44:02.368Z","comments":true,"path":"2017/10/29/interesting blog/","link":"","permalink":"http://yoursite.com/2017/10/29/interesting blog/","excerpt":"","text":"看到几篇不错的TCP数据传输的博文，记录一下。侵权作者可以给我发邮件，我只贴链接。1.TCP 的那些事儿（上）.作者：陈皓2.TCP 的那些事儿（下）.这两篇文章入门挺好但是要想详细了解还是要从TCP/IP 协议这本书开始，然后看看论文。 3.学习sFlow–陈沙克日志.作者：陈沙克貌似也是和李呈混SDNAP的，sFlow本身的网络流量监管性能很卓越，但是需要openswitch的支持，NS-3支持sFlow. 4.NS-2教学手册.作者：柯志亨这个已经很全了，(国立)金门大学柯志亨自己搞的。 5.Ubuntu14.04+ns2.34.这个搭配会出现包不匹配情况，按照这个修正我跑通了，我们常见的是14.04+ns2.35除了会出现/linkstate/ls.h的erase问题，其余都是正常的。 6.在Ubuntu 14.04 64bit上安装numpy和matplotlib库.这个搭配也是跑通的。","categories":[],"tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"}]},{"title":"NumPy基础：数组和矢量计算","slug":"numpy_basic","date":"2017-10-26T13:21:48.506Z","updated":"2017-10-27T07:49:25.421Z","comments":true,"path":"2017/10/26/numpy_basic/","link":"","permalink":"http://yoursite.com/2017/10/26/numpy_basic/","excerpt":"","text":"NumPy(Numerical Python的简称)是高性能科学技术和数据分析的基础包。对于大部分数据分析应用而言，主要关注的功能在： 对于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算 常用的数组算法，如排序，唯一化，集合运算等 高效的描述统计和数据聚合/摘要运算 对于异构数据集的合并/连接运算的数据对齐和关系型数据运算 将条件逻辑表述为数组表达式(而不是带有if-elif-else分支的循环) 数据的分组运算(聚合、转换、函数应用) NumPy的ndarray:一种多维数组对象","categories":[],"tags":[{"name":"Bigdata","slug":"Bigdata","permalink":"http://yoursite.com/tags/Bigdata/"}]},{"title":"Introducation- What is Machine Learning?","slug":"Introduction","date":"2017-10-22T05:09:17.552Z","updated":"2017-10-22T05:46:00.975Z","comments":true,"path":"2017/10/22/Introduction/","link":"","permalink":"http://yoursite.com/2017/10/22/Introduction/","excerpt":"","text":"What is Machine Learning?Two definitions of Machine Learning are offered. Arthur Samuel described it as: “the field of study that gives computers the ability to learn without being explicitly programmed.” This is an older, informal definition. Tom Mitchell provides a more modern definition: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.” Example: playing checkers. E = the experience of playing many games of checkers T = the task of playing checkers. P = the probability that the program will win the next game. In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning and Unsupervised learning. Supervised LearningIn supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output. Supervised learning problems are categorized into “regression” and “classification” problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories. Example 1: Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output, so this is a regression problem. We could turn this example into a classification problem by instead making our output about whether the house “sells for more or less than the asking price.” Here we are classifying the houses based on price into two discrete categories.(a) Regression - Given a picture of a person, we have to predict their age on the basis of the given picture (b) Classification - Given a patient with a tumor, we have to predict whether the tumor is malignant or benign. 假设你想预测房价（无比需要啊！）， 之前某学生已经从某地收集了数据集（不是中国的，囧）其中一个数据集是这样的。这是横坐标，即不同房子的面积，单位平方脚（^-^）纵轴上是房价，单位千美元。根据给定数据，假设你朋友有栋房子，750平尺（70平米）想知道这房子能卖多少，好卖掉。那么学习算法怎么帮你呢？学习算法可以：绘出一条直线，让直线尽可能匹配到所有数据。 基于此看上去，那个房子应该、可能、也许、大概卖到15万美元（一平米两千刀！）。但这不是唯一的学习算法。可能还有更好的。比如不用直线了，可能平方函数会更好， 即二次多项式更符合数据集。如果你这样做，预测结果就应该是20万刀（一平三千刀，涨价好快）。后面我们会介绍到如何选择是选择直线还是平方函数来拟合。没有明确的选择，就不知哪个能给你的朋友更好的卖房建议。只是这些每个都是很好的学习算法例子。也是监督学习的例子。术语监督学习，意指给出一个算法，需要部分数据集已经有正确答案。比如给定房价数据集，对于里面每个数据，算法都知道对应的正确房价，即这房子实际卖出的价格。算法的结果就是 算出更多的正确价格，比如那个新房子， 你朋友想卖的那个。用更术语的方式来定义，监督学习又叫回归问题（应该是回归属于监督中的一种）意指要预测一个连续值的输出，比如房价。 虽然从技术上，一般把房价记到美分单位。所以实际还是个离散值，但通常把它看作实际数字，是一个标量值，一个连续值的数，而术语回归，意味着要预测这类连续值属性的种类。 另一个监督学习的例子，我和一些朋友之前研究的领域。让我们来看医学记录，并预测胸部肿瘤是恶性良性。如果某人发现有胸部肿瘤，恶性肿瘤有害又危险,良性肿瘤则是少害。显然人们很关注这个。让我们看一个收集好的数据集，假设在数据集中，横轴表示肿瘤的大小，纵轴我打算圈上0或1，是或否，即肿瘤是恶性的还是良性的。所以如图所示，可以看到这个大小的肿瘤块是良性的，还有这些大小的都是良性的。不幸地是也看到一些恶性肿瘤，比如这些大小的肿瘤。所以，有5个良性块，在这一块，还有5个恶性的，它们纵轴值为1.现在假设某人杯具地得胸部肿瘤了，大小大概是这么大。对应的机器学习问题就是，你能否估算出一个概率，即肿瘤为恶或为良的概率？专业地说，这是个分类问题。 分类是要预测一个离散值输出。 这里是0或1，恶性或良性。事实证明，在分类问题中，有时会有超过两个的值，输出的值可能超过两种。举个具体例子，胸部肿瘤可能有三种类型，所以要预测离散值0，1，2，3.0就是良性肿瘤，没有癌症。 1 表示1号癌症，假设总共有三种癌症。 2 是2号癌症，3 就是3号癌症。这同样是个分类问题，因为它的输出的离散值集合分别对应于无癌，1号，2号，3号癌症我再露一小手，在分类问题中，还有另一种作图方式来描述数据。我画你猜。要用到些许不同的符号集合来描绘数据。如果肿瘤大小作为唯一属性，被用于预测恶性良性，可以把数据作图成这样。使用不同的符号来表示良性和恶性，即阴性和阳性。所以，不再统一画叉叉了，改用圈圈来代表良性肿瘤，就像这样。仍沿用X（叉叉）代表恶性肿瘤。希望你能明白。我所做的就是，把在上面的数据，映射下来。再用不同的符号，圈和叉来分别代表良性和恶性。 在上例中，只使用了一个特征属性，即肿瘤块大小，来预测肿瘤是恶性良性。在其它机器学习问题里，有着不只一个的特征和属性。例子，现在不只是知道肿瘤大小，病人年龄和肿瘤大小都知道了。这种情况下，数据集如表图所示，有些病人，年龄、肿瘤已知，不同的病人，会有一点不一样，肿瘤恶性，则用叉来代表。所以，假设有一朋友得了肿瘤。肿瘤大小和年龄落在此处。那么依据这个给定的数据集，学习算法所做的就是画一条直线，分开恶性肿瘤和良性肿瘤，所以学习算法会画条直线，像这样，把两类肿瘤分开。然后你就能判断你朋友的肿瘤是…了,如果它在那边，学习算法就说你朋友的肿瘤在良性一边，因此更可能是良性的。好，本例中，总共有两个特征，即病人年龄和肿瘤大小。在别的ML问题中，经常会用到更多特征，我朋友研究这个问题时，通常使用这些特征：比如块的厚度，即胸部肿瘤的厚度肿瘤细胞大小和形状的一致性， 等等。它表明，最有趣的学习算法（本课中将学到）能够处理，无穷多个特征。不是3到5个这么少。在这张幻灯片中，我已经列举了总共5个不同的特征。但对于一些学习问题，真要用到的不只是三五个特征，要用到无数多个特征，非常多的属性，所以，你的学习算法要使用很多的属性或特征、线索来进行预测。那么，你如何处理无限多特征呢？甚至你如何存储无数的东西进电脑里，又要避免内存不足？事实上，等我们介绍一种叫支持向量机的算法时， 就知道存在一个简洁的数学方法，能让电脑处理无限多的特征。想像下，我不是这边写两个特征， 右边写三个特征。而是，写一个无限长的特征表，不停地写特征，似乎是个无限长的特征的表。 但是，我们也有能力设计一个算法来处理这个问题。所以再从头复述一遍。本课中，我们介绍监督学习。其基本思想是，监督学习中，对于数据集中的每个数据，都有相应的正确答案，（训练集）算法就是基于这些来做出预测。就像那个房价，或肿瘤的性质。后面介绍了回归问题。 即通过回归来预测一个连续值输出。我们还谈到了分类问题，目标是预测离散值输出。 下面是个小测验题目： 假设你有家公司，希望研究相应的学习算法去解决两个问题。第一个问题，你有一堆货物的清单。假设一些货物有几千件可卖，你想预测出，你能在未来三个月卖出多少货物。第二个问题，你有很多用户，你打算写程序来检查每个用户的帐目。对每个用户的帐目， 判断这个帐目是否被黑过（hacked or compromised）。请问，这两个问题是分类问题，还是回归问题？当视频暂停时，请用你的鼠标进行选择，四选一，选择你认为正确的答案。 好，希望你刚才答对了。问题一是个回归问题因为如果我有几千件货物，可能只好把它当作一个实际的值，一个连续的值。也把卖出的数量当作连续值。第二个问题，则是分类问题，因为可以把我想预测的一个值设为0，来表示账目没有被hacked另一个设为1，表示已经被hacked。 就像乳癌例子中，0表示良性，1表示恶性。 所以这个值为0或1，取决于是否被hacked， 有算法能预测出是这两个离散值中的哪个。因为只有少量的离散值，所以这个就是个分类问题。 这就是监督学习. Unsupervised LearningUnsupervised Learning Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don’t necessarily know the effect of the variables. We can derive this structure by clustering the data based on relationships among the variables in the data. With unsupervised learning there is no feedback based on the prediction results. Example: Clustering: Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on. Non-clustering: The “Cocktail Party Algorithm”, allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party).在上一节视频中我们已经讲过监督学习回想起上次的数据集每个样本都已经被标明为 正样本或者负样本即良性或恶性肿瘤. 因此对于监督学习中的每一个样本我们已经被清楚地告知了什么是所谓的正确答案即它们是良性还是恶性在无监督学习中我们用的数据会和监督学习里的看起来有些不一样在无监督学习中没有属性或标签这一概念也就是说所有的数据都是一样的没有区别 所以在无监督学习中我们只有一个数据集没人告诉我们该怎么做我们也不知道每个数据点究竟是什么意思相反它只告诉我们现在有一个数据集你能在其中找到某种结构吗？对于给定的数据集无监督学习算法可能判定该数据集包含两个不同的聚类你看这是第一个聚类,然后这是另一个聚类. 无监督学习算法会把这些数据分成两个不同的聚类,所以这就是所谓的聚类算法实际上它被用在许多地方我们来举一个聚类算法的栗子 Google 新闻的例子如果你还没见过这个页面的话你可以到这个URL news.google.com 去看看谷歌新闻每天都在干什么呢？他们每天会去收集成千上万的网络上的新闻然后将他们分组组成一个个新闻专题,比如让我们来看看这里这里的URL链接连接着不同的有关BP油井事故的报道所以让我们点击这些URL中的一个恩让我们点一个然后我们会来到这样一个网页这是一篇来自华尔街日报的 有关……你懂的 有关BP油井泄漏事故的报道标题为《BP杀死了Macondo》 Macondo 是个地名 就是那个漏油事故的地方,如果你从这个组里点击一个不同的URL,那么你可能会得到不同的新闻 这里是一则CNN的新闻是一个有关BP石油泄漏的视频,如果你再点击第三个链接又会出现不同的新闻这边是英国卫报的报道也是关于BP石油泄漏,所以谷歌新闻所做的就是去搜索成千上万条新闻 然后自动的将他们聚合在一起 因此 有关同一主题的 新闻被显示在一起 实际上 聚类算法和无监督学习算法 也可以被用于许多其他的问题. 这里我们举个它在基因组学中的应用,下面是一个关于基因芯片的例子 基本的思想是 给定一组不同的个体 对于每个个体 检测它们是否拥有某个特定的基因 也就是说，你要去分析有多少基因显现出来了 因此 这些颜色 红 绿 灰 等等 它们 展示了这些不同的个体 是否拥有一个特定基因 的不同程度 然后你能做的就是 运行一个聚类算法 把不同的个体归入不同的类 或归为不同类型的人,这就是无监督学习 我们没有提前告知这个算法 这些是第一类的人 这些是第二类的人 这些是第三类的人等等 相反我们只是告诉算法 你看 这儿有一堆数据 我不知道这个数据是什么东东 我不知道里面都有些什么类型 叫什么名字 我甚至不知道都有哪些类型 但是 请问你可以自动的找到这些数据中的类型吗？ 然后自动的 按得到的类型把这些个体分类 虽然事先我并不知道哪些类型 因为对于这些数据样本来说 我们没有给算法一个 正确答案 所以 这就是无监督学习. 无监督学习或聚类算法在其他领域也有着大量的应用,它被用来组织大型的计算机集群.我有一些朋友在管理 大型数据中心 也就是 大型计算机集群 并试图 找出哪些机器趋向于 协同工作 如果你把这些机器放在一起你就可以让你的数据中心更高效地工作. 第二种应用是用于社交网络的分析,所以 如果可以得知 哪些朋友你用email联系的最多 或者知道你的Facebook好友 或者你Google+里的朋友 知道了这些之后 我们是否可以自动识别 哪些是很要好的朋友组 哪些仅仅是互相认识的朋友组. 还有在市场分割中的应用许多公司拥有庞大的客户信息数据库那么给你一个客户数据集你能否自动找出不同的市场分割,并自动将你的客户分到不同的 细分市场中 从而有助于我在 不同的细分市场中 进行更有效的销售 这也是无监督学习 我们现在有 这些客户数据 但我们预先并不知道 有哪些细分市场 而且 对于我们数据集的某个客户 我们也不能预先知道 谁属于细分市场一 谁又属于细分市场二等等 但我们必须让这个算法自己去从数据中发现这一切 我们谈到了无监督学习它是一种学习机制你给算法大量的数据要求它找出数据中蕴含的类型结构 以下的三个例子中 哪一个 您认为是 无监督学习算法 而不是监督学习问题 对于每一个选项 在左边的复选框 选中你认为 属于无监督学习的 选项 然后按一下右下角的按钮 提交你的答案 所以 当视频暂停时 请回答幻灯片上的这个问题 恩 没忘记垃圾邮件文件夹问题吧？ 如果你已经标记过数据 那么就有垃圾邮件和 非垃圾邮件的区别 我们会将此视为一个监督学习问题 新闻故事的例子 正是我们在本课中讲到的 谷歌新闻的例子 我们介绍了你可以如何使用 聚类算法这些文章聚合在一起 所以这是无监督学习问题 市场细分的例子 我之前有说过 这也是一个无监督学习问题 因为我是要 拿到数据 然后要求 它自动发现细分市场 Resource Machine Learning Andrew Ng. 复制转载，侵删！ 博主看到可联系我。","categories":[],"tags":[{"name":"Bigdata","slug":"Bigdata","permalink":"http://yoursite.com/tags/Bigdata/"}]},{"title":"网络基本介绍","slug":"network introduce","date":"2017-10-12T11:50:23.788Z","updated":"2017-10-29T09:01:15.215Z","comments":true,"path":"2017/10/12/network introduce/","link":"","permalink":"http://yoursite.com/2017/10/12/network introduce/","excerpt":"","text":"这个专题主要讲述数据传输方向，主要普及关于网络方向，主要的拥塞避免方向会写在我的知乎专栏上。 网络传输的基本单位： bps(bit per second). 1 Network EdgeEdge Network(边缘网路)是由一群主机(host)和应用组成，核心网络(Core Network)则是由一群路由器(Router)将网络链接起来。 1.1 Client-Server Computing(主从式运算)Client应用程序向Server要求服务，Server程序回应client并提供服务。(如：Web浏览器，Web Server) 1.2 Peer-to-Peer (P2P,点对点) ComputingPeer既是Client, 也是Server. (如: Skype, Bit Torrent)资料在edge的两端, 传输服务(Transport Srvice)可能是可靠的 (如: TCP/Transmission Control Protocol), 或不可靠的 (如: UDP/User Datagram Protocol). TCP服务提供：(1)顺序正确可靠的字节流(Byte-Stream)(2)流量控制(3)拥塞控制TCP服务要先建立连接. UDP服务是属于沒有记录状态(stateless)的不可靠服务.UDP服务比TCP更快，超载时将会无法处理的资料舍弃。 1.3 Access Network (接取网络)家庭:(1) Dialup Modem(拨号数据线,)-&gt;up to 56Kbps(2) ADSL(Asymmetric Digital Subscriber Line)-&gt;Upstream:up to 1Mbps;downstream:up to 8Mbps(3) HFC(Hybrid Fiber Coax)-&gt;Upstream:up to 2Mbps;downstream:up to 30Mbps 学校公司 : WiFi 无线网络: Wireless PAN/LAN/WAN 1.4 Physical Media (传输媒介)Twisted Pair (双绞线) : Catogory 5 UTP(100M/1Gbps ethernet) Coaxial cable (同轴电缆) Fiber Radio link :人造卫星 end-to-end delay 270ms. 1.5 网络拓扑 (topology)(1) 汇流排拓扑(bus topology)所有的Host都会连接到一条共用的线路(i.e.汇流排)，所有的信息都会延着共用线路传输，和汇流排所相连的所有节点都可以接受到信息。 (2) 星状拓扑(star topology) 主要是透过一个中央控制的节点(或是server)去连接所有的Host，Host之间沒有相连接。 (3) 环状拓扑(ring topology)每一台Host都会和另一台Host相连接，最后会形式一个环状的结构，且所要传送的信息是利用单方向的传送。 (4) 树状拓扑(tree topology)所有的Host连接的形式会成树状的结构，且任两个Host之间都只会有一条的传输路径。 (5) 网状拓扑(mesh topology)a. 完全连接网状拓扑：在网络系统中各个Host都会和所有的Host有相连接的路径。b. 不完全连接网状拓扑：在网络系统中各的Host不一定会和所有的Host有相连接的路径；也就是说，传送信息时，可能要先经过其他的Host才会到达目的地。 2 Network Core2.1 Circuit Switching把网络资源分成很多份，每个Call都有专属的连线，资源不共享，如果一个连线无人使用，则会闲置，不会分给其他人使用。Multiplexing (多工) 有2种方式 FDM vs. TDM FDM(Frequency-division multiplexing)：以frequency划分，每个使用者平均分配所有的frequency TDM(Time-division multiplexing)：以时间划分，时间內每个使用者享有所有的frequency 2.2 Packet Switching所有人的package共享所有网络资源会发生coongestion原因：packet在queue里面等待被使用. Packet switching的优点:处理bursty data的能力佳，共享网络资源，不必事先做call setup的动作。Packet switching的缺点:网络拥塞会造成packet delay和loss必须配合reliable data transfer和congestion control的机制。 2.3 Statistical Multiplexing不同于Circuit Switching事先分配好所有资源,依据需求來分配连结的使用,需要时频宽可分享。 2.4 Internet Service Provider (ISP)网际网络供应商,Points-of-Presence (POP):從一ISP連到其他ISP的点。 3 Packet-Switching 分析 (Delay, Loss, and Throughput)3.1 Delay in Packet-Switched NetworkStatistical Multiplexing(统计复用):依据需求来分配链接的使用，需要时频宽可分享。Store-and-Forwards:要接收到完整封包后才能把封包往外送。 3.2 Queuing Delay and Packet LossAverage queuing delay vs. Traffic Intensity (La/R)L : packet length (bit/packet)a : arrival rate (packet/sec)R : transmission rate, bandwidth (bit/sec, bps)La/R -&gt; 0 : average queueing delay smallLa/R -&gt; 1 : delays become large.La/R &gt; 1 : more “work” arriving than can be serviced, average delay infinite! packet loss:若output queue已满(也就是La/R 接近1时),则会出现封包丢失。 3.3 End-to-End Delaydnodal = dproc + dqueue + dtrans + dprop dproc = Processing delay : typically a few microsecs or less.dqueue = Queuing delay : depends on congestion.dtrans = Transmission delay : = L/R, significant for low-speed links.dprop = Propagation dalay : a few microsecs to hundreds of msecs. 路径种每个节点有以上四种延迟 Nodal processing delay:check bit errors 决定要送往何处的时间 Queueing delay:若封包要传出去的连结正在忙碌,在output queue等待的时间 Transmission delay:因store and forward而引起,等待接收到完整封包的时间 Propagation delay:把封包从link中传送到下一个router的时间 3.4 ThroughputThroughput = min{Ra,Rb,….Rn}就像是水管相连一樣,水流大小会取决于管子最细的那条。(ICMP就是这样)ex:5公分 和3公分水管接再一起,水流量为3公分水管的流量","categories":[],"tags":[{"name":"network","slug":"network","permalink":"http://yoursite.com/tags/network/"}]},{"title":"Ctex插图以及pseudo codes","slug":"Ctex_paper","date":"2017-10-11T12:48:39.966Z","updated":"2017-05-28T06:29:12.000Z","comments":true,"path":"2017/10/11/Ctex_paper/","link":"","permalink":"http://yoursite.com/2017/10/11/Ctex_paper/","excerpt":"","text":"插图使用 Baidu给出的都是重复搜索，基本上都是没什么卵用的。－ 1.首先插图不指定eps格式，不然latax未免太蠢了，网上的插入方式基本上都是要么直接用eps图片，要么把把jpg,png,jpeg通过一个ebb的指令来变成latex可执行文件，我查询了最近一般ctex这个傻逼功能早就没了，网上给出的ebb文件路径也不对。－ 2.正确打开方式如下：首先你需要安装一个full版的ctex功能比较全，然后你直接点击图片就会出现代码，但是这个代码上面写的很清楚需要一个宏包。123456\\begin&#123;figure&#125; \\centering % Requires \\usepackage&#123;graphicx&#125; \\includegraphics[width=4in]&#123;a.jpg&#125;\\\\ \\caption&#123;hehe&#125;\\label&#123;fig.1&#125;\\end&#123;figure&#125; 最关键的问题在于宏包插在什么位置，一般是插在\\documentclass[]{}的下面，由于我是投稿会议模版如下:12\\documentclass[conference]&#123;IEEEtran&#125;\\usepackage&#123;graphicx&#125; Pseudo codes 怎么插入伪代码倒是不难，要学一下代码的写入格式，还是一样要插入宏包 伪代码的风格比较简单，主要有两种第一种比较简单，第二种宏包多代码复杂，但是可能好看些，具体事例如下：12345678910111213141516example1:简易风\\documentclass[conference]&#123;IEEEtran&#125;\\usepackage&#123;clrscode&#125;\\begin&#123;codebox&#125;\\Procname&#123;$\\proc&#123;Insertion-Sort(A)&#125;$&#125;\\li \\For $j \\gets 2$ \\To $\\id&#123;length&#125;[A]$ \\label&#123;li:for&#125;\\li \\Do $\\id&#123;key&#125; \\gets A[j]$ \\label&#123;li:for-begin&#125;\\li \\Comment Insert $A[j]$ into the sorted sequence $A[1 \\twodots j-1]$.\\li $i \\gets j-1$\\li \\While $i&gt;0$ and $A[i]&gt;\\id&#123;key&#125;$ \\label&#123;li:while&#125;\\li \\Do $A[i+1] \\gets A[i]$ \\label&#123;li:while-begin&#125;\\li $i \\gets i-1$ \\label&#123;li:while-end&#125; \\End\\li $A[i+1] \\gets \\id&#123;key&#125;$ \\label&#123;li:for-end&#125; \\End\\end&#123;codebox&#125; 1234567891011121314151617181920212223example2:酷炫风\\documentclass[conference]&#123;IEEEtran&#125;\\usepackage&#123;caption&#125;\\usepackage&#123;algorithm&#125;\\usepackage&#123;algpseudocode&#125;\\begin&#123;document&#125;\\begin&#123;algorithm&#125; \\caption&#123;A test algorithm (Part I)&#125; \\begin&#123;algorithmic&#125;[1] \\Procedure &#123;BellmanKalaba&#125;&#123;$G$, $u$, $l$, $p$&#125; \\ForAll &#123;$v \\in V(G)$&#125; \\State $l(v) \\leftarrow \\infty$ \\EndFor \\algstore&#123;bkbreak&#125; \\end&#123;algorithmic&#125; \\begin&#123;algorithmic&#125;[1] \\algrestore&#123;bkbreak&#125; \\state $l(v) \\leftarrow \\infty$ \\EndProcedure\\end&#123;algorithmic&#125;\\end&#123;algorithm&#125;\\end&#123;document&#125; 这两个代码我都自己跑过了是可行的，第二种伪代码其实是两个代码拼接的，所以直接用就好。－－－这个会比较好看一点，怎么写就自己查官方问题集，不过单纯的用来写论文直接拿IEEE模版改一改就好了，如果真的很复杂不如重新安装。 Resource[Ctex-FAQ].阿西吧，困死我了，才写了四页，我真是哔了狗！！！！！koba!(我新学的台湾骂人话 嘿嘿嘿～)","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"SDN虚拟机环境搭建（Mininet+Ryu）","slug":"buildryu","date":"2017-10-11T12:48:39.962Z","updated":"2017-06-28T11:01:34.000Z","comments":true,"path":"2017/10/11/buildryu/","link":"","permalink":"http://yoursite.com/2017/10/11/buildryu/","excerpt":"","text":"因为hsnl的主要项目是sdn，所以我准备转到sdn方向做qos，而且由于有真机，在实作上可能效果会蛮好的。开始搭建环境首先我要说直接用sudo apt-get 是最简单，但是对环境的要求比较高，要求版本什么的都必须是要求的，对于我们计算机而言之前的环境搭的很幸苦，删了未免得不偿失，所以我们尽量用源码编译，或者直接使用git的方式。 基本环境1234sudo apt-get install python-pip python-dev build-essentialsudo apt-get install python-eventlet python-routes python-webob python-paramiko/*上面两个是安装ryu的依赖包*//*关于mininet安装包及可能出现的问题我在mininet里面写*/ Mininetmininet很多人都推荐使用12sudo apt-get install mininetsudo mn /*有拓扑不报错表示成功*/ 实际上，这种方式虽然简单但是我还是觉得源码编译会靠谱一些，我是用源码安装的，当然直接get是可行的。源码安装方式如下123456git clone git://github.com/mininet/mininetcd mininetgit taggit checkout -b 2.2.2util/install.sh -asudo mn 如果拓扑出来了，那就是没问题了，实际上还是可能会出现依赖包不匹配的问题，这个时候你看下他报什么错1.你的版本过高 那么是可以兼容的2.你的版本过低 更新版本，或者按照报错的去update。我出现的是openswitch-common和openswitch-pki过低的问题，更新后是可以用的 RyuRyu安装的时候也建议源码安装,首先先安装我最上面说的基本环境然后输入下述指令12345678/*没有pip的线安装pip*/wget https://bootstrap.pypa.io/get-pip.pypython get-pip.pypip -Vsudo pip install ryuryu-manager/*出现loading app ryu.controller.ofp_handler.....就表示成功了*/ 两个环境都搭好以后怎么连起来呢？如下1234567$ cd /*启动mininet，建立基本拓扑先*/$ sudo mn --topo single,3 --mac --switch ovsk --controller remotemininet &gt; pingall/*新开端口打开ryu准备连进去*/$ ryu-manager ryu/ryu/app/simple_switch.py/*这个时候应该可以在ryu捕捉到2层信息了，环境也算成功了*/ 环境成功就可以开始学写了，具体的里面东西我下午开始学了，居然花了一个小时搭环境，我果然是个腊鸡。成功后的图如下祝大家学习顺利，学习使我快乐，学习使我进步，学习使我没有女朋友，耶！","categories":[],"tags":[{"name":"sdn","slug":"sdn","permalink":"http://yoursite.com/tags/sdn/"}]},{"title":"二叉树的遍历总结--Python","slug":"binaryorder","date":"2017-10-11T12:48:39.957Z","updated":"2017-07-20T15:15:06.000Z","comments":true,"path":"2017/10/11/binaryorder/","link":"","permalink":"http://yoursite.com/2017/10/11/binaryorder/","excerpt":"","text":"还是要自己动手写才知道有什么问题 ＝＝！，大约看了很久视频讲解，自己终于也算写出来了，做个大概的总结，明天可能会考虑把leetcode里面所有easy的二叉树的题做一下。 主要实现了生成树，怎么把节点添加进去然后用递归的方式实现了前序，后序，中序遍历（就是node在前中后的遍历），非递归的方式（用栈实现，其实差不多），层序遍历（广度优先，队列）的实现。想了下还是把函数分段，建议把函数先拉到最后看一下函数的输入是什么。 1234567891011121314151617181920212223242526272829303132333435class Node(object): def __init__ (self,elem = -1,lchild = None,rchild = None): self.elem = elem self.lchild = lchild self.rchild = rchildclass Tree(object): def __init__(self): self.root = Node() ＃这里实例化 self.myQueue = [] def add(self,elem): node = Node(elem) ＃ 把参数传进来，那node每个循环就是 1，2，3，4，5，6，7，8，9 # what is Node # print node if self.root.elem == -1: self.root = node self.myQueue.append(self.root) #没有节点就设为根节点，然后放到队列里面（这个出队列的时间要看下） else: treeNode = self.myQueue[0] # 把队列第一个数输出作为根节点 #what is treeNode # print treeNode if treeNode.lchild == None: treeNode.lchild = node self.myQueue.append(treeNode.lchild) else: treeNode.rchild = node self.myQueue.append(treeNode.rchild) self.myQueue.pop(0) #在这里出队列 print myQueue 1 1 1 2 2 3 que = [1 2 3] －&gt;这个时候把1 pop出去根节点就变成2 3 que = [2 3] 下面是递归的三种遍历方式,这个有个小哥的视频讲的很清楚，我贴一下吧，虽然讲到最后自己也讲蒙蔽了，笑死了。 Yu Zhou-Youtube二叉搜索树(Binary Search Tree) in Python Part 1. (Insert)二叉搜索树(Binary Search Tree) in Python Part 2. (Find value)二叉搜索树(Binary Search Tree) in Python Part 3. (Traverse) 1234567891011121314151617181920212223def front_digui(self,root): if root == None: return else: print root.elem self.front_digui(root.lchild) self.front_digui(root.rchild)def middle_digui(self,root): if root == None: return else: self.middle_digui(root.lchild) print root.elem self.middle_digui(root.rchild)def later_digui(self,root): if root == None: return else: self.later_digui(root.lchild) self.later_digui(root.rchild) print root.elem 下面是非递归的方式就是用了栈，其实逻辑是一样的，栈就是先入后出嘛所以前序的时候，先访问根节点node.elem，如果有子树就入栈并且输出，如果没有子节点就出栈（出栈但是不输出），我后面看到一个不错的博客逻辑比较清晰，我贴出来，看完我的代码在看会清晰很多。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#非递归的方式def front_stack(self,root): if root == None: return myStack = [] node = root while node or myStack: while node: #从根节点一直找左子树 print node.elem myStack.append(node) node = node.lchild node = myStack.pop() #pop()完node就空了跳出循环 node = node.rchild #node.elem 左子树 右子树def middle_stack(self,root): if root == None: return myStack = [] node = root while node or myStack: while node: myStack.append(node) node = node.lchild node = myStack.pop() print node.elem node = node.rchild def later_stack(self,root): if root == None: return myStack1 = [] myStack2 = [] node = root myStack1.append(node) while myStack1: #找出后序遍历的逆序，存在myStack2里面 node = myStack1.pop() if node.lchild: myStack1.append(node.lchild) if node.rchild: myStack1.append(node.rchild) myStack2.append(node) while myStack2: #将myStack2中的元素出栈，即为后序遍历次序 print myStack2.pop().elem 根据先序遍历的顺序，先访问根节点，再访问左子树，后访问右子树，而对于每个子树来说，又按照同样的访问顺序进行遍历，上图的先序遍历顺序为：ABDECF。非递归的实现思路如下：对于任一节点P，1）输出节点P，然后将其入栈，再看P的左孩子是否为空；2）若P的左孩子不为空，则置P的左孩子为当前节点，重复1）的操作；3）若P的左孩子为空，则将栈顶节点出栈，但不输出，并将出栈节点的右孩子置为当前节点，看其是否为空；4）若不为空，则循环至1）操作；5）如果为空，则继续出栈，但不输出，同时将出栈节点的右孩子置为当前节点，看其是否为空，重复4）和5）操作；6）直到当前节点P为NULL并且栈空，遍历结束。 下面以上图为例详细分析其先序遍历的非递归实现过程：首先，从根节点A开始，根据操作1），输出A，并将其入栈，由于A的左孩子不为空，根据操作2），将B置为当前节点，再根据操作1），将B输出，并将其入栈，由于B的左孩子也不为空，根据操作2），将D置为当前节点，再根据操作1），输出D，并将其入栈，此时输出序列为ABD；由于D的左孩子为空，根据操作3），将栈顶节点D出栈，但不输出，并将其右孩子置为当前节点；由于D的右孩子为空，根据操作5），继续将栈顶节点B出栈，但不输出，并将其右孩子置为当前节点；由于B的右孩子E不为空，根据操作1），输出E，并将其入栈，此时输出序列为：ABDE；由于E的左孩子为空，根据操作3），将栈顶节点E出栈，但不输出，并将其右孩子置为当前节点；由于E的右孩子为空，根据操作5），继续将栈顶节点A出栈，但不输出，并将其右孩子置为当前节点；由于A的右孩子C不为空，根据操作1），输出C，并将其入栈，此时输出序列为：ABDEC；由于A的左孩子F不为空，根据操作2），则将F置为当前节点，再根据操作1），输出F，并将其入栈，此时输出序列为：ABDECF；由于F的左孩子为空，根据操作3），将栈顶节点F出栈，但不输出，并将其右孩子置为当前节点；由于F的右孩子为空，根据操作5），继续将栈顶元素C出栈，但不输出，并将其右孩子置为当前节点；此时栈空，且C的右孩子为NULL，因此遍历结束。 层序遍历其实逻辑和add子树是一样的。123456789101112131415161718192021222324252627def level_queue(self,root): if root == None: return myQueue = [] node = root myQueue.append(node) while myQueue: node =myQueue.pop(0) print node.elem if node.lchild != None: myQueue.append(node.lchild) if node.rchild != None: myQueue.append(node.rchild)if __name__ == &apos;__main__&apos;: elems = range(10) tree = Tree() for elem in elems: tree.add(elem) tree.level_queue(tree.root) tree.front_digui(tree.root) tree.middle_digui(tree.root) tree.later_digui(tree.root) tree.front_stack(tree.root) tree.middle_stack(tree.root) tree.later_stack(tree.root) 这个代码还是有点长的，逻辑很清晰，我放到github里面了。 话说，虽然不写大括号让人不舒服，但是sublime换个背景会让人的效率大大的提升啊！！安利一下Dawn的主题，稳得要死。 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"二叉堆 BinaryHeap实现及回顾--Python","slug":"binaryheap","date":"2017-10-11T12:48:39.953Z","updated":"2017-07-17T14:36:12.000Z","comments":true,"path":"2017/10/11/binaryheap/","link":"","permalink":"http://yoursite.com/2017/10/11/binaryheap/","excerpt":"","text":"数据结构二叉堆能够很好地实现优先队列的基本操作。在二叉堆的数组中，每个元素都要保证大于等于另两个特定位置的元素。相应地，这些位置的元素又至少要大于等于数组中的另两个元素，以此类推。如果我们将所有元素画成一棵二叉树，将每个较大元素和两个较小的元素用边连接就可以很容易看出这种结构。 查了一下堆的定义，当一颗二叉树的每个结点都大雨等于它的两个子结点时，它被称为堆有序。 二叉堆的逻辑结构用图形表示很像二叉树,但我们却可以仅仅用一个列表来 实现它。二叉堆通常有两种:最小成员 key 排在队首的称为“最小堆(min heap)”,反之,最大 key 排在队首的是“最大堆(max heap)”。 二叉堆的实现使用“完全二叉树”来简化问题，减少复杂度，平衡的二 叉树树根左右子树有着相同数量的节点。使用完全二叉树的特性，对于完全树，如果节点在列表中的位置为 p,那么其左子节点的位置为 2p,其 右子节点的位置为 2p+1。当我们要找任意节点的父节点时,可以直接利用 python 的整数除法。若节点在列表中的位置为 n,那么父节点的位置是 n//2。(之后上浮或者下沉都可以利用这一特性，来寻找嵌套的列表) 二叉堆操作的实现采用一个列表来保存堆数据,构造函数 仅仅需要初始化一个列表和一个 currentSize 来跟踪记录堆当前的大小。1.插入key值往列表中添加数据项最简单也最高效的方式是直接将数据项添加到列表末尾。这样做虽然保持了完全树的性质,但无法保持堆的次序性。不过,我们可以通过比较新加入的数据项和父节点的方法来恢复堆的次序性。如果新加入的数据项比父节点要小,可以把它与父节点互换位置。使用“up”操作就可以保证堆次序，不停交换位置即可。123456789101112def precUp(self,i): while i // 2 &gt; 0: if self.heapList[i] &lt; self.heapList[i//2]: tmp = self.heapList[i//2] self.heapList[i//2] = self.heapList[i] self.heapList[i] = tmp i = i //2def insert(self,k): self.heapList.append(k) //先插在列表最后面 self.currentSize = self.currentSize+1 self.precUp(self.currentSize) 2.delmin()堆次序要求根节点是树中最小的数据项,因此很容易找到最小项。比较困难的是移走根节点的数据项后如何恢复堆结构和堆次序。分成两步，首先,用最后一个节点来代替根节点。移走最后一个节点维持了堆结构的性质。但是经过简单的替换,可能导致直接破坏堆次序。这就要用到第二步:将新节点“下沉”来恢复堆次序。”down”操作12345678910111213141516171819202122232425def percDown(self,i): while(i*2) &lt;= self.currentSize: mc = self.minChild(i) if self.heapList[i] &gt; self.heapList[mc]: tmp = self.heapList[i] self.heapList[i] = self.heapList[mc] self.heapList[mc] = tmp i = mcdef minChild(self,i): if i*2 + 1 &gt; self.currentSize: return i *2 else: if self.heapList[i*2] &lt; self.heapList[i*2+1]: return i *2 else: return i*2 +1def delMin(self): retval = self.heapList[1] self.heapList.pop() self.percDown(1) self.heapList[1] = self.heapList[self.currentSize] self.currentSize = self.currentSize -1 无序表生成堆最简单易想的方法，用insert (key)方法,将无序表中的数据项逐个插入到堆中。对于一个排好序的列表,我们可以用二分搜索找到合适的位置来插入下一个 key,操作复杂度是 O(logn).然而插入一个数据项到列表中间需要将列表其他数据项移动为新节点腾出位置,操作复杂度是 O(n).因此用insert(key)方法的总代价是 O(nlogn)。其实,我们能直接将整个列表生成堆,将总代价控制在 O(n)。 1234567def buildHeap(self,alist): i = len(alist) // 2 self.currentSize = len(alist) self.heapList = [0] + alist[:] while (i &gt; 0): self.percDown(i) i = i -1 这个图其实挺能说明问题，我贴一下 最右边的两颗树,首先 9 从 根节点的位置上移走,移到下一层级之后,percDown进一步检查它此时的子节点,保证它下降到不能下降为止,即下降到正确的位置。这就导致了第二次交换:9和3的交换。由于9已经移到了树的 最底层,便无法进一步交换了。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"树的遍历方式","slug":"bianli","date":"2017-10-11T12:48:39.947Z","updated":"2017-07-13T11:52:12.000Z","comments":true,"path":"2017/10/11/bianli/","link":"","permalink":"http://yoursite.com/2017/10/11/bianli/","excerpt":"","text":"前序遍历(preorder):在前序遍历中,我们先访问根节点,然后递归地前序遍历访问左子树,再 递归地前序遍历访问右子树。中序遍历(inorder):在中序遍历中,我们递归地中序遍历访问左子树,然后访问根节点,最后 再递归地中序遍历访问右子树。后序遍历(postorder):在后序遍历中,我们先递归地后序遍历访问左子树和右子树,最后访问 根节点。 前序遍历根－左子树－右子树123456def preorder(self): print(self.key) if self.leftChild: self.leftChild.preorder() if self.rightChild: self.rightChild.preoder() preorder函数123456def preorder(self): print(self.key) if self.leftChild: self.leftChild.preorder() if self.rightChild: self.rightChild.preorder() 中序遍历12def inorder(tree): if tree != None:inorder(tree.getLeftChild()) print(tree.getRootVal()) inorder(tree.getRightChild()) 后序遍历12def postorder(tree): if tree != None:postorder(tree.getLeftChild()) postorder(tree.getRightChild()) print(tree.getRootVal())","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"背包问题 -- 动态规划(Dynamic Programming)","slug":"beibao","date":"2017-10-11T12:48:39.943Z","updated":"2017-08-02T14:26:22.000Z","comments":true,"path":"2017/10/11/beibao/","link":"","permalink":"http://yoursite.com/2017/10/11/beibao/","excerpt":"","text":"先更新背包问题，最长子序列慢慢来吧，还有二叉树的的leetcode没有AC掉。背包问题最简单粗暴的做法就是暴力解法，就是尝试各种可能的商品组合，并找出价值最高的组合。 动态规划在01背包问题中，在选择是否要把一个物品加到背包中，必须把该物品加进去的子问题的解与不取该物品的子问题的解进行比较，这种方式形成的问题导致了许多重叠子问题，使用动态规划来解决。n=5是物品的数量，c=10是书包能承受的重量，w=[2,2,6,5,4]是每个物品的重量，v=[6,3,5,4,6]是每个物品的价值，先把递归的定义写出来：其实画一个表格就很清晰了，我们假设只有一个物品，那前一栏肯定是最优解，新一栏要么就是上一栏的值，要么就是当前商品价值加上剩余空间的价值，去最大就是了。前面因为背包的容量最大就是填充这么多，直到背包容量更新我们才可以更新新值。其实我们看起来计算更新的值时使用了新的公式，其实是一样的公式，那就是取两者的最大值。max(上一个单元的值，当前物品的价值＋剩余空间的值)上一个单元：就是没有更新容量的最大值，如果容量增加不够，那就是上一个值，如果容量够了那么针对这一行的第二个值就是：当前行的物品值＋剩余空间的值。首先我们要知道为什么要使用(Dynamic programming)dp，我们在选择dp算法的时候，往往是在决策问题上，而且是在如果不使用dp，直接暴力效率会很低的情况下选择使用dp. 那么问题来了，什么时候会选择使用dp呢，一般情况下，我们能将问题抽象出来，并且问题满足无后效性，满足最优子结构，并且能明确的找出状态转移方程的话，dp无疑是很好的选择。 无后效性通俗的说就是只要我们得出了当前状态，而不用管这个状态怎么来的，也就是说之前的状态已经用不着了，如果我们抽象出的状态有后效性，很简单，我们只用把这个值加入到状态的表示中。 最优子结构(自下而上)：在决策问题中，如果，当前问题可以拆分为多个子问题，并且依赖于这些子问题，那么我们称为此问题符合子结构，而若当前状态可以由某个阶段的某个或某些状态直接得到，那么就符合最优子结构 重叠子问题(自上而下)：动态规划算法总是充分利用重叠子问题，通过每个子问题只解一次，把解保存在一个需要时就可以查看的表中，每次查表的时间为常数，如备忘录的递归方法。斐波那契数列的递归就是个很好的例子 状态转移：这个概念比较简单，在抽象出上述两点的的状态表示后，每种状态之间转移时值或者参数的变化。代码如下:123456789101112131415161718192021222324252627282930313233# gita 1500 1g# box 3000 4g# mac 2000 3g# iphone 2000 1gweight = [0,1,4,3,1]val = [0,1500,3000,2000,2000]n = len(weight) - 1 # compute the mount of the commorditym = 4 #total weightx = [] #bagsv = 0optp = [[0 for col in range(m + 1)] for raw in range(n + 1)]print optpdef knapsack_dynamic(weight,val,n,m,x): for i in range(1,n+1): for j in range(1,m+1): if (j &gt;= weight[i]): optp[i][j] = max(optp[i-1][j],optp[i-1][j-weight[i]]+val[i]) else: optp[i][j] = optp[i-1][j] j = m for i in range(n,0,-1): if optp[i][j] &gt; optp[i-1][j]: x.append(i) j = j - weight[i] v = optp[n][m] return vprint &apos;max val:&apos; + str(knapsack_dynamic(weight, val, n, m, x))print &apos;commodity index:&apos;,x Resource1.动态规划(DP)的整理-Python描述.2.01背包问题（动态规划）python实现.3.Python算法：动态规划.","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"数据结构中的栈(前中后缀表达式)，队列的实现－－python","slug":"algorithm_list","date":"2017-10-11T12:48:39.938Z","updated":"2017-07-05T13:49:24.000Z","comments":true,"path":"2017/10/11/algorithm_list/","link":"","permalink":"http://yoursite.com/2017/10/11/algorithm_list/","excerpt":"","text":"栈栈的实现123456789101112131415161718192021222324class Stack(object): # Stack() 创建一个空的新栈。 def __init__(self): self.items = [] # push(new_item)将一个新的元素添加到栈顶。 def push(self, new_item): self.items.append(new_item) # 返回栈顶元素，但不会弹出它。 def top(self)： return self.items[-1] # 弹出并返回栈顶元素 def pop(self): return self.items.pop() # 返回栈是否为空。栈空返回true，否则返回false。 def isEmpty(self): return [] == self.items # 返回栈的长度，即栈中元素的个数。 def size(self): return len(self.items) 后缀表达式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485class Stack(object): # Stack() 创建一个空的新栈。 def __init__(self): self.items = [] # push(new_item)将一个新的元素添加到栈顶。 def push(self, new_item): self.items.append(new_item) # 返回栈顶元素，但不会弹出它。 def top(self): return self.items[-1] # 弹出并返回栈顶元素 def pop(self): return self.items.pop() # 返回栈是否为空。栈空返回true，否则返回false。 def isEmpty(self): return [] == self.items # 返回栈的长度，即栈中元素的个数。 def size(self): return len(self.items)# 将中缀表达式变换成后缀表达式# trans_string为传入的待转换的中缀表达式# op_rank为运算符的优先级，数字越大，优先级越高def mid2post(trans_string, op_rank): post_list = [] #创建一个空列表，用于保存生成中的后缀表达式 stack = Stack() #创建一个新的栈用于保存未被输出的运算符 for checking_char in trans_string: #从左到右，逐个遍历中缀表达式中的字符 if checking_char in &apos;ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&apos;: #当前字符为字母或数字 post_list.append(checking_char) #将字符接入后缀表达式 elif checking_char == &apos;(&apos;: #当前符号为左括号 stack.push(checking_char) #将左括号入栈，代表着后面出现的运算符优先级更高 elif checking_char == &apos;)&apos;: #当前符号为右括号 top_char = stack.pop() while top_char != &apos;(&apos;: #弹出元素，接入后缀表达式，直到出现配对的左括号 post_list.append(top_char) top_char = stack.pop() else: #符号为运算符 while (not stack.isEmpty()) and (op_rank[stack.top()]&gt;=op_rank[checking_char]): #栈不为空，且栈顶符号优先级不低于当前符号 post_list.append(stack.pop()) #弹出这个更靠前的运算符，并接入后缀表达式 stack.push(checking_char) #将运算符压入栈 while not stack.isEmpty(): #当栈未空 post_list.append(stack.pop()) #弹出所有运算符，并接入后缀表达式 return &apos;&apos;.join(post_list) #将列表转换为字符串并返回# 将计算后缀表达式# post_string为传入的待计算的后缀表达式# op_rank为运算符的优先级，数字越大，优先级越高def compute_post(post_string): stack = Stack() #创建一个新的栈用于保存未被输出的运算符 for computing_char in post_string: #从左遍历 if computing_char in &apos;01234567889&apos;: #如果当前为数字 stack.push(computing_char) #压入栈 else: #如果为运算符 value_2 = int(stack.pop()) #先弹出后一个操作数 value_1 = int(stack.pop()) #后弹出前一个操作数 if computing_char == &apos;+&apos;: value_3 = value_1 + value_2 elif computing_char == &apos;-&apos;: value_3 = value_1 - value_2 elif computing_char == &apos;*&apos;: value_3 = value_1 * value_2 else: value_3 = value_1 / value_2 stack.push(value_3) #将运算结果入栈 return stack.pop()def main(): op_rank = &#123;&apos;*&apos;:2, &apos;/&apos;:2, &apos;+&apos;:1, &apos;-&apos;:1, &apos;(&apos;:0&#125; string_list = [&apos;1+2&apos;, &apos;1+2*3&apos;, &apos;(1+2)*3&apos;, &apos;(1+2)*(3+4)&apos;, &apos;1+2+3+4&apos;] for trans_string in string_list: print(&quot;%s --&gt; %s --&gt; %d&quot; % (trans_string, mid2post(trans_string,op_rank), compute_post(mid2post(trans_string,op_rank)) )) print(&quot;-----------------&quot;)if __name__ == &quot;__main__&quot;: main() 中缀表达式假设表达式中只有大写字母、数字和运算符，如何将一个中缀表达式转换为后缀表达式？解决这一问题的要点有如下： 大写字母和数字的排列顺序，中缀表达式和后缀表达式是相同的。 优先级更高的运算符和靠左的同级别运算符应当更早在后缀表达式中出现。 括号相当于更高的一个平台，左括号作为平台的开始，右括号作为平台的结束。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class Stack(object): # Stack() 创建一个空的新栈。 def __init__(self): self.items = [] # push(new_item)将一个新的元素添加到栈顶。 def push(self, new_item): self.items.append(new_item) # 返回栈顶元素，但不会弹出它。 def top(self): return self.items[-1] # 弹出并返回栈顶元素 def pop(self): return self.items.pop() # 返回栈是否为空。栈空返回true，否则返回false。 def isEmpty(self): return [] == self.items # 返回栈的长度，即栈中元素的个数。 def size(self): return len(self.items)# 将中缀表达式变换成后缀表达式# trans_string为传入的待转换的中缀表达式# op_rank为运算符的优先级，数字越大，优先级越高def mid2post(trans_string, op_rank): post_list = [] #创建一个空列表，用于保存生成中的后缀表达式 stack = Stack() #创建一个新的栈用于保存未被输出的运算符 for checking_char in trans_string: #从左到右，逐个遍历中缀表达式中的字符 if checking_char in &apos;ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&apos;: #当前字符为字母或数字 post_list.append(checking_char) #将字符接入后缀表达式 elif checking_char == &apos;(&apos;: #当前符号为左括号 stack.push(checking_char) #将左括号入栈，代表着后面出现的运算符优先级更高 elif checking_char == &apos;)&apos;: #当前符号为右括号 top_char = stack.pop() while top_char != &apos;(&apos;: #弹出元素，接入后缀表达式，直到出现配对的左括号 post_list.append(top_char) top_char = stack.pop() else: #符号为运算符 while (not stack.isEmpty()) and (op_rank[stack.top()]&gt;=op_rank[checking_char]): #栈不为空，且栈顶符号优先级不低于当前符号 post_list.append(stack.pop()) #弹出这个更靠前的运算符，并接入后缀表达式 stack.push(checking_char) #将运算符压入栈 while not stack.isEmpty(): #当栈未空 post_list.append(stack.pop()) #弹出所有运算符，并接入后缀表达式 return &apos;&apos;.join(post_list) #将列表转换为字符串并返回def main(): op_rank = &#123;&apos;*&apos;:2, &apos;/&apos;:2, &apos;+&apos;:1, &apos;-&apos;:1, &apos;(&apos;:0&#125; string_list = [&apos;A+B&apos;, &apos;A+B*C&apos;, &apos;(A+B)*C&apos;, &apos;(A+B)*(C+D)&apos;, &apos;A+B+C+D&apos;] for trans_string in string_list: print(&quot;%s --&gt; %s&quot;%( trans_string, mid2post(trans_string,op_rank))) print(&quot;-----------------&quot;)if __name__ == &quot;__main__&quot;: main() 前缀表达式就是反向的后缀，从右到左往里面读字符。 队列123456789101112131415class Queue: def __init__(self): self.items = [] def isEmpty(self): return self.items == [] def enqueue(self, item): self.items.insert(0,item) def dequeue(self): return self.items.pop() def size(self): return len(self.items) 知名实例，传山芋问题(copy自博客)我们模拟一种真实的先进先出的情形。作为开始，我们观察一种儿童游戏，叫烫手的山芋（hotpotato），在这个游戏中，孩子们排成一圈，把手里的东西一个传一个，在某种情形下，停止传递，手上拿着烫手的山芋的人就要被清出来，其他的人继续玩，直到只剩一个人。如图所示：从现代意义上说，这个游戏等价于著名的约瑟夫问题。据说，一世纪左右，历史学家弗拉维约瑟夫与犹太人一起反抗罗马。一次，约瑟夫和他的39个同志一起在山洞里抵抗，不过眼看就要失败了，他们决定宁死也不做罗马的奴隶。他们围坐成一圈，一个人一个编号，按时针方向，每第七个人就要被杀死。据说约瑟夫是个数学家，他马上就知道按这规则，应该坐在哪个位置会留到最后。看来约瑟夫最后没有自杀，相反却投降了。这个故事有很多版本，有的版本说是每3个人杀一个，有的说最后一个人可以骑马逃脱，但不管怎样，思想是相同的。我们引入一个烫手的山芋的模拟过程，参数是一个名字列表和一个常数num。num用来计数，最后函数返回经多轮计数后，剩下的最后一个人的名字。后来发生什么，就看你的了。为了模拟这个圆圈，我们使用队列（图3）。假定开始拿着山芋的孩子站在队伍的前端，一经传出山芋后，模拟程序只需要简单地把这个孩子移出队列，然后再将他加入尾部，然后他在尾部再逐步前移，直到再次轮到他。经过num次出队入队之后，前端的孩子最终被完全清出队列，然后剩余的人继续游戏，直到最后一个。12345678910111213141516from pythonds.basic.queue import Queue def hotPotato(namelist, num): simqueue = Queue() for name in namelist: simqueue.enqueue(name) while simqueue.size() &gt;1: for i in range(num): simqueue.enqueue(simqueue.dequeue()) simqueue.dequeue() return simqueue.dequeue() print(hotPotato([&quot;Bill&quot;,&quot;David&quot;,&quot;Susan&quot;,&quot;Jane&quot;,&quot;Kent&quot;,&quot;Brad&quot;],7)) 双端队列deque 与队列类似，也是一系列元素的有序组合，其两端分别为队首(front)和队尾(rear)，元素在到达两端之前始终未愈双端队列之中。与队列不同的是，双端队列对元素的添加和删除的限制不那么严格，可以从两端插入和两端删除。主要操作如下：123456789101112131415161718class Deque: def __init__(self): self.items = [] def isEmpty(self): return self.items == [] def addFront(self,item): self.items.append(item) def addRear(self,item): self.items.insert(0,item) def removeFront(self): return self.items.pop() def removeRear(self): return self.items.pop(0) def size(self): return len(self.items)d =Deque()print (d.isEmpty()) 双端队列判断回文词因为我们可以同时去除两端的字符，所以我们可以比较他们是否相同，如果相同就继续比较剩下双端队列的首尾字符，要么只剩一个字符，这取决于字符串的原始长度是奇数还是偶数，不管哪种情况这个字符都是一个回文字符穿。123456d = Deque()while d.size() &gt; 1: first = d.removeFront() last = d.removeRear() if first != last: return False","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"浅谈SQL SERVER中事务的ACID","slug":"ACID","date":"2017-10-11T12:48:39.934Z","updated":"2017-08-01T09:29:30.000Z","comments":true,"path":"2017/10/11/ACID/","link":"","permalink":"http://yoursite.com/2017/10/11/ACID/","excerpt":"","text":"我们将看到进程是如何保证每个查询在自己的事务内执行的。但开始之前，我们需要理解ACID事务的概念。 Server中的ACID一个ACID事务是一个工作单元，它要保证4个属性： A:原子性(Atomicity),事务『要么全部完成，要么全部取消』，即使它持续运行10个小时。如果事务崩溃，状态回到事务之前(事务回滚)。 C:一致性（Consistency）,只有合法的数据（依照关系约束和函数约束）能写入数据库，一致性与原子性和隔离性有关。 I:隔离性（Isolation）,如果2个事务 A 和 B 同时运行，事务 A 和 B 最终的结果是相同的，不管 A 是结束于 B 之前/之后/运行期间。 D:持久性（Durability）,一旦事务提交（也就是成功执行）,不管发生什么（崩溃或者出错），数据要保存在数据库中。 在同一个事务内，你可以运行多个SQL查询来读取、创建、更新和删除数据。当两个事务使用相同的数据，麻烦就来了。经典的例子是从账户A到账户B的汇款。假设有2个事务： 事务1（T1）从账户A取出100美元给账户B 事务2（T2）从账户A取出50美元给账户B 我们回来看看ACID属性: 原子性确保不管 T1 期间发生什么（服务器崩溃、网络中断…），你不能出现账户A 取走了100美元但没有给账户B 的现象（这就是数据不一致状态）。 隔离性确保如果 T1 和 T2 同时发生，最终A将减少150美元，B将得到150美元，而不是其他结果，比如因为 T2 部分抹除了 T1 的行为，A减少150美元而B只得到50美元（这也是不一致状态）。 持久性确保如果 T1 刚刚提交，数据库就发生崩溃，T1 不会消失得无影无踪。 一致性确保钱不会在系统内生成或灭失 现代数据库不会使用纯粹的隔离作为默认模式，因为它会带来巨大的性能消耗。SQL一般定义4个隔离级别：1.串行化(Serializable，SQLite默认模式）：最高级别的隔离。两个同时发生的事务100%隔离，每个事务有自己的『世界』2.可重复读（Repeatable read，MySQL默认模式）：每个事务有自己的『世界』，除了一种情况。如果一个事务成功执行并且添加了新数据，这些数据对其他正在执行的事务是可见的。但是如果事务成功修改了一条数据，修改结果对正在运行的事务不可见。所以，事务之间只是在新数据方面突破了隔离，对已存在的数据仍旧隔离。举个例子，如果事务A运行”SELECT count(1) from TABLE_X” ，然后事务B在 TABLE_X 加入一条新数据并提交，当事务A再运行一次 count(1)结果不会是一样的。这叫幻读（phantom read）。3.读取已提交（Read committed，Oracle、PostgreSQL、SQL Server默认模式）：可重复读+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（或删除）并提交，事务A再次读取数据D时数据的变化（或删除）是可见的。这叫不可重复读（non-repeatable read）。4.读取未提交（Read uncommitted）：最低级别的隔离，是读取已提交+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（但并未提交，事务B仍在运行中），事务A再次读取数据D时，数据修改是可见的。如果事务B回滚，那么事务A第二次读取的数据D是无意义的，因为那是事务B所做的从未发生的修改（已经回滚了嘛）。这叫脏读（dirty read） 并发控制确保隔离性、一致性和原子性的真正问题是对相同数据的写操作（增、更、删）： 如果所有事务只是读取数据，它们可以同时工作，不会更改另一个事务的行为。 如果（至少）有一个事务在修改其他事务读取的数据，数据库需要找个办法对其它事务隐藏这种修改。而且，它还需要确保这个修改操作不会被另一个看不到这些数据修改的事务擦除。这个问题叫并发控制。最简单的解决办法是依次执行每个事务（即顺序执行），但这样就完全没有伸缩性了，在一个多处理器/多核服务器上只有一个核心在工作，效率很低。理想的办法是，每次一个事务创建或取消时: 监控所有事务的所有操作 检查是否2个（或更多）事务的部分操作因为读取/修改相同的数据而存在冲突 重新编排冲突事务中的操作来减少冲突的部分 按照一定的顺序执行冲突的部分（同时非冲突事务仍然在并发运行） 考虑事务有可能被取消用更正规的说法，这是对冲突的调度问题。更具体点儿说，这是个非常困难而且CPU开销很大的优化问题。企业级数据库无法承担等待几个小时，来寻找每个新事务活动最好的调度，因此就使用不那么理想的方式以避免更多的时间浪费在解决冲突上。 锁管理器为了解决这个问题，多数数据库使用锁和/或数据版本控制。这是个很大的话题，我会集中探讨锁，和一点点数据版本控制。 悲观锁: 如果一个事务需要一条数据 它就把数据锁住 如果另一个事务也需要这条数据 它就必须要等第一个事务释放这条数据这个锁叫排他锁。但是对一个仅仅读取数据的事务使用排他锁非常昂贵，因为这会迫使其它只需要读取相同数据的事务等待。因此就有了另一种锁，共享锁。 共享锁: 如果一个事务只需要读取数据A 它会给数据A加上『共享锁』并读取 如果第二个事务也需要仅仅读取数据A 它会给数据A加上『共享锁』并读取 如果第三个事务需要修改数据A 它会给数据A加上『排他锁』，但是必须等待另外两个事务释放它们的共享锁。同样的，如果一块数据被加上排他锁，一个只需要读取该数据的事务必须等待排他锁释放才能给该数据加上共享锁。 lockmanager锁管理器是添加和释放锁的进程，在内部用一个哈希表保存锁信息（关键字是被锁的数据），并且了解每一块数据是： 被哪个事务加的锁 哪个事务在等待数据解锁 死锁但是使用锁会导致一种情况，2个事务永远在等待一块数据：在本图中： 事务A 给 数据1 加上排他锁并且等待获取数据2 事务B 给 数据2 加上排他锁并且等待获取数据1这叫死锁。 在死锁发生时，锁管理器要选择取消（回滚）一个事务，以便消除死锁。这可是个艰难的决定： 杀死数据修改量最少的事务（这样能减少回滚的成本）？ 杀死持续时间最短的事务 (因为其它事务的用户等的时间更长)？ 杀死能用更少时间结束的事务（避免可能的资源饥荒）？ 一旦发生回滚，有多少事务会受到回滚的影响？在作出选择之前，锁管理器需要检查是否有死锁存在。哈希表可以看作是个图表,图中出现循环就说明有死锁。由于检查循环是昂贵的（所有锁组成的图表是很庞大的），经常会通过简单的途径解决：使用超时设定。如果一个锁在超时时间内没有加上，那事务就进入死锁状态。 锁管理器也可以在加锁之前检查该锁会不会变成死锁，但是想要完美的做到这一点还是很昂贵的。因此这些预检经常设置一些基本规则。 两段锁：实现纯粹的隔离最简单的方法是：事务开始时获取锁，结束时释放锁。就是说，事务开始前必须等待确保自己能加上所有的锁，当事务结束时释放自己持有的锁。这是行得通的，但是为了等待所有的锁，大量的时间被浪费了。更快的方法是两段锁协议（Two-Phase Locking Protocol，由 DB2 和 SQL Server使用），在这里，事务分为两个阶段： 成长阶段：事务可以获得锁，但不能释放锁。 收缩阶段：事务可以释放锁（对于已经处理完而且不会再次处理的数据），但不能获得新锁。 这两条简单规则背后的原理是： 释放不再使用的锁，来降低其它事务的等待时间 防止发生这类情况：事务最初获得的数据，在事务开始后被修改，当事务重新读取该数据时发生不一致。 这个规则可以很好地工作，但有个例外：如果修改了一条数据、释放了关联的锁后，事务被取消（回滚），而另一个事务读到了修改后的值，但最后这个值却被回滚。为了避免这个问题，所有独占锁必须在事务结束时释放。 真实的数据库使用更复杂的系统，涉及到更多类型的锁（比如意向锁，intention locks）和更多的粒度（行级锁、页级锁、分区锁、表锁、表空间锁），但是道理是相同的。 我只探讨纯粹基于锁的方法，数据版本控制是解决这个问题的另一个方法。 版本控制是这样的： 每个事务可以在相同时刻修改相同的数据 每个事务有自己的数据拷贝（或者叫版本） 如果2个事务修改相同的数据，只接受一个修改，另一个将被拒绝，相关的事务回滚（或重新运行）这将提高性能，因为： 读事务不会阻塞写事务 写事务不会阻塞读 没有『臃肿缓慢』的锁管理器带来的额外开销除了两个事务写相同数据的时候，数据版本控制各个方面都比锁表现得更好。只不过，你很快就会发现磁盘空间消耗巨大。数据版本控制和锁机制是两种不同的见解：乐观锁和悲观锁。两者各有利弊，完全取决于使用场景（读多还是写多）。 Resource1.原文链接-link.2.版本控制-pdf.","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"长短流和多路径选择问题","slug":"长短流和多路径问题","date":"2017-10-11T12:48:39.929Z","updated":"2017-07-17T09:41:06.000Z","comments":true,"path":"2017/10/11/长短流和多路径问题/","link":"","permalink":"http://yoursite.com/2017/10/11/长短流和多路径问题/","excerpt":"","text":"针对虚拟机迁移场景，会导致流量中长流增加，长流易辨别，低开销且在路径规划中对长流的规划会对我们的vm migration的迁移时间大幅度减下，大约调研了一天主要分成两个部分。一个是多路径选择，一个是流量的动态分配。 数据中心流量分析数据中心流量在南北方向主要是用户访问，在东西方向时数据备份和数据迁移之类的，大约东西是南北的4倍左右，SDN之所以这么在DC中这么火，很大一个原因就是SDN对链路利用率，感知链路剩余带宽获取链路信息上有很大的便捷，甚至会专门划一个服务器用来作为信息推送（pull和push的方式是不一样的）。 SDN对上述链路信息的获取，大概常见方式也是两种，一个是定期抽样，一个是节点对之间的流量预测。实际上ECMP的性能从调研文章来看并不很优秀，现在的Hedra大约是ECMP的4倍效率，在vm完成分发的时间上。调研后发现ECMP这种静态方式，如果在链路差异大的的情况下，等价路由是会使效率极其低下。 等价路由协议传统的网络拓朴结构可以形象的表示为树结构，我们称之为“有中心的网络拓扑结构”，简单地认为很多流量请求最终会汇聚到主干网这样的路由中心，才能转发到下一条路径。 传统的路由协议都是采用单路径路由的方式，简单地认为，从源到目的，所有的包都通过一条路径转发（如果某条最优路径出现了问题，再考虑下一条最优路径），其它链路处于备份状态或无效状态，并且在动态路由环境下相互的切换需要一定时间。 现在问题来了： 1）主干网总有一天会承受不了过多的流量请求； 2）单一的路径路由会使很多路由路径处于相对空闲的状态。 那么一个解决问题的办法就产生了，使用多路径路由，因为路由器是有多个端口的，所以这样的路由方式在硬件上是有支持的。好处就是，在网络环境下同时使用多条链路，不仅增加了传输带宽，并且可以无时延无丢包地备份失效链路的数据传输。 多路径路由特点：（1）可以为不同的服务质量要求提供不同的路径。（2）多路可以为同一种类型的服务提供多条路径，经聚集可实现更高的服务质量。（3）由于主机对路径有自主的使用权，它可以通过探测各路径的状况（比如丢包率）猜测网络的拥塞程度，据此调整对各路径的使用，从而在得到优质服务的同时也提高了网络的利用率。因此，多路的正确使用还可以提高网络的利用率。 根据不相交性，多路径路由可以分为3种：节点不相交（Node-Disjoint）多路径、链路不相交（Link-Disjoint）多路径和相交多路径。节点不相交多路径，也称为完全不相关多路径，就是各条路径中除源节点和目的节点之外没有其他任何共用节点。链路不相交多路径是指各条路径间没有任何共用的链路，但有可能有共用的节点。相交多路径是指各条路径间既有共用的节点，又有共用的链路。表1是3种路径间的比较。 ECMP是指，到达一个目的地有多条相同度量值的路由项（路由路径），这样就可以使用不超过3条这样的路径来转发流量。ECMP最大的特点是实现了等值情况下，多路径负载均衡和链路备份的目的，在静态路由和OSPF中基本上都支持ECMP功能。 但是实际情况是，各路径的带宽、时延和可靠性等不一样，把Cost认可成一样，不能很好地利用带宽，尤其在路径间差异大时，效果会非常不理想。例如，路由器两个出口，两路径，一个带宽是100M，一个是2M，如果部署是ECMP，则网络总带宽只能达到4M的利用率。（在RFC2991中讨论了一般的多路径路由。每一封包多路径路由的负载平衡通常不适用因为大辐变化的延迟、数据包重新排序，以及可以破坏许多互联网协定运作的最大传输单元（MTU）在网络流量的差异，最特别是传输控制协议（TCP）和path MTU discovery。）另外一种情况下等价多路径路由也不能提供真正的最佳路径路由的优点，例如，如果多个最佳的next-hop的路径到目的地重新汇聚到一个单一的低带宽的路径（一种常见的情形）下游，它只会增加到该目的地流量路径的复杂性，而无法提高带宽的能力。 现在我比较担心的事ECMP在效果上未必会有那么好，可能要先把ECMP搭出来做一个判断，现有的GFF协议和Hedera看起来效果不错（搜索所有有效路径，发现带宽合适就转发，然后更新链路状态，）动态协议的优点这么明显，而之前不布置的原因是什么？ 比较好的消息长短流的选流算法和优先级调控就现在来看对虚拟机迁移是非常有效的。而且实验场景来看这篇清华的文章还是和我想的很相似。 流量动态分配（load balance）负载分担方式有3种。 基于流负载分担：路由器根据IP报文的五元组信息（是指源IP地址，源端口，目的IP地址，目的端口，和传输层协议这五个量组成的一个集合。 例如：192.168.1.1 10000 TCP 121.14.88.76 80 就构成了一个五元组）将数据分成不同的流。具有相同五元组信息的IP报文属于同一个流。转发数据时，路由器把不同的数据流根据算法从多个路径上依次发送出去。 基于包负载分担：转发数据时，路由器把数据包从多个路径上依次发送出去。 基于带宽的非平衡负载分担：报文按接口物理带宽进行负载分担(即基于报文的负载分担)。当用户为接口配置了指定的负载带宽后，设备将按用户指定的接口带宽进行负载分担，即根据各接口物理带宽比例关系进行分配。 基于包转发能够做到更精确的负载分担。但是由于路由器要对每一个包进行路由查表与转发操作，所以无法使用快速转发缓存来转发数据，转发效率降低了。另外，Internet应用都是基于流的，如果路由器采用基于包的负载分担，一条流中的数据包会经过不同路径到达目的地，可能会造成接收方的乱序接收，从而影响应用程序的正常运行。 现在看起来做个长短流的选流算法（长流预测）和选路混在一起也许在特定的vm场景下效果会不错。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"常用知识点","slug":"常用的知识点","date":"2017-10-11T12:48:39.925Z","updated":"2017-06-30T02:35:06.000Z","comments":true,"path":"2017/10/11/常用的知识点/","link":"","permalink":"http://yoursite.com/2017/10/11/常用的知识点/","excerpt":"","text":"这是从知乎贴出来的一个答案，但是感觉除了数据库我没怎么用过，其余也不是很难啊，难怪赞这么少，我这几天有空就把答案写一下。Mark～ 设计模式1.设计模式的六大原则2.常用的设计模式3.用一个设计模式写一段代码或画出一个设计模式的UML4.如何理解MVC5.高内聚，低耦合方面的理解 算法1.深度优先，广度优先算法2.排序算法以及对应的时间复杂度和空间复杂度3.写一个排序算法4.查找算法5.B+树和二叉树查找时间复杂度6.KMP算法、hash算法7.常用的hash算法8.如何判断一个单链表有环9.给你一万个数，如何找出所有重复的书，用你所有能想到的方法，时间复杂度和空间复杂度是多少10.给你一个数组如何找到和为k的两个数11.10000000个数怎么找到最大和最小的十个12.一堆数字里面继续去重，要怎么处理 数据结构1.队列，栈，链表，树，堆，图2.编码实现队列，栈 Linux1.Linux常用的命令2.如何查看内存使用情况3.Linux下如何进行进程调度 操作系统1.操作系统什么情况下会死锁2.产生死锁的必要条件3.死锁预防 数据库1.范式2.数据库事务隔离级别3.数据库连接池原理4.乐观锁和悲观锁5.如何实现不同数据库的数据分页查询6.SQL注入的原理，如何预防 数据库索引的实现(B+树介绍、和B树、R树区别) SQL性能优化 数据库索引的优缺点以及什么时候数据库索引失效10.Redis的存储结构 网络 OSI七层模型以及TCP/IP四层模型 HTTP和HTTPS区别 HTTP报文内容 get提交和post提交的区别 get提交是否有字节限制，如果有是在哪限制的 TCP的三次握手和四次挥手 session和cookie的区别 HTTP请求中Session实现原理 redirect与forward区别 DNS TCP和UDP区别","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"Xuanlong","slug":"XuanLong","date":"2017-10-11T12:48:39.923Z","updated":"2018-01-09T13:12:45.882Z","comments":true,"path":"2017/10/11/XuanLong/","link":"","permalink":"http://yoursite.com/2017/10/11/XuanLong/","excerpt":"","text":"Xuanlong Qin(秦宣龙)Master of Science, Candidate,Computer Science,School of Electronics &amp; Computer Engineering,Peking University (PKU) E-mail:&#113;&#120;&#108;&#x70;&#x6b;&#117;&#x40;&#x67;&#109;&#97;&#105;&#x6c;&#46;&#99;&#111;&#x6d;&#x78;&#x75;&#x61;&#x6e;&#x6c;&#111;&#x6e;&#103;&#x40;&#112;&#x6b;&#x75;&#46;&#101;&#100;&#x75;&#x2e;&#x63;&#x6e; - Please pay attention to case sensitive IntroductionHello,It seems that you are interested in my resume, I am a postgraduate student in computer science in Peking University and expect to receive master degree in 2018. My research interests include Network Congestion,VM live migration,Software-Defined Networking and basical Network Protocals (TCP,UDP,LLDP..etc) Education Peking University (PKU)– M.Sc. candidate in Computer Science– GPA: 87.13 / 100– Adviser: Dr. Li– Focus: Datacenter, VM migration, flow scheduling , congestion control ,etc. China University of Mining and Technology (CUMT)– B.E. in Electronic Enginnering– RANK: 7 / 150– Cumulative GPA: 81 / 100 National Tsing Hua University (NTHU)– Non-degree student (Exchange)– Computer Science and Information Engineering– Adviser: Dr. Huang– Focus: SDN, flow scheduling, openflow, etc. Publications JOURNALS [1] X. Qin, D. Li, “ High Speed Data Transport Technology for Datacenter Networks,” Computerengineering and Software, vol. 37, no. 9, pp. 1–8, Sep 2016. CONFERENCES [1] X. Qin, D. li, “High Speed Data Transport Technology for Datacenter Networks,” in NCCA 2016,Tangshan, Hebei, China, Apr 2016. [2] X. Qin, D. Li, C. Chen, and N. Huang “ Early Notification and Dynamic Routing: An ImprovedSDN-based Optimization Mechanism for VM Migration,” in CollaborateCom 2017, Edingurgh,UK, Dec 2017. Awards The first scholarship, Peking University Individual scholarships, China University of Mining and Technology The third scholarships, China University of Mining and Technology The Second Prize of Physics Olympic Additional Comments Dr. Li(Dagang Li)[DgLi-link].– Assistant Professor in Peking University– Postdoctorate, University of Leuven– Research Area: Communication systems and computer networks Laboratory: Center for Internet Research and Engineering (CIRE) 2015-2018 Dr. Huang(Nen-fu Huang)[NfHuang-link].– Distinguished Professor in Nation Tsing Hua University– PhD, Nation Tsing Hua University– Research Area: IoT Networks and Applications, MOOCs Learning Data Analysis, Network Security,SDN/NFV Network, High-performance Switches/Routers, Network Flow Classification Technologies Laboratory: High-Speed Networks Labtory (HSNL) April.2017-Oct.2017 Resouce VM live migration.[link]. Network Congestion.[link]. Software-defined networking.[link]. More details about me see Resume. Just feel free to contact me if you have any interests on my research ^_^.","categories":[],"tags":[{"name":"Personal","slug":"Personal","permalink":"http://yoursite.com/tags/Personal/"}]},{"title":"HPCC-Based_SDN的老板的审核意见及问题","slug":"vm_migration","date":"2017-10-11T12:48:39.918Z","updated":"2017-06-06T13:45:30.000Z","comments":true,"path":"2017/10/11/vm_migration/","link":"","permalink":"http://yoursite.com/2017/10/11/vm_migration/","excerpt":"","text":"昨晚收到老板的邮件，大约提出了两个问题，一个是关于sdn和传输层优化的问题，一个是host和simulation的问题，我觉得写下来，会给做科研的人一些思考。 1.sdn and the optimization of transport layer老板的意思是写文章要有中心点，但是我在北大做的这部分是偏向于tcp的传输优化，而在清华做的这部分是偏向于sdn做寻路部分。实际上分开来看，一个是传输层优化一个是链路层上的优化，所以这两个问题怎噩梦结合起来，所以比较幸运的是这个问题都是基于vm migration这个场景，而migration在总的停机时间上不会有太长的优化，所以看起来两边的效果是差不多的。－ 这个给我们的结论就是科研的点最好要聚焦在一点，而不是分到两个层，老板的意思这种做法基本上是上不了顶会，上c类还要看看人家给不给面子QAQ,那你让我拿ncca毕业我就不投了～真是。。。 2.host &amp; simulation这个问题就是因为现在做的是全仿真所以我们能在模拟器上看到问题，但是实际上仿真器时经过抽象的，那实际上究竟存不存在这个问题，这是一个伪命题的话而仿真器出现了，我们去解决它根本没有任何意义。但是其实我们之所以不做真机有一部分原因是真机的行为太复杂了，所以我们放到仿真里做，老板表示不要把真机和仿真作为一谈，如果过度抽象存在伪命题，那文章是无法服众的。－ 这个给我们的结论就是在模型上一定要进行验证和比对，如果出现了模型和真机不符合一定要去找问题，然后仿真和真机要控制在一个容错范围内。 针对这两个问题1.这个问题其实是没有办法的事情，要把两个实验室的东西集合起来，虽然都是网络实验室，但是实际上差别还是很大，北大主要是在做传出层优化，而清华这边的主要在拿sdn做vcpe来做实现，其实是很偏应用层了，所以只能把点放到虚拟机迁移时间的减少。 2.这个问题我在仿真器上有输出cwnd.tr的trace文件，发现在急剧掉包会出现在轮次时间点之后，所以在仿真器上是存在的，但是在真机上，我明天还要去找一下代码，到底buffer＝0后会有什么操作，会不会等到ack回来这个问题。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"广度优先遍历和深度优先遍历的实现以及二叉树用这两种方式遍历 -- Python","slug":"treeBFSDFS","date":"2017-10-11T12:48:39.914Z","updated":"2017-07-19T10:10:30.000Z","comments":true,"path":"2017/10/11/treeBFSDFS/","link":"","permalink":"http://yoursite.com/2017/10/11/treeBFSDFS/","excerpt":"","text":"DFS1.递归定义：假设给定图G的初态是所有顶点均未曾访问过。在G中任选一顶点v为初始出发点(源点)，则深度优先遍历可定义如下：首先访问出发点v，并将其标记为已访问过；然后依次从v出发搜索v的每个邻接点w。若w未曾访问过，则以w为新的出发点继续进行深度优先遍历，直至图中所有和源点v有路径相通的顶点(亦称为从源点可达的顶点)均已被访问为止。若此时图中仍有未访问的顶点，则另选一个尚未访问的顶点作为新的源点重复上述过程，直至图中所有顶点均已被访问为止。 图的深度优先遍历类似于树的前序遍历。采用的搜索方法的特点是尽可能先对纵深方向进行搜索。这种搜索方法称为深度优先搜索(Depth-First Search)。相应地，用此方法遍历图就很自然地称之为图的深度优先遍历 2.实现思想（1）访问顶点v；（2）从v的未被访问的邻接点中选取一个顶点w，从w出发进行深度优先遍历；（3）重复上述两步，直至图中所有和v有路径相通的顶点都被访问到。 3.代码实现12345678910111213def depth_first_search(self,root=None): order = [] def dfs(node): self.visited[node] = True //该点被访问过 order.append(node) for n in self.node_neighbors[node]: if not n in self.visited: dfs(n)//未访问过则递归调用dfs if root: dfs(root) for node in self.nodes(): if not node in self.visited: dfs(node) 具体代码会放到github里面。 BFS1.定义 图的广度优先遍历BFS算法是一个分层搜索的过程，和树的层序遍历算法类同，它也需要一个队列以保持遍历过的顶点顺序，以便按出队的顺序再去访问这些顶点的邻接顶点。 这个图是从一个视频里面截出来的，非常好！ 红线我标出来的就是搜索的顺序，以及在列表存放的位置。2.基本实现思想（1）顶点v入队列。（2）当队列非空时则继续执行，否则算法结束。（3）出队列取得队头顶点v；访问顶点v并标记顶点v已被访问。（4）查找顶点v的第一个邻接顶点col。（5）若v的邻接顶点col未被访问过的，则col入队列。（6）继续查找顶点v的另一个新的邻接顶点col，转到步骤（5）。（7）直到顶点v的所有未被访问过的邻接点处理完。转到步骤（2）。 广度优先遍历图是以顶点v为起始点，由近至远，依次访问和v有路径相通而且路径长度为1，2，……的顶点。为了使“先被访问顶点的邻接点”先于“后被访问顶点的邻接点”被访问，需设置队列存储访问的顶点。 3.代码实现1234567891011121314151617def breadth_first_search(self,root=None): queue = [] order = [] def bfs(): while len(queue)&gt; 0: node = queue.pop(0) //队列非空表示一定有节点，直接pop self.visited[node] = True for n in self.node_neighbors[node]: if (not n in self.visited) and (not n in queue): queue.append(n) order.append(n) if root: dfs(root) for node in self.nodes(): if node not in visited: dfs(node) //未访问的节点进行递归操作 代码也是放在github上 其实从整个代码逻辑上来看BFS和DFS不难写，怎么把图和节点放进去我不太会，所以看了好一阵，基础不扎实啊！主要是这个邻接节点怎么添加进去，可以看github. 广度优先/深度优先遍历二叉树这个逻辑和图是一样的，但是图比较复杂，因为树只有两个孩子，先是生成完全呢二叉树，然后再去进行递归实现。然后将结果放在列表里。这个博客写的挺详细二叉树的深度优先遍历、广度优先遍历和非递归遍历－link.前面也是关于生成二叉树，就不写了放在github里面，然后把算法部分写一下：BFS:123456789101112131415def breadth_tree(tree): lst = [] def traverse(node, p): if node._left is not None: lst.append(node._left) if node._right is not None: lst.append(node._right) if p &gt; (len(lst) -2): return else: traverse(lst[p+1], p+1) lst.append(tree._root) traverse(tree._root, 0) DFS:12345678910def depth_tree(tree): lst = [] lst.append(tree._root) while len(lst) &gt; 0: node = lst.pop() print node._data if node._right is not None: lst.append(node._right) if node._left is not None: lst.append(node._left) Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"面试题 -- Python","slug":"test","date":"2017-10-11T12:48:39.912Z","updated":"2017-07-21T04:12:32.000Z","comments":true,"path":"2017/10/11/test/","link":"","permalink":"http://yoursite.com/2017/10/11/test/","excerpt":"","text":"1.@staticmethod和@classmethod区别？@property是什么？这道题我知道是装饰器但是有什么区别我还真不知道，我就去查了一下。写一个类，里面包含了普通函数foo，clss_foo和static_foo12345678910111213class A(object): def foo(self,x): print &quot;exceting foo(%s,%s)&quot;%(self,x) @classmethod def class_foo(cls,x): print &quot;exceting foo(%s,%s)&quot;%(cls,x) @staticmethod def static_foo(x): print &quot;excuting static_foo(%s)&quot;%xa = A() a.foo(1) 对象实体调用方法，对象实体a被隐藏的传递给了第一个参数self.1&gt;&gt;&gt; exceting foo(&lt;test3.A object at 0x10a25a290&gt;,1) 用classmethods装饰,隐藏的传递给第一个参数的是对象实体的类(class A)而不是self.1&gt;&gt;&gt; exceting foo(&lt;class 'test3.A'&gt;,1) 你也可以用类调用class_foo.实际上,如果你把一些方法定义成classmethod,那么实际上你是希望用类来调用这个方法,而不是用这个类的实例来调用这个方法.这个时候你用A.class_foo(1)，是可以正常运行的。(因为classmethod就是用类来调用，而不是类的实例调用)1&gt;&gt;&gt; exceting foo(&lt;class 'test3.A'&gt;,1) 我们用直接用实例调用A.foo(1)是不行的。12&gt;&gt;&gt; TypeError: unbound method foo() must be called with A instance as first argument (got int instance instead)&gt;&gt;&gt; 这个错误就是说我们在调用实例的时候没有绑定 用staticmethods来装饰,不管传递给第一个参数的是self(对象实体)还是cls(类).它们的表现都一样:1234&gt;&gt;&gt; a.static_foo(1)&gt;&gt;&gt; excuting static_foo(1)&gt;&gt;&gt; A.static_foo(1)&gt;&gt;&gt; excuting static_foo(1) 静态方法被用来组织类之间有逻辑关系的函数. foo只是个函数,但是当你调用a.foo的时候你得到的不仅仅是一个函数,你得到的是一个第一个参数绑定到a的”加强版”函数.foo需要两个参数,而a.foo仅仅需要一个参数. 什么是绑定呢？我们输出一下参数！12345678910111213&gt;&gt;&gt; print a.foo&gt;&gt;&gt; print a.class_foo&gt;&gt;&gt; print a.static_foo# a绑定了foo. &gt;&gt;&gt; &lt;bound method A.foo of &lt;test3.A object at 0x1049a8290&gt;&gt;# A绑定到了class_foo而不是a.&gt;&gt;&gt; &lt;bound method type.class_foo of &lt;class 'test3.A'&gt;&gt;# a.static_foo只是返回一个不带参数绑定的方法.# static_foo和a.static_foo只需要一个参数.就是一个方法&gt;&gt;&gt; &lt;function static_foo at 0x10499bf50&gt; 2.Python可变类型有哪些我第一时间想起就是数字，字符串和元组(tuple)不可变，列表和字典是可变的。对不可变类型的变量重新赋值，实际上是重新创建一个不可变类型的对象，并将原来的变量重新指向新创建的对象（如果没有其他变量引用原有对象的话（即引用计数为0），原有对象就会被回收）。 这个也没啥好补充的 3.用numpy生成一个1-9的3*3的数组这个就直接调用内置函数就行，我做leetcode有一道就是把矩阵重新定向，里面有一个求除和求余的过程，但是用numpy的reshape()函数特别简单，所以记得比较清楚。1234567import numpy as npa = np.arange(1,10).reshape(3,3)print a&gt;&gt;&gt; [[1 2 3]&gt;&gt;&gt; [4 5 6]&gt;&gt;&gt; [7 8 9]] 4.如何判断一个字符串str的编码方式，打印出编码方式的名字这题我虽然不会，但是shangru之前帮我改一个代码的时候有提到字符编码导致编译不通过的问题，今天又被提起来就去查一下好了。查到一个博客讲字符编码笔记：ASCII，Unicode和UTF-8.str和unicode都是basestring的子类,所以有判断是否是字符串的方法12def is_str(s): return isinstance(s,basestring) str是字节串，由unicode经过编码(encode)后的字节组成的,unicode才是真正意义上的字符串，由字符组成判断是否是字符串方法如下：123456789&gt;&gt;&gt; isinstance(u'中文', unicode)True&gt;&gt;&gt; isinstance('中文', unicode)False&gt;&gt;&gt; isinstance('中文', str)True&gt;&gt;&gt; isinstance(u'中文', str)False 5.＊args和＊＊kwargs是什么意思，为什么要用他们？这个就是不知道参数的个数时候用的，*kwargs是传不确定的键值对的数量。但是具体为什么要用我也不知道啊。当你不确定你的函数里将要传递多少参数时你可以用args.例如,它可以传递任意数量的参数:12345678&gt;&gt;&gt; def print_everything(*args): for count, thing in enumerate(args):... print &apos;&#123;0&#125;. &#123;1&#125;&apos;.format(count, thing)...&gt;&gt;&gt; print_everything(&apos;apple&apos;, &apos;banana&apos;, &apos;cabbage&apos;)0. apple1. banana2. cabbage 相似的,**kwargs允许你使用没有事先定义的参数名:1234567&gt;&gt;&gt; def table_things(**kwargs):... for name, value in kwargs.items():... print &apos;&#123;0&#125; = &#123;1&#125;&apos;.format(name, value)...&gt;&gt;&gt; table_things(apple = &apos;fruit&apos;, cabbage = &apos;vegetable&apos;)cabbage = vegetableapple = fruit 你也可以混着用.命名参数首先获得参数值然后所有的其他参数都传递给args和*kwargs.命名参数在列表的最前端.例如:1def table_things(titlestring, **kwargs) ＊args和＊＊kwargs可以同时在函数的定义中,但是args必须在*kwargs前面.. 当调用函数时你也可以用和*语法.例如:123456&gt;&gt;&gt; def print_three_things(a, b, c):... print &apos;a = &#123;0&#125;, b = &#123;1&#125;, c = &#123;2&#125;&apos;.format(a,b,c)...&gt;&gt;&gt; mylist = [&apos;aardvark&apos;, &apos;baboon&apos;, &apos;cat&apos;]&gt;&gt;&gt; print_three_things(*mylist)a = aardvark, b = baboon, c = cat 就像你看到的一样,它可以传递列表(或者元组)的每一项并把它们解包.注意必须与它们在函数里的参数相吻合. 6.对一个字符串进行多次替换例如：给定sent = “1232gawg”,rep = {“1”:”a”,”2”,”b”,”3”:”c”}将sent进行rep替换，结果是”abcbagawg”这题不难啊，就是字符串替换啊。自己写的时候还写懵了，可能没睡醒。。。。代码有点冗余，把key和value拆开了。。我一定是个菜鸡，才写出这种菜鸡代码～～～～～123456789101112131415161718192021rep = &#123;&quot;1&quot;:&quot;a&quot;,&quot;2&quot;:&quot;b&quot;,&quot;3&quot;:&quot;c&quot;&#125;def Morechange(list1): key1 = [] value1 = [] for key, value in rep.items(): key1.append(key) value1.append(value) result = [] for i in list1: if i in key1: p = key1.index(i) #print p #print value1[p] result.append(value1[p]) else: result.append(i) print list(result)list1 = &quot;1232gwag&quot;Morechange(list1) 7.range和xrange的区别这个我倒是知道，因为当时看生成器的时候，知道range是产生一个列表要分配空间，但是xrange是一个生成器就是调用的时候返回一个值，大概是这样，我去查了一下网上的答案。range函数说明：range([start,] stop[, step])根据start与stop指定的范围以及step设定的步长，生成一个序列。xrange函数说明：用法与range完全相同，所不同的是生成的不是一个数组，而是一个生成器。 要生成很大的数字序列的时候，用xrange会比range性能优很多，因为不需要一上来就开辟一块很大的内存空间，这两个基本上都是在循环的时候用：1234for i in range(0, 100):print ifor i in xrange(0, 100):print i 这两个输出的结果都是一样的，实际上有很多不同，range会直接生成一个list对象：输出结果：123&gt;&gt;&gt; &lt;type 'list'&gt;&gt;&gt;&gt; [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]&gt;&gt;&gt; 0 1 而xrange则不会直接生成一个list，而是每次调用返回其中的一个值：1234a = xrange(0,100)print type(a)print aprint a[0], a[1] 输出结果：123&gt;&gt;&gt; &lt;type 'xrange'&gt;&gt;&gt;&gt; xrange(100)&gt;&gt;&gt; 0 1 所以xrange做循环的性能比range好，尤其是返回很大的时候，尽量用xrange吧，除非你是要返回一个列表。 8.copy和deepcopy区别描述：origin = [1,2,[3,4]]cop1 = copy.copy(origin)cop2 = copy.deepcopy(origin) 1.print cop1,cop2origin[2][0] = “hey!” 2.print cop1,cop2 这道题不查还真不知道，copy和deepcopy区别从python中copy与deepcopy的区别看python引用.copy拷贝一个对象，但是对象的属性还是引用原来的，deepcopy拷贝一个对象，把对象里面的属性也做了拷贝，deepcopy之后完全是另一个对象了. copy时可变类型和不可变类型也会影响结果！ 9.yield实现非波那契数列一个带有 yield 的函数就是一个 generator，它和普通函数不同，生成一个generator看起来像函数调用，但不会执行任何函数代码，直到对其调用 next()（在 for 循环中会自动调用 next()）才开始执行。虽然执行流程仍按函数的流程执行，但每执行到一个 yield语句就会中断，并返回一个迭代值，下次执行时从yield的下一个语句继续执行。看起来就好像一个函数在正常执行的过程中被yield中断了数次，每次中断都会通过 yield 返回当前的迭代值。yield 的好处是显而易见的，把一个函数改写为一个generator就获得了迭代能力，比起用类的实例保存状态来计算下一个 next()的值，不仅代码简洁，而且执行流程异常清晰。123456789def fab(max): n = 0 a = 0 b = 1 while n &lt; max: yield b #print b (a,b) = (b,a+b) n+=1 这个博客讲的不能再仔细了。Python yield 使用浅析-廖雪峰. 10.python的garbage collection机制python采用的是引用计数机制为主，标记-清除和分代收集两种机制为辅的策略引用计数机制：python里每一个东西都是对象，它们的核心就是一个结构体：PyObject1234 typedef struct_object &#123; int ob_refcnt; struct_typeobject *ob_type;&#125; PyObject; PyObject是每个对象必有的内容，其中ob_refcnt就是做为引用计数。当一个对象有新的引用时，它的ob_refcnt就会增加，当引用它的对象被删除，它的ob_refcnt就会减少.123456#define Py_INCREF(op) ((op)-&gt;ob_refcnt++) //增加计数#define Py_DECREF(op) \\ //减少计数 if (--(op)-&gt;ob_refcnt != 0) \\ ; \\ else \\ __Py_Dealloc((PyObject *)(op)) 当引用计数为0时，该对象生命就结束了。 引用计数机制的优点： 1.简单2.实时性：一旦没有引用，内存就直接释放了。不用像其他机制等到特定时机。实时性还带来一个好处：处理回收内存的时间分摊到了平时。 引用计数机制的缺点： 1.维护引用计数消耗资源2.循环引用1234list1 = []list2 = []list1.append(list2)list2.append(list1) list1与list2相互引用，如果不存在其他对象对它们的引用，list1与list2的引用计数也仍然为1，所占用的内存永远无法被回收，这将是致命的。对于如今的强大硬件，缺点1尚可接受，但是循环引用导致内存泄露，注定python还将引入新的回收机制。(标记清除和分代收集)资料收集全靠博客Python垃圾回收机制. 呼～总算做完了，得知尚儒也没收到华为的短信，也是一件很开心的事了，难兄难弟，一起打出GG！ 顺手看到一个大神博客贴上，万一以后要用，写的挺好的。Stackoverflow about Python.这个资源还可以的！","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"Test comment系统","slug":"test blog","date":"2017-10-11T12:48:39.907Z","updated":"2017-06-30T15:15:48.000Z","comments":true,"path":"2017/10/11/test blog/","link":"","permalink":"http://yoursite.com/2017/10/11/test blog/","excerpt":"","text":"要进入全文才能看到评论系统感觉不科学，要不要调一下web架构呢。蓝瘦 添加了一晚上的评论系统，使用 “多说 disqus”的评论系统，这个文件用来测试评论系统是否成功。评论系统输入：1.可以选择游客和自己邮箱评论两种方式。2.游客方式 可以自己键入自己的name，邮箱随便填写都行，但是需要满足邮箱格式，比如woshitiancai@gmai.com3.自己的邮箱评论会获得confirm邮件，费时费力不建议使用。 哈哈哈哈，yoho！！！！！测试后台：test/blog/hexoINFO Deploying: gitINFO Clearing .deploy_git folder…INFO Copying files from public folder…INFO Copying files from extend dirs…[master bc16cd8] Site updated: 2017-06-30 22:50:39 59 files changed, 1605 insertions(+), 716 deletions(-) create mode 100644 2017/06/30/test blog/index.html rewrite content.json (97%)To https://github.com/XuanlongQ/XuanlongQ.github.io.git 9b35f86..bc16cd8 HEAD -&gt; masterBranch master set up to track remote branch master from https://github.com/XuanlongQ/XuanlongQ.github.io.git. 后台没啥问题，测试一下前端。 测试前端：this is a comment test要进文章才能评论。 眼睛要瞎了，学到一句话：1记得每天都要拉开窗帘 不然会觉得与世隔绝 渐渐封闭 听起来就很孤独，答主你要学会取悦自己啊。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"TCP三次握手和四次挥手行为","slug":"tcphandsip","date":"2017-10-11T12:48:39.905Z","updated":"2017-07-25T14:28:36.000Z","comments":true,"path":"2017/10/11/tcphandsip/","link":"","permalink":"http://yoursite.com/2017/10/11/tcphandsip/","excerpt":"","text":"TCP的报文格式如下图：比较重要的字段有：1.序列号：Seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。2.确认序号：ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，ack=Seq+1。3.标志位：有6个，URG、ACK、PSH、RST、SYN、FIN。 URG：紧急指针（urgent pointer）有效。 ACK：确认序号有效。这个ACK是标志位，ack是确认的序列号不一样！ PSH：接收方应该尽快将这个报文交给应用层。 RST：重置连接。 SYN：发起一个新连接。 FIN：释放一个连接。 important:1.不要将确认序号Ack与标志位中的ACK搞混了。2.确认方ack=发起方Seq+1，两端配对。 三次握手所谓三次握手（Three-Way Handshake）即建立TCP连接，就是指建立一个TCP连接时，需要客户端和服务端总共发送3个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发，整个流程如下图所示：（1）第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。（2）第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。（3）第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 SYN攻击：在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行：1# netstat -nap | grep SYN_RECV 四次握手四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发，整个流程如下图所示：由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭，上图描述的即是如此。（1）第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。（2）第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。（3）第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。（4）第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。上面是一方主动关闭，另一方被动关闭的情况，实际中还会出现同时发起主动关闭的情况，具体流程如下图： 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送。 PostMessage(异步)和SendMessage(同步)的区别1.PostMessage只把消息放入队列，不管其他程序是否处理都返回，然后继续执行，这是个异步消息投放函数。而SendMessage必须等待其他程序处理消息完了之后才返回，继续执行，这是个同步消息投放函数。而且，PostMessage的返回值表示PostMessage函数执行是否正确；而SendMessage的返回值表示其他程序处理消息后的返回值。2.同一个线程内：SendMessage发送消息时，由USER32.DLL模块调用目标窗口的消息处理程序，并将结果返回，SendMessage 在同一个线程里面发送消息不进入线程消息队列；PostMessage发送的消息要先放到消息队列，然后通过消息循环分派到目标窗口（DispatchMessage）。3.不同线程：SendMessage 发送消息到目标窗口的消息队列，然后发送消息的线程在USER32.DLL模块内监视和等待消息的处理结果，直到目标窗口的才处理返回，SendMessage在返回之前还需要做许多工作，如响应别的线程向它发送的SendMessage().PostMessge() 到别的线程的时候最好使用PostThreadMessage 代替。PostMessage()的HWND 参数可以为NULL，相当于PostThreadMessage() + GetCrrentThreadId.SendMessage函数功能：该函数将指定的消息发送到一个或多个窗口。此函数为指定的窗口调用窗口程序，直到窗口程序处理完消息再返回，是同步消息投放函数。而函数PostMessage不同，将一个消息寄送到一个线程的消息队列后立即返回，是异步消息投放函数。具体参考的blog为PostMessage(异步)和SendMessage(同步)的区别.","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"Switching Hub--real work","slug":"switching hub","date":"2017-10-11T12:48:39.894Z","updated":"2017-06-28T11:01:58.000Z","comments":true,"path":"2017/10/11/switching hub/","link":"","permalink":"http://yoursite.com/2017/10/11/switching hub/","excerpt":"","text":"想了很久决定新划一个版面出来。所有实验环境基于如下： linux 14.04+Ryu+pica8+openflow1.3+python(3.6)今天主要是看了一个最基本的switch的flood和match，以及和controller交互。 Switching Hub首先看一下简单的交换机具备的基本功能 连接到端口的host的MAC地址，并记录在MAC表中 对于已经记录的MAC地址，若是收到送往改MAC地址的封包，则转送改封包到相应的port。 对于未制定目标地址的封包就执行flooding 这个模型其实就是switch_simple_13.py 看起来基本上时调用和导入模块，实际上很多模块里面的功能我都不知道，还好奕衔他们说出了常用模块，基本都是现查，感觉还是有点难度的。 opendlow实作交换机Openflow交换机会收到来自ryu的指令并完成以下功能。 对收到的封包进行修改或者针对指定的端口进行转发 对于收到的封包传到Controller的action.(Packet-In)，一般都是不能识别的包才会Packet—In吧。 对于来自controller的封包转送到指定的port.(Packet-Out).把这些组合起来就是一个完整的交换机功能。 对于一个新的交换机，里面的mac table，flow table,都是空的，所以无论什么流进来他都无法识别，所以Packet－In这个时候就充当了学习的功能。对封包分析获得host的mac之类的操作。在学习之后，对所收到的封包进行转送，将封包的dst address在已经学习的host资料中进行检索，根据检索的结果进行处理：1.如果纪录存在，packet-out至对应的port。2.纪录不存在，pactet-out，flooding，这就是正常网络的操作，不过这样相当于把信息全部存在了controller里面了而已。 代码常用模块分析这个种东西我应该只会写一次，因为是最基本的模块，一定要扎实，具体的代码还是会po到github，或者你直接去ryu/app/simple_switch_13.py里面自己看。主要分为以下几个模块。 类别的定义和初始化首先实作Ryu一定要继承app_manager.RyuApp,为了使用openflow-1.3,指定version没毛病。123456class SimpleSwitch13(app_manager.RyuApp): OFP_VERSION = [ofproto_v1.3.OFP_VERSION] \"\"\"docstring for SimpleSwitch13\"\"\" def __init__(self, *arg,**kwargs): super(SimpleSwitch13, self).__init__(*args,**kwargs) self.mac_to_port = &#123;&#125; MAC的地址表由mac_to_port定义。 事件管理(Event Handler)对于Ryu来说，接受到任何一个openflow讯息即会产生一个相对应的事件，而Ryu必须实作事件管理来处理相对应发生的事件。事件管理有一个Event Object作为参数，并且使用set_ev_cls的装饰器函数。set_ev_cls：指定事件类别得以接受信息和交换机状态作为参数 事件类别的命名规则：ryu.controller.ofp_event.EventOFP + 比如packet-in信息的状态下事件的名称就是EventOFPPacketIn.交换机状态如下：名称 说明ryu.controller.handler.HANDSHAKE_DISPATCHER “交换 HELLO 信息” //就是握手协议ryu.controller.handler.CONFIG_DISPATCHER 接收 SwitchFeatures 信息ryu.controller.handler.MAIN_DISPATCHER 一般状态ryu.controller.handler.DEAD_DISPATCHER 连线中断 新增Table-miss Flow Entryopenflow交换机的握手协议完成之后，新增table-miss flow 进到flow table中为接收packet-in信息做准备。(具体来说接收到switch features(fetures reply)信息后就会新增table-miss flow entry)123456@set_ev_cls(ofp_event.EventOFPSwitchFeatures,CONFIG_DISPATCHER)def switch_features_handler(self,ev): datapath = ev.msg.datapath ofproto = datapath.ofproto parser = datapath.ofproto_parser ... ev.msg用来存储openflow信息实体datapath类别用来处理openflow交换器重要的信息，例如执行与交换机的通信和触发接受讯息相关的事件。123math = parser.OFPMatch() actions = [parser.OFPActionOutput(ofproto.OFPP_CONTROLLER,ofproto.OFPCML_NO_BUFFER)] self.add_flow(datapath,0,match,actions) Table-miss Flow Entry 的优先级 0 即最低的优先级,而且此 Entry 可以 match 所有的封包。 这个 Entry 的 Instruction 通常指定为 output action ,並且输出的端口将指向Controller。因此当封包沒有 match 任何一個普通 Flow Entry 時,则触发 Packet-In。空的 match 将被产生为了 match 所有的封包。match 表示在 OFPMatch 类別中。接下來,为了转送到 Controller 连接点,OUTPUT action 类別(OFPActionOutput )的实例将会 被产生。Controller 会被指定为封包的目的地,OFPCML_NO_BUFFER 会被设定为 max_len 以便接 下來的封包传送。 最后将优先级设为 0(最低优先级),然后执行 add_flow() 方法以发送 Flow Mod 信息。 Packet-in信息为了接收处理未知目的地的封包，需要packet-in事件管理。123456@set_ev_cls(ofp_event.EventOFPPacketIn,MAIN_DISPATCHER)def _packet_in_handler(self,ev): msg = ev.msg datapath = msg.datapath ofproto = datapath.ofproto parser = datapath.ofproto_parser OFPPacketIn类别常使用的属性有：match,data,total_len,buffer_id(这个书上说如果存在Openflow交换器上所指定的ID如果在没有buffer的状况下，则缺省为ryu.ofproto.ofproto_v1_3.OFP_NO_BUFFER) 更新MAC表和判断封包的连接点其实这个章节反而没什么说的，就是按照实例和逻辑输出。这个直接看代码就行 新增Flow Entry的处理Packet-In handler 的处理尚未说明,先來看一看新增 Flow Entry 的方法。1234def add_flow(self,datapath,priority,match,actions): ofproto = datapath.ofproto parser = datapath.ofproto_parser inst = [parser.OFPInstructionActions(ofproto.OFPIT_APPLY_ACTIONS,actions)] 对于 Flow Entry 来说,设定 match 条件以分辨目标封包、设定 instruction 来处理封包以及 Entry 的优先级和有效时间。对于交换机的实操,Apply Actions 是用來设定那些必须立即执行的 action 所使用。最后通过 Flow Mod 信息將 Flow Entry 新增到 Flow table 中。12345def add_flow(self,datapath,priority,match,actions): ... mod = parser.gOFPFlowMod(datapath = datapath,priority = priority,match = match,instructions = inst) datapath.send_msg(mod) Flow Mod 信息的类别为 OFPFlowMod 。使用 OFPFlowMod 所产生的实体通过 Datap- ath.send_msg() 方法來发送信息给 OpenFlow 交换机。OFPFlowMod 类別构建的子参数非常多，大多数都有缺省值，这个就需要自己去源码里查询了。 转发封包回到 Packet-In handler 并说明转发封包的最后一步。在 MAC 位址表中寻找目的 MAC 位址,若是有找到则发送 Packet-Out 信息,並且转发封包。12345678910def _packet_in_handler(self, ev): ... data = None # if msg.buffer_id == ofproto.OFP_NO_BUFFER: data = msg.data out = parser.OFPPacketOut(datapath=datapath,buffer_id = msg.buffer_id,in_port = in_port,actions = actions,data = data) datapath.send_msg(out) Packet-Out 信息对应的类别是 OFPPacketOut，同样 OFPPacketOut 的子函数及初始化的值需要自己去查找。 后面的博客就不会分析的这么仔细了，毕竟一个一个字敲太累了，后面主要会讲一些project和sdn实操，具体的代码我就自己看就不分析了。吃饭，累～ Resource代码还是会扔到[Github-link].example_switch_13.py","categories":[],"tags":[{"name":"sdn","slug":"sdn","permalink":"http://yoursite.com/tags/sdn/"}]},{"title":"Ryu交换机分析，详细类的继承","slug":"switch13","date":"2017-10-11T12:48:39.889Z","updated":"2017-07-03T09:22:08.000Z","comments":true,"path":"2017/10/11/switch13/","link":"","permalink":"http://yoursite.com/2017/10/11/switch13/","excerpt":"","text":"可以对着switch13.py那个官方入门例子来比对一下，里面的add_flow只有一部分，只看这篇blog可能会晕123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103from ryu.base import app_managerfrom ryu.controller import ofp_eventfrom ryu.controller.handler import CONFIG_DISPATCHER , MAIN_DISPATCHERfrom ryu.controller.handler import set_ev_clsfrom ryu.ofproto import ofproto_v1_3from ryu.lib.packet import packetfrom ryu.lib.packet import ethernetclass SimpleSwitch13(app_manager.RyuApp): OFP_VERSIONS = [ofproto_v1_3.OFP_VERSION] \"\"\"docstring for SimpleSwitch13\"\"\" def __init__(self, *arg, **kwargs): super(SimpleSwitch13, self).__init__(*args,**kwargs) self.mac_to_port = &#123;&#125; # mac地址表现自刚开始的时候是空的 # set_ev_cls(事件类别，交换器状态) (EventOFP+&lt;Openflow讯息名称&gt;) @set_ev_cls(ofp_event.EventOFPSwitchFeatures , CONFIG_DISPATCHER) def switch_features_handler(self,ev): # ev.msg用来存储对应事件的oprnflow信息实体，在这里就是ryu.ofproto.ofproto_v1_3_parser.OFPSwitchFeatures # msg.datapath 用来存储OF交换机的ryu.controller.controller.Datapath类的对应的实体 # datapath 处理OF交换机重要的讯息，例如执行与交换器的通讯和触发接收讯息相关的事件 datapath = ev.msg.datapath ofproto = datapath.ofproto parser = datapath.ofproto_parser # ofproto 表示使用的 OpenFlow 版本所对应的 ofproto module # ofproto_parser 和 ofproto 一樣，表示 ofproto_parser module # 交换器本身不仅仅使用switch feature 信息，还使用事件处理以取得新增table-miss flow entry的时间点。 def switch_features_handler(self , ev): match = parser.OFPMatch() #空的match将被产生，为了match所有封包，match表示在OFPMatch类别中 # 為了轉送到 Controller 連接埠，OUTPUT action 類別（ OFPActionOutput ）的实例將会 被产生。Controller 会被指定为封包的目的地，OFPCML_NO_BUFFER 会被设定为 max_len 以便接 下來的封包傳送。 actions = [parser.OFPActionOutput(ofproto.OFPP_CONTROLLER ,ofproto.OFPCML_NO_BUFFER)] self.add_flow(datapath , 0, match , actions) #跳转到add_flow()发送 Flow Mod 信息 def add_flow(self,datapath,priority,match,actions): ofproto = datapath.ofproto parser = datapath.ofproto_parser inst = [parser.OFPInstructionActions(ofproto.OFPIT_APPLY_ACTIONS,actions)] #对于flow entry来说，设定match条件以分辨目标封包，设定instruction以处理封包以及Entry的优先权和有效时间 #对于交换机的实作，Apply Actions是用来设定那些必须立即执行的action所使用。 #最后通过flow mod信息将flow entry新增到flow table中。 # def add_flow(self,datapath,port,dst,actions): # mod = parser.OFPFlowMod(datapath=datapath , priority=priority ,match=match , instructions=inst) # datapath.send_msg(mod) #Flow Mod 信息的类别为OFPFlow Mod,使用OFPFlowMod所产生的实体通过datapath.send_msg()方法来发送信息给OF交换机 #OFPFlowMod类的子函数很多，大多都有预设值，源码中括号内的部分就是预设值 #比如有：datapath cookie(0) cookie_mask(0) table_id (0) command (ofproto_v1_3.OFPFC_ADD) idle_timeout (0) # hard_timeout (0) priority (0) buffer_id (ofproto_v1_3.OFP_NO_BUFFER) out_port (0) out_group (0) flags (0) # match (None) instructions ([]) @set_ev_cls(ofp_event.EventOFPPacketIn , MAIN_DISPATCHER) #为了接收处理未知目的地的封包，需要packet-in事件管理 def _packet_in_handler(self , ev): msg = ev.msg datapath = msg.datapath ofproto = datapath.ofproto parser = datapath.ofproto_parser def _packet_in_handler(self , ev): # ... in_port = msg.match['in_port']#从 OFPPacketIn 类別的 match 得到接收点（ in_port ）的信息。 pkt = packet.Packet(msg.data) eth = pkt.get_protocols(ethernet.ethernet)[0] # 目的 MAC 位址和來源 MAC 位址使用 Ryu 的封包函式库，从接收到封包的 Ethernet header 取得。 dst = eth.dst src = eth.src dpid = datapath.id # 得知目的 MAC 位址和來源 Mac 位址，更新 MAC 位址表 self.mac_to_port.setdefault(dpid , &#123;&#125;) self.logger.info(\"packet in %s %s %s %s\", dpid , src, dst, in_port) # learn a mac address to avoid FLOOD next time. self.mac_to_port[dpid][src] = in_port # ... def _packet_in_handler(self , ev): # ... if dst in self.mac_to_port[dpid]: out_port = self.mac_to_port[dpid][dst] else: out_port = ofproto.OFPP_FLOOD actions = [parser.OFPActionOutput(out_port)] # install a flow to avoid packet_in next time if out_port != ofproto.OFPP_FLOOD: match = parser.OFPMatch(in_port=in_port , eth_dst=dst) self.add_flow(datapath , 1, match , actions) # ... def _packet_in_handler(self,ev): data = None if msg.buffer_id == ofproto.OFP_NO_BUFFER: data = msg.data out = parser.OFPPacketOut(datapath=datapath , buffer_id=msg.buffer_id , in_port=in_port , actions=actions , data=data) datapath.send_msg(out) Packet-Out 信息对应的类别是 OFPPacketOut OFPPacketOut 的子函数有：datapath buffer_id in_port actions data 交换机的实作时，在 Packet-In 信息中指定 buffer_id。若是 Packet-In 信息中 buffer_id 被设定为无效时。Packet-In 的封包必须指定 data 以便传送。","categories":[],"tags":[{"name":"sdn","slug":"sdn","permalink":"http://yoursite.com/tags/sdn/"}]},{"title":"用栈实现递归--Python","slug":"stack_test","date":"2017-10-11T12:48:39.887Z","updated":"2017-07-07T03:59:06.000Z","comments":true,"path":"2017/10/11/stack_test/","link":"","permalink":"http://yoursite.com/2017/10/11/stack_test/","excerpt":"","text":"这个还蛮有意思，有时候需要转变一下思维，慢慢靠近计算机思维。 递归用递归的方法来进行进制的转换，然后数字输出字符。12345678910111213import Stackr_stack = Stack()def to_str(n,base): convert_str = '0123456789ABCDEF' if n &lt; base: r_stack.push(convert_str[n]) else: r_stack.push(convert_str[n%base]) n = n //base res = \" \" while not r_stack.isempty(): res = res + str(r_stack.pop()) return res print (to_str(1453,16)) 重要的不是代码，是思想。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"网络编程/TCP编程/UDP编程--Python","slug":"socket","date":"2017-10-11T12:48:39.883Z","updated":"2017-07-23T14:29:04.000Z","comments":true,"path":"2017/10/11/socket/","link":"","permalink":"http://yoursite.com/2017/10/11/socket/","excerpt":"","text":"网络编程为了把全世界的所有不同类型的计算机都连接起来，就必须规定一套全球通用的协议，为了实现互联网这个目标，互联网协议簇（Internet Protocol Suite）就是通用协议标准。Internet是由inter和net两个单词组合起来的，原意就是连接“网络”的网络，有了Internet，任何私有网络，只要支持这个协议，就可以联入互联网。 因为互联网协议包含了上百种协议标准，但是最重要的两个协议是TCP和IP协议，所以，大家把互联网的协议简称TCP/IP协议。 通信的时候，双方必须知道对方的标识，好比发邮件必须知道对方的邮件地址。互联网上每个计算机的唯一标识就是IP地址，类似123.123.123.123。如果一台计算机同时接入到两个或更多的网络，比如路由器，它就会有两个或多个IP地址，所以，IP地址对应的实际上是计算机的网络接口，通常是网卡。 IP协议负责把数据从一台计算机通过网络发送到另一台计算机。数据被分割成一小块一小块，然后通过IP包发送出去。由于互联网链路复杂，两台计算机之间经常有多条线路，因此，路由器就负责决定如何把一个IP包转发出去。IP包的特点是按块发送，途径多个路由，但不保证能到达，也不保证顺序到达。 TCP协议则是建立在IP协议之上的。TCP协议负责在两台计算机之间建立可靠连接，保证数据包按顺序到达。TCP协议会通过握手建立连接，然后，对每个IP包编号，确保对方按顺序收到，如果包丢掉了，就自动重发。 许多常用的更高级的协议都是建立在TCP协议基础上的，比如用于浏览器的HTTP协议、发送邮件的SMTP协议等。 一个IP包除了包含要传输的数据外，还包含源IP地址和目标IP地址，源端口和目标端口。 端口有什么作用？在两台计算机通信时，只发IP地址是不够的，因为同一台计算机上跑着多个网络程序。一个IP包来了之后，到底是交给浏览器还是QQ，就需要端口号来区分。每个网络程序都向操作系统申请唯一的端口号，这样，两个进程在两台计算机之间建立网络连接就需要各自的IP地址和各自的端口号。 一个进程也可能同时与多个计算机建立链接，因此它会申请很多端口。 TCP编程Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。 客户端大多数连接都是可靠的TCP连接。创建TCP连接时，主动发起连接的叫客户端，被动响应连接的叫服务器。举个例子，当我们在浏览器中访问新浪时，我们自己的计算机就是客户端，浏览器会主动向新浪的服务器发起连接。如果一切顺利，新浪的服务器接受了我们的连接，一个TCP连接就建立起来的，后面的通信就是发送网页内容了。所以，我们要创建一个基于TCP连接的Socket，可以这样做：123456# 导入socket库:import socket# 创建一个socket:s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 建立连接:s.connect((&apos;www.sina.com.cn&apos;, 80)) 创建Socket时，AF_INET指定使用IPv4协议，如果要用更先进的IPv6，就指定为AF_INET6。SOCK_STREAM指定使用面向流的TCP协议，这样，一个Socket对象就创建成功，但是还没有建立连接。 客户端要主动发起TCP连接，必须知道服务器的IP地址和端口号。新浪网站的IP地址可以用域名www.sina.com.cn自动转换到IP地址，但是怎么知道新浪服务器的端口号呢？ 答案是作为服务器，提供什么样的服务，端口号就必须固定下来。由于我们想要访问网页，因此新浪提供网页服务的服务器必须把端口号固定在80端口，因为80端口是Web服务的标准端口。其他服务都有对应的标准端口号，例如SMTP服务是25端口，FTP服务是21端口，等等。端口号小于1024的是Internet标准服务的端口，端口号大于1024的，可以任意使用。 因此，我们连接新浪服务器的代码如下：1s.connect((&apos;www.sina.com.cn&apos;, 80)) 注意参数是一个tuple，包含地址和端口号。建立TCP连接后，我们就可以向新浪服务器发送请求，要求返回首页的内容：12# 发送数据:s.send(&apos;GET / HTTP/1.1\\r\\nHost: www.sina.com.cn\\r\\nConnection: close\\r\\n\\r\\n&apos;) TCP连接创建的是双向通道，双方都可以同时给对方发数据。但是谁先发谁后发，怎么协调，要根据具体的协议来决定。例如，HTTP协议规定客户端必须先发请求给服务器，服务器收到后才发数据给客户端。发送的文本格式必须符合HTTP标准，如果格式没问题，接下来就可以接收新浪服务器返回的数据了：12345678910# 接收数据:buffer = []while True: # 每次最多接收1k字节: d = s.recv(1024) if d: buffer.append(d) else: breakdata = &apos;&apos;.join(buffer) 接收数据时，调用recv(max)方法，一次最多接收指定的字节数，因此，在一个while循环中反复接收，直到recv()返回空数据，表示接收完毕，退出循环。当我们接收完数据后，调用close()方法关闭Socket，这样，一次完整的网络通信就结束了：12# 关闭连接:s.close() 接收到的数据包括HTTP头和网页本身，我们只需要把HTTP头和网页分离一下，把HTTP头打印出来，网页内容保存到文件：12345header, html = data.split(&apos;\\r\\n\\r\\n&apos;, 1)print header# 把接收的数据写入文件:with open(&apos;sina.html&apos;, &apos;wb&apos;) as f: f.write(html) 现在，只需要在浏览器中打开这个sina.html文件，就可以看到新浪的首页了。 服务器和客户端编程相比，服务器编程就要复杂一些。服务器进程首先要绑定一个端口并监听来自其他客户端的连接。如果某个客户端连接过来了，服务器就与该客户端建立Socket连接，随后的通信就靠这个Socket连接了。所以，服务器会打开固定端口（比如80）监听，每来一个客户端连接，就创建该Socket连接。由于服务器会有大量来自客户端的连接，所以，服务器要能够区分一个Socket连接是和哪个客户端绑定的。一个Socket依赖4项：服务器地址、服务器端口、客户端地址、客户端端口来唯一确定一个Socket。但是服务器还需要同时响应多个客户端的请求，所以，每个连接都需要一个新的进程或者新的线程来处理，否则，服务器一次就只能服务一个客户端了。我们来编写一个简单的服务器程序，它接收客户端连接，把客户端发过来的字符串加上Hello再发回去。首先，创建一个基于IPv4和TCP协议的Socket：1s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) 然后，我们要绑定监听的地址和端口。服务器可能有多块网卡，可以绑定到某一块网卡的IP地址上，也可以用0.0.0.0绑定到所有的网络地址，还可以用127.0.0.1绑定到本机地址。127.0.0.1是一个特殊的IP地址，表示本机地址，如果绑定到这个地址，客户端必须同时在本机运行才能连接，也就是说，外部的计算机无法连接进来。端口号需要预先指定。因为我们写的这个服务不是标准服务，所以用9999这个端口号。请注意，小于1024的端口号必须要有管理员权限才能绑定：12# 监听端口:s.bind((&apos;127.0.0.1&apos;, 9999)) 紧接着，调用listen()方法开始监听端口，传入的参数指定等待连接的最大数量：12s.listen(5)print &apos;Waiting for connection...&apos; 接下来，服务器程序通过一个永久循环来接受来自客户端的连接，accept()会等待并返回一个客户端的连接:123456while True: # 接受一个新连接: sock, addr = s.accept() # 创建新线程来处理TCP连接: t = threading.Thread(target=tcplink, args=(sock, addr)) t.start() 每个连接都必须创建新线程（或进程）来处理，否则，单线程在处理连接的过程中，无法接受其他客户端的连接：1234567891011def tcplink(sock, addr): print &apos;Accept new connection from %s:%s...&apos; % addr sock.send(&apos;Welcome!&apos;) while True: data = sock.recv(1024) time.sleep(1) if data == &apos;exit&apos; or not data: break sock.send(&apos;Hello, %s!&apos; % data) sock.close() print &apos;Connection from %s:%s closed.&apos; % addr 连接建立后，服务器首先发一条欢迎消息，然后等待客户端数据，并加上Hello再发送给客户端。如果客户端发送了exit字符串，就直接关闭连接。 要测试这个服务器程序，我们还需要编写一个客户端程序：1234567891011s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 建立连接:s.connect((&apos;127.0.0.1&apos;, 9999))# 接收欢迎消息:print s.recv(1024)for data in [&apos;Michael&apos;, &apos;Tracy&apos;, &apos;Sarah&apos;]: # 发送数据: s.send(data) print s.recv(1024)s.send(&apos;exit&apos;)s.close() 实现代码我自己照着敲了一遍，仍在github里面。 UDP编程TCP是建立可靠连接，并且通信双方都可以以流的形式发送数据。相对TCP，UDP则是面向无连接的协议。 使用UDP协议时，不需要建立连接，只需要知道对方的IP地址和端口号，就可以直接发数据包。但是，能不能到达就不知道了。 虽然用UDP传输数据不可靠，但它的优点是和TCP比，速度快，对于不要求可靠到达的数据，就可以使用UDP协议。 我们来看看如何通过UDP协议传输数据。和TCP类似，使用UDP的通信双方也分为客户端和服务器。服务器首先需要绑定端口：123s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)# 绑定端口:s.bind((&apos;127.0.0.1&apos;, 9999)) 创建Socket时，SOCK_DGRAM指定了这个Socket的类型是UDP。绑定端口和TCP一样，但是不需要调用listen()方法，而是直接接收来自任何客户端的数据：123456print &apos;Bind UDP on 9999...&apos;while True: # 接收数据: data, addr = s.recvfrom(1024) print &apos;Received from %s:%s.&apos; % addr s.sendto(&apos;Hello, %s!&apos; % data, addr) recvfrom()方法返回数据和客户端的地址与端口，这样，服务器收到数据后，直接调用sendto()就可以把数据用UDP发给客户端。注意这里省掉了多线程，因为这个例子很简单。客户端使用UDP时，首先仍然创建基于UDP的Socket，然后，不需要调用connect()，直接通过sendto()给服务器发数据：1234567s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)for data in [&apos;Michael&apos;, &apos;Tracy&apos;, &apos;Sarah&apos;]: # 发送数据: s.sendto(data, (&apos;127.0.0.1&apos;, 9999)) # 接收数据: print s.recv(1024)s.close() 从服务器接收数据仍然调用recv()方法。 UDP的使用与TCP类似，但是不需要建立连接。此外，服务器绑定UDP端口和TCP端口互不冲突，也就是说，UDP的9999端口与TCP的9999端口可以各自绑定。 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"Simulator vs Emulator","slug":"sim_emu","date":"2017-10-11T12:48:39.878Z","updated":"2017-06-06T08:31:34.000Z","comments":true,"path":"2017/10/11/sim_emu/","link":"","permalink":"http://yoursite.com/2017/10/11/sim_emu/","excerpt":"","text":"先看一下stackoverflow的人怎么看待这个问题，下面是最高票答案Q：Simulator or Emulator? What is the difference? A： Emulation is the process of mimicking the outwardly observable behavior to match an existing target. The internal state of the emulation mechanism does not have to accurately reflect the internal state of the target which it is emulating. Simulation, on the other hand, involves modeling the underlying state of the target. The end result of a good simulation is that the simulation model will emulate the target which it is simulating. 好，看起来土著们说的话比较晦涩难懂，我个人理解如下，可能是错的，其实这两个东西确实没有什么明显的分界线，一般来说我们说simulator主要是指仿真，就是把真实环境的东西做成一个只有参数的模型仿真到我们的模拟器上，比如说我们常说的ns2（network simulation 2），译过来就是网络仿真器，但是说这两个没什么明显的界限是因为很多simulation中是包含emulator模块，比如说我们常说的ns3(network simulation 3)其中就包含emulator模块，说了这么多什么是emulator在我看来就是真实的模拟环境，比如说你做sdn需要openflow交换机，如果你单纯用ovs去仿真那你就是simulation，如果你接上真实的openflow白盒交换机那就是emulator.接下来我们比对一下NS2,NS3和Estinet,我们的场景就放在based-sdn的vm migration下去说： ns2ns2就是个纯simulation，因为所有的模块都是抽象化的，本来我想贴ppt的但是现在已经九点半了，我还要去找Q聊天，我把链接贴出来自己看好吧，链接在resource里面。可以从ns2的架构里看出里面的数据产生，发送模块都是内部实现，模块虽然可以编辑但是也是属于在一个大的框架下面，所以除非你重写整个ns2不然你是没有办法获得模块化外的扩展，比如我要加虚拟机迁移模块进去，那我的应用是没办法变成虚拟机迁移的真实情况，只能自己写模型。 ns3ns3严格上来说是一个simulation,但是他有一部分外接的功能，大个比方，我要加入虚拟机模型，那么我需要在节点上加一个container，在这个容器里去跑虚拟机迁移的情况，看一下ns3的架构。架构里写的很清楚这里面就可以直接从rawsocket接到realdevice,换言之这就是一种外接emulator的方式。 EstiNet这个软件是王協源老师和他的lab编写的，只所以把模型用ns3外接mininet去做，主要原因也是因为王老师推荐的，同样王老师很喜欢大陆的学生，我也把他的lab和个人主页贴出来，关于sdn方向问题可以向我或者他发邮件咨询。[王協源-Shie-Yuan Wang].以及实验室[lab-Network and System Laboratory-NSL].Estinet已经是一个商业化的成熟软件，所以可以说它就是一个emulator,里面强大的UI设计对新生很方便，但是我们还是主要去看一下他的架构，如果你是做关于tcp方向的仿真的话，我还是不建议你用这个软件，用ns3和ns2会好一点。因为其实从架构上看，你可以看到EstiNet的tcp部分其实是过了tcp的内核的，所以修改起来会非常的困难，从ns2-&gt;ns3-&gt;Estinet其实tcp的复杂度是几何量级上升的，ns2的tcp文件基本上都是在tcp.cc和tcp.h里面就写完了，但是到ns3这块就变成了tcp-socket-base.cc,tcp-socket-base.h,tcp-socket.cc,tcp-socket.h等很多模块拼接的，所以要读起来会非常非常的难，我还是很建议新手从ns2或者ns3开始，不然实在是太难了，Estinet的整体架构我在resource里面会贴出来，是一个王老师的ppt，希望对你有用。Resource1.[NS2-introduction].这是个ns2－introduction的ppt.[NS2-Presentation].这个入门看看架构会好一些。2.[NS3-introduction].这是一个ppt可以直接下载,也是基本的结构。[NS3-Emulator].这是外接Emulator部分。3.[Estinet].这是当时在会议上给出的introduction，已经很清晰了。 如果你也对我现在的科研有兴趣的话请记得联系我，邮箱直接点击外部链接即可。我还要强调一下，如果你只是调研的话我这篇blog实际上是够的，但是如果你想用它来实现一些功能，我还是建议你买几本书看看，比较常用的资料可以去我的其他blog找找，没有的话就去上网搜搜，公认的比较好的就那几本，如果这种买书的问题你也骚扰我的话，我会拉黑你的。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"选择排序和插入排序","slug":"Selectsort","date":"2017-10-11T12:48:39.874Z","updated":"2017-07-11T01:43:22.000Z","comments":true,"path":"2017/10/11/Selectsort/","link":"","permalink":"http://yoursite.com/2017/10/11/Selectsort/","excerpt":"","text":"选择排序选择排序􏰀高了冒泡排序的性能,它每遍历一次列表只交换一次数据,即进行一次遍历时找 到最大的项,完成遍历后,再把它换到正确的位置。和冒泡排序一样,第一次遍历后,最大的数 据项就已归位,第二次遍历使次大项归位。这个过程持续进行,一共需要n-1次遍历来排好n个数 据,因为最后一个数据必须在第n-1次遍历之后才能归位。图3展示了选择排序的整个过程。每一次遍历,最大的数据项被选中,随后排到正确位置。 第一次遍历排好了93,第二次排好了77,第三次排好了55,以此类推。代码1展示了实现选择排 序的函数。1234567891011121314151617选择排序def selectionSort(alist): for fillslot in range(len(alist)-1,0,-1): print fillslot positionOfMax = 0 for location in range(1,fillslot+1): #print location if alist[location]&gt;alist[positionOfMax]: positionOfMax = location print alist[fillslot] temp = alist[fillslot] alist[fillslot] = alist[positionOfMax] alist[positionOfMax] = tempalist = [54,26,93,17,77,31,44,55,20]selectionSort(alist)print alist 插入排序插入排序的算法复杂度仍然是O(n2),但其工作原理稍有不同。它总是保持一个位置靠前的 已排好的子表,然后每一个新的数据项被“插入”到前边的子表里,排好的子表增加一项。 插入排序需要进行的最多的比较次数仍是从1到n-1的所有的整数之和,即复杂度为O(n2)。但 是,最好的情况下,每排一个数据只需要一次比较,即列表已经排好的情况。 关于“转移”与“交换”操作的考虑也很重要。通常情况下,“转移”的步骤约为“交换” 步骤的1/3,因为它只有一次赋值操作。在基准测试中,插入排序将展示非常好的性能。 123456789101112131415def insertionSort(alist): for index in range(1,len(alist)): currentvalue = alist[index] print currentvalue position = index print position while position &gt; 0 and alist[position-1]&gt;currentvalue: alist[position] = alist[position-1] position = position -1 alist[position] = currentvaluealist = [54,26,93,17,77,31,44,55,20]insertionSort(alist)print alist","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"独立磁盘冗余阵列 RAID","slug":"RAID","date":"2017-10-11T12:48:39.870Z","updated":"2017-08-03T14:12:14.000Z","comments":true,"path":"2017/10/11/RAID/","link":"","permalink":"http://yoursite.com/2017/10/11/RAID/","excerpt":"","text":"RAID （ Redundant Array of Independent Disks ）即独立磁盘冗余阵列，通常简称为磁盘阵列。简单地说， RAID 是由多个独立的高性能磁盘驱动器组成的磁盘子系统，从而提供比单个磁盘更高的存储性能和数据冗余的技术。 RAID 是一类多磁盘管理技术，其向主机环境提供了成本适中、数据可靠性高的高性能存储。 RAID 的初衷是为大型服务器提供高端的存储功能和冗余的数据安全。在整个系统中， RAID 被看作是由两个或更多磁盘组成的存储空间，通过并发地在多个磁盘上读写数据来提高存储系统的 I/O 性能。大多数 RAID 等级具有完备的数据校验、纠正措施，从而提高系统的容错性，甚至镜像方式，大大增强系统的可靠性， Redundant 也由此而来。 RAID的优势1.大容量这是 RAID 的一个显然优势，它扩大了磁盘的容量，由多个磁盘组成的 RAID 系统具有海量的存储空间。现在单个磁盘的容量就可以到 1TB 以上，这样 RAID 的存储容量就可以达到 PB 级，大多数的存储需求都可以满足。一般来说， RAID 可用容量要小于所有成员磁盘的总容量。不同等级的 RAID 算法需要一定的冗余开销，具体容量开销与采用算法相关。如果已知 RAID 算法和容量，可以计算出 RAID 的可用容量。通常， RAID 容量利用率在 50% ~ 90% 之间。 2.高性能RAID 的高性能受益于数据条带化技术。单个磁盘的 I/O 性能受到接口、带宽等计算机技术的限制，性能往往很有 限，容易成为系统性能的瓶颈。通过数据条带化， RAID 将数据 I/O 分散到各个成员磁盘上，从而获得比单个磁盘成倍增长的聚合 I/O 性能。 3.可靠性可用性和可靠性是 RAID 的另一个重要特征。从理论上讲，由多个磁盘组成的 RAID 系统在可靠性方面应该比单个磁盘要差。这里有个隐含假定：单个磁盘故障将导致整个 RAID 不可用。 RAID 采用镜像和数据校验等数据冗余技术，打破了这个假定。 镜像是最为原始的冗余技术，把某组磁盘驱动器上的数据完全复制到另一组磁盘驱动器上，保证总有数据副本可用。比起镜像50%的冗余开销，数据校验要小很多，它利用校验冗余信息对数据进行校验和纠错。RAID冗余技术大幅提升数据可用性和可靠性，保证了若干磁盘出错时，不 会导致数据的丢失，不影响系统的连续运行。 4.可管理性实际上， RAID 是一种虚拟化技术，它对多个物理磁盘驱动器虚拟成一个大容量的逻辑驱动器。对于外部主机系统来说， RAID 是一个单一的、快速可靠的大容量磁盘驱动器。这样，用户就可以在这个虚拟驱动器上来组织和存储应用系统数据。 从用户应用角度看，可使存储系统简单易用，管理也很便利。 由于 RAID 内部完成了大量的存储管理工作，管理员只需要管理单个虚拟驱动器，可以节省大量的管理工作。 RAID 可以动态增减磁盘驱动器，可自动进行数据校验和数据重建，这些都可以 大大简化管理工作。 RAID关键技术1.镜像镜像是一种冗余技术，为磁盘提供保护功能，防止磁盘发生故障而造成数据丢失。对于 RAID 而言，采用镜像技术 典型地 将会同时在阵列中产生两个完全相同的数据副本，分布在两个不同的磁盘驱动器组上。镜像提供了完全的数据冗余能力，当一个数据副本失效不可用时，外部系统仍可正常访问另一副本，不会对应用系统运行和性能产生影响。而且，镜像不需要额外的计算和校验，故障修复非常快，直接复制即可。镜像技术可以从多个副本进行并发读取数据，提供更高的读 I/O 性能，但不能并行写数据，写多个副本会会导致一定的 I/O 性能降低。镜像技术提供了非常高的数据安全性，其代价也是非常昂贵的，需要至少双倍的存储空间。高成本限制了镜像的广泛应用，主要应用于至关重要的数据保护，这种场合下数据丢失会造成巨大的损失。另外，镜像通过 “ 拆分 ” 能获得特定时间点的上数据快照，从而可以实现一种备份窗口几乎为零的数据备份技术。 2.数据条带磁盘存储的性能瓶颈在于磁头寻道定位，它是一种慢速机械运动，无法与高速的 CPU 匹配。再者，单个磁盘驱动器性能存在物理极限， I/O 性能非常有限。 RAID 由多块磁盘组成，数据条带技术将数据以块的方式分布存储在多个磁盘中，从而可以对数据进行并发处理。这样写入和读取数据就可以在多个磁盘上同时进行，并发产生非常高的聚合 I/O ，有效提高了整体 I/O 性能，而且具有良好的线性扩展性。这对大容量数据尤其显著，如果不分块，数据只能按顺序存储在磁盘阵列的磁盘上，需要时再按顺序读取。而通过条带技术，可获得数倍与顺序访问的性能提升。数据条带技术的分块大小选择非常关键。条带粒度可以是一个字节至几KB大小，分块越小，并行处理能力就越强，数据存取速度就越高，但同时就会增加块存取的随机性和块寻址时间。实际应用中，要根据数据特征和需求来选择合适的分块大小，在数据存取随机性和并发处理能力之间进行平衡，以争取尽可能高的整体性能。数据条带是基于提高 I/O 性能而提出的，也就是说它只关注性能， 而对数据可靠性、可用性没有任何改善。 实际上，其中任何一个数据条带损坏都会导致整个数据不可用，采用数据条带技术反而增加了数据发生丢失的概念率。 3.数据校验镜像具有高安全性、高读性能，但冗余开销太昂贵。数据条带通过并发性来大幅提高性能，然而对数据安全性、可靠性未作考虑。数据校验是一种冗余技术，它用校验数据来提供数据的安全，可以检测数据错误，并在能力允许的前提下进行数据重构。相对镜像，数据校验大幅缩减了冗余开销，用较小的代价换取了极佳的数据完整性和可靠性。数据条带技术提供高性能，数据校验提供数据安全性， RAID 不同等级往往同时结合使用这两种技术。采用数据校验时， RAID 要在写入数据同时进行校验计算，并将得到的校验数据存储在 RAID 成员磁盘中。校验数据可以集中保存在某个磁盘或分散存储在多个不同磁盘中，甚至校验数据也可以分块，不同 RAID 等级实现各不相同。当其中一部分数据出错时，就可以对剩余数据和校验数据进行反校验计算重建丢失的数据。校验技术相对于镜像技术的优势在于节省大量开销，但由于每次数据读写都要进行大量的校验运算，对计算机的运算速度要求很高，必须使用硬件 RAID 控制器。在数据重建恢复方面，检验技术比镜像技术复杂得多且慢得多。海明校验码和 异或校验是两种最为常用的 数据校验算法。 海明校验码是由理查德·海明提出的，不仅能检测错误，还能给出错误位置并自动纠正。海明校验的基本思想是：将有效信息按照某种规律分成若干组，对每一个组作奇偶测试并安排一个校验位，从而能提供多位检错信息，以定位错误点并纠正。可见海明校验实质上是一种多重奇偶校验。 异或校验通过异或逻辑运算产生，将一个有效信息与一个给定的初始值进行异或运算，会得到校验信息。如果有效信息出现错误，通过校验信息与初始值的异或运算能还原正确的有效信息。 常见RAID类型NIA 、 Berkeley 等组织机构把 RAID0 、 RAID1 、 RAID2 、 RAID3 、 RAID4 、 RAID5 、 RAID6 七个等级定为标准的 RAID 等级，这也被业界和学术界所公认。标准等级是最基本的 RAID 配置集合，单独或综合利用数据条带、镜像和数据校验技术。标准 RAID 可以组合，即 RAID 组合等级，满足 对性能、安全性、可靠性要求更高的存储应用需求。 RAID 0：如果你有n块磁盘，原来只能同时写一块磁盘，写满了再下一块，做了RAID 0之后，n块可以同时写，速度提升很快，但由于没有备份，可靠性很差。n最少为2。 RAID 1：正因为RAID 0太不可靠，所以衍生出了RAID 1。如果你有n块磁盘，把其中n/2块磁盘作为镜像磁盘，在往其中一块磁盘写入数据时，也同时往另一块写数据。坏了其中一块时，镜像磁盘自动顶上，可靠性最佳，但空间利用率太低。n最少为2。 RAID 3：为了说明白RAID 5，先说RAID 3.RAID 3是若你有n块盘，其中1块盘作为校验盘，剩余n-1块盘相当于作RAID 0同时读写，当其中一块盘坏掉时，可以通过校验码还原出坏掉盘的原始数据。这个校验方式比较特别，奇偶检验，1 XOR 0 XOR 1=0，0 XOR 1 XOR 0=1，最后的数据时校验数据，当中间缺了一个数据时，可以通过其他盘的数据和校验数据推算出来。但是这有个问题，由于n-1块盘做了RAID 0，每一次读写都要牵动所有盘来为它服务，而且万一校验盘坏掉就完蛋了。最多允许坏一块盘。n最少为3. RAID 5：在RAID 3的基础上有所区别，同样是相当于是1块盘的大小作为校验盘，n-1块盘的大小作为数据盘，但校验码分布在各个磁盘中，不是单独的一块磁盘，也就是分布式校验盘，这样做好处多多。最多坏一块盘。n最少为3. RAID 6：在RAID 5的基础上，又增加了一种校验码，和解方程似的，一种校验码一个方程，最多有两个未知数，也就是最多坏两块盘。(同时损坏两块盘才会出现数据无法损毁)。RAID6 等级是在 RAID5 的基础上为了进一步增强数据保护而设计的一种 RAID 方式，它可以看作是一种扩展的 RAID5 等级。RAID6 不仅要支持数据的恢复，还要支持校验数据的恢复，因此实现代价很高，控制器的设计也比其他等级更复杂、更昂贵。RAID6 思想最常见的实现方式是采用两个独立的校验算法，假设称为 P 和 Q ，校验数据可以分别存储在两个不同的校验盘上，或者分散存储在所有成员磁盘中。当两个磁盘同时失效时，即可通过求解两元方程来重建两个磁盘上的数据。RAID6 具有快速的读取性能、更高的容错能力。但是，它的成本要高于 RAID5 许多，写性能也较差，并有设计和实施非常复杂。因此， RAID6 很少得到实际应用，主要用于对数据安全等级要求非常高的场合。它一般是替代 RAID10 方案的经济性选择 RAID组合等级标准 RAID 等级各有优势和不足。自然地，我们想到把多个 RAID 等级组合起来，实现优势互补，弥补相互的不足，从而达到在性能、数据安全性等指标上更高的 RAID 系统。目前在业界和学术研究中提到的 RAID 组合等级主要有 RAID00 、 RAID01 、 RAID10 、 RAID100 、 RAID30 、 RAID50 、 RAID53 、 RAID60 ，但实际得到较为广泛应用的只有 RAID01 和 RAID10 两个等级。当然，组合等级的实现成本一般都非常昂贵，只是在 少数特定场合应用。 RAID10 和 RAID01RAID01 兼备了 RAID0 和 RAID1 的优点，它先用两块磁盘建立镜像，然后再在镜像内部做条带化。 RAID01 的数据将同时写入到两个磁盘阵列中，如果其中一个阵列损坏，仍可继续工作，保证数据安全性的同时又提高了性能。 RAID01 和 RAID10 内部都含有 RAID1 模式，因此整体磁盘利用率均仅为 50% 。 RAID50RAID 5与RAID 0的组合,先作RAID 5，再作RAID 0，也就是对多组RAID 5彼此构成Stripe访问。由于RAID 50是以RAID 5为基础，而RAID 5至少需要3颗硬盘，因此要以多组RAID 5构成RAID 50，至少需要6颗硬盘。以RAID 50最小的6颗硬盘配置为例，先把6颗硬盘分为2组，每组3颗构成RAID 5，如此就得到两组RAID 5，然后再把两组RAID 5构成RAID 0。 RAID 50在底层的任一组或多组RAID 5中出现1颗硬盘损坏时，仍能维持运作，不过如果任一组RAID 5中出现2颗或2颗以上硬盘损毁，整组RAID 50就会失效。RAID 50由于在上层把多组RAID 5构成Stripe，性能比起单纯的RAID 5高，容量利用率比RAID5要低。比如同样使用9颗硬盘，由各3颗RAID 5再组成RAID 0的RAID 50，每组RAID 5浪费一颗硬盘，利用率为(1-3/9)，RAID 5则为(1-1/9)。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"快速排序和归并排序","slug":"quicksort","date":"2017-10-11T12:48:39.865Z","updated":"2017-07-11T11:10:52.000Z","comments":true,"path":"2017/10/11/quicksort/","link":"","permalink":"http://yoursite.com/2017/10/11/quicksort/","excerpt":"","text":"归并排序归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。 合并相邻有序子序列step1:step2:归并排序是稳定排序，它也是一种十分高效的排序，能利用完全二叉树特性的排序一般性能都不会太差。java中Arrays.sort()采用了一种名为TimSort的排序算法，就是归并排序的优化版本。从上文的图中可看出，每次合并操作的平均时间复杂度为O(n)，而完全二叉树的深度为|log2n|。总的平均时间复杂度为O(nlogn)。而且，归并排序的最好，最坏，平均时间复杂度均为O(nlogn)。 快速排序快速排序由C. A. R. Hoare在1962年提出。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 考虑到在blog里面讲代码太费时间，直接丢到github。 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"继承和多重继承--Python","slug":"python_superclass","date":"2017-10-11T12:48:39.863Z","updated":"2017-06-23T03:06:12.000Z","comments":true,"path":"2017/10/11/python_superclass/","link":"","permalink":"http://yoursite.com/2017/10/11/python_superclass/","excerpt":"","text":"继承在Python中，如果需要的话，可以让一个类去继承一个类，被继承的类称为父类或者超类、也可以称作基类，继承的类称为子类。并且Python支持多继承，能够让一个子类有多个父类。 Python中类的继承定义基本形式如下：1234567#父类 class superClassName: block #子类 class subClassName(superClassName): block 在定义一个类的时候，可以在类名后面紧跟一对括号，在括号中指定所继承的父类，如果有多个父类，多个父类名之间用逗号隔开。以大学里的学生和老师举例，可以定义一个父类UniversityMember，然后类Student和类Teacher分别继承类UniversityMember：123456789101112131415161718192021222324252627282930313233343536373839class UniversityMember: def __init__(self,name,age): self.name = name self.age = age def getName(self): return self.name def getAge(self): return self.age class Student(UniversityMember): def __init__(self,name,age,sno,mark): UniversityMember.__init__(self,name,age) #注意要显示调用父类构造方法，并传递参数self self.sno = sno self.mark = mark def getSno(self): return self.sno def getMark(self): return self.mark class Teacher(UniversityMember): def __init__(self,name,age,tno,salary): UniversityMember.__init__(self,name,age) self.tno = tno self.salary = salary def getTno(self): return self.tno def getSalary(self): return self.salary 在大学中的每个成员都有姓名和年龄，而学生有学号和分数这2个属性，老师有教工号和工资这2个属性，从上面的代码中可以看到:1.在Python中，如果父类和子类都重新定义了构造方法init( ),在进行子类实例化的时候，子类的构造方法不会自动调用父类的构造方法，必须在子类中显示调用。2.如果需要在子类中调用父类的方法，需要以”父类名.方法“这种方式调用，以这种方式调用的时候，注意要传递self参数过去。 对于继承关系，子类继承了父类所有的公有属性和方法，可以在子类中通过父类名来调用，而对于私有的属性和方法，子类是不进行继承的，因此在子类中是无法通过父类名来访问的。 tips: Python支持多重继承。对于多重继承，比如 class SubClass(SuperClass1,SuperClass2) 此时有一个问题就是如果SubClass没有重新定义构造方法，它会自动调用哪个父类的构造方法？这里记住一点：以第一个父类为中心。如果SubClass重新定义了构造方法，需要显示去调用父类的构造方法，此时调用哪个父类的构造方法由你自己决定；若SubClass没有重新定义构造方法，则只会执行第一个父类的构造方法。并且若SuperClass1和SuperClass2中有同名的方法，通过子类的实例化对象去调用该方法时调用的是第一个父类中的方法。 其实还有一个我觉得刚开始学的时候很多人都不明白怎么继承父类的公有属性，而且子类的初始化函数经常搞混了，不知道该怎么写，我觉得可以这么看，实际上在子类初始化的时候不会调用父类的init()函数的，所以你需要自己写一个，那有些变量是你自己增加的，你需要对他初始化，比如上面说的self.tno = tno这个新的属性你需要自己去初始化，但是你还继承了父类的对吧，所以你先把从父类继承过来的元素写上，但是你继承过来你总的定义传过来的参数，子类不知道我要传多少参数，所以这么一看我们的步骤很明显了。step1:1def __init__(self,name,age,tno,salary): 我先确定我要传的参数（有要继承父类的，有要自己初始化的，我都要传参的对吧）step2:1UniversityMember.__init__(self,name,age) 我们再把父类的继承过来，我们继承的是父类的初始化函数，所以(父类名.方法)没毛病。别忘了self是对象本身所以要传。step3:12self.tno = tno self.salary = salary 把自己新增的参数也要初始化对吧，就和父类一样，做完这三步这个新函数就有你需要的参数，其余操作和普通类一样了就。补充一下：实际上上面这个方式是python2.7里面的特性，在python3里面加入了一个super继承的方式，我进行了下测试，先把代码贴出来再解释。1234567891011121314151617class Person(object): \"\"\"docstring for ClassName\"\"\" def __init__(self, name,age): self.name = name self.age = age xuanlong = Person(\"xuanlong\",24)class student(Person): \"\"\"docstring for student\"\"\" def __init__(self, name,age,grade): #super(Person, self).__init__() Person.__init__(self,name,age) self.grade = gradeqiu = student(\"qiu\",24,15)print qiu.grade 这两个方法的区别在于1.传统的继承方式是： 父类名.init(self,要继承的父类属性，要继承的父类属性)2.super新式继承：super(Person, self).init()实际上！！！super很适合只有一个类的因为他要求最顶层的父类一定要继承于object，这样就可以利用super()函数来调用父类的init()等函数，每个父类都执行且执行一次，并不会出现重复调用的情况。而且在子类的实现中，不用到处写出所有的父类名字。采用super()方式时，会自动找到第一个多继承中的第一个父类，但是如果还想强制调用其他父类的init()函数或两个父类的同名函数时，就要用老办法了。 * 还是比较建议使用传统继承方式，简单易懂，新的方法可能之后我学一学会再补充一些。大约花了四天的时间刷完了codecademy里面的python部分，虽然有c++的基础但是在做leetcode的时候还是心有余而力不足，昨天花了那么久才做了两道，算法部分还是蛮难的，希望sdn和ryu部分让我的python代码能力得到质的提升。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"Intermediate Python(进阶)--Python","slug":"python_jinjie","date":"2017-10-11T12:48:39.861Z","updated":"2017-06-26T09:49:20.000Z","comments":true,"path":"2017/10/11/python_jinjie/","link":"","permalink":"http://yoursite.com/2017/10/11/python_jinjie/","excerpt":"","text":"这个章节里面主要讲一下通过一周的学习了解了python的语法和一些基本的函数面向对象等功能，但是有一些进阶的东西是必备的，主要分为下面这个小节: args和*kwargs,生成器，装饰器，推导式。其余一些小的概念我非常非常建议大家先花3-4的时间去把codecademy的python入门部分学完，因为它里面边讲，边要你自己写代码，所以进展会非常快，当然前提是你有一定的代码基础，不然我还是会推荐python核心入门这本书。由于在我的预算里我要准备动ryu的，所以python在实战中可能会进展的更快，而且picca8我已经从Vicky那里拿到，明天我就准备加入SDN的实战操作，所有的resource我也会进行一个总结，贴到最后。 args和**kwargs*args的用法args 和 **kwargs 主要用于函数定义。 你可以将不定数量的参数传递给一个函数。这里的不定的意思是：预先并不知道, 函数使用者会传递多少个参数给你, 所以在这个场景下使用这两个关键字。 args 是用来发送一个非键值对的可变数量的参数列表给一个函数.随便写一个代码demo：123456def test_var_args(f_arg, *argv): print(\"first normal arg:\", f_arg) # for arg in argv: print(\"another arg through *argv:\", arg)test_var_args('xuanlong', 'heihei', 'hehe', 'haha') 输出是什么呢，明显第一个参数是正常的传参，后面就是你不知道多少个数目的大小。1234&gt;&gt;&gt; first normal arg: xuanlong&gt;&gt;&gt; another arg through *argv: heihei&gt;&gt;&gt; another arg through *argv: hehe&gt;&gt;&gt; another arg through *argv: haha **kwargs这这参数也是传不定量参数传递，但是这里传输的是key-value对。kwargs 允许你将不定长度的键值对, 作为参数传递给一个函数。 如果你想要在一个函数里处理带名字的参数, 你应该使用kwargs。1234567def greet_me(**kwargs): # for key, value in kwargs.items(): print(\"&#123;0&#125; == &#123;1&#125;\".format(key, value))&gt;&gt;&gt; greet_me(name=\"yasoob\")name == yasoob 关于format(),它通过{}和:来代替%.它可以通过位置，关键字参数，对象属性，下标来进行映射，这部分我觉得不是本文的重点，我会在后面把链接贴出来，你有兴趣的话可以看一下，我在这里旧居一个通过位置映射的例子。12345678&gt;&gt;&gt; &apos;&#123;0&#125;,&#123;1&#125;&apos;.format(&apos;qxl&apos;,24) &gt;&gt;&gt; &apos;qxl,24&apos; &gt;&gt;&gt; &apos;&#123;&#125;,&#123;&#125;&apos;.format(&apos;qxl&apos;,24) &gt;&gt;&gt; &apos;qxl,24&apos; &gt;&gt;&gt; &apos;&#123;1&#125;,&#123;0&#125;,&#123;1&#125;&apos;.format(&apos;qxl&apos;,24) &gt;&gt;&gt; &apos;24,qxl,24&apos; 标准参数与args、*kwargs在使用时的顺序顺序是这样的： some_func(fargs, args, *kwargs) 生成器迭代器先了解一下迭代器。迭代器是一个让程序员可以遍历一个容器（特别是列表）的对象。然而，一个迭代器在遍历并读取一个容器的数据元素时，并不会执行一个迭代。你可能有点晕了，那我们来个慢动作。换句话说这里有三个部分： 可迭代对象(Iterable):可迭代对象就是能提供迭代器的任意对象 迭代器(Iterator):任意对象，只要定义了next(Python2) 或者next方法，它就是一个迭代器.(有next才能进行迭代啊). 迭代(Iteration):它就是从某个地方（比如一个列表）取出一个元素的过程。当我们使用一个循环来遍历某个东西时，这个过程本身就叫迭代.生成器生成器也是一种迭代器，但是你只能对其迭代一次。这是因为它们并没有把所有的值存在内存中，而是在运行时生成值。你通过遍历来使用它们，要么用一个“for”循环，要么将它们传递给任意可以进行迭代的函数和结构。大多数时候生成器是以函数来实现的。然而，它们并不返回一个值，而是yield(暂且译作“生出”)一个值。 划个重点，不返回值，只是产生一个值。 生成器最佳应用场景是：你不想同一时间将所有计算出来的大量结果集分配到内存当中，特别是结果集里还包含循环。(这样做会消耗大量资源) 装饰器我首先下个定义，什么是装饰器，装饰器就是一个封装好的函数，你使用”@”来调用，可以让你在被装饰函数之前或之后执行代码，而不用修改函数本身。之后我们在讲一下要理解装饰器你可能需要以下的背景。 实际上这个文章里写的太好了，我只是为了记录一下，我不觉得我自己阐述会有他讲的好，所以我直接把东西贴进来，同时会把链接贴到Resource里面。一切皆对象123456789101112131415161718192021def hi(name=\"yasoob\"): return \"hi \" + nameprint(hi())# output: 'hi yasoob'# 我们甚至可以将一个函数赋值给一个变量，比如greet = hi# 我们这里没有在使用小括号，因为我们并不是在调用hi函数# 而是在将它放在greet变量里头。我们尝试运行下这个print(greet())# output: 'hi yasoob'# 如果我们删掉旧的hi函数，看看会发生什么！del hiprint(hi())#outputs: NameErrorprint(greet())#outputs: 'hi yasoob' 在函数中定义函数在Python中我们可以在一个函数中定义另一个函数：123456789101112131415161718192021222324def hi(name=\"yasoob\"): print(\"now you are inside the hi() function\") def greet(): return \"now you are in the greet() function\" def welcome(): return \"now you are in the welcome() function\" print(greet()) print(welcome()) print(\"now you are back in the hi() function\")hi()#output:now you are inside the hi() function# now you are in the greet() function# now you are in the welcome() function# now you are back in the hi() function# 上面展示了无论何时你调用hi(), greet()和welcome()将会同时被调用。# 然后greet()和welcome()函数在hi()函数之外是不能访问的，比如：greet()#outputs: NameError: name 'greet' is not defined 那现在我们知道了可以在函数中定义另外的函数。也就是说：我们可以创建嵌套的函数。现在你需要再多学一点，就是函数也能返回函数。 从函数中返回函数其实并不需要在一个函数里去执行另一个函数，我们也可以将其作为输出返回出来：123456789101112131415161718192021def hi(name=\"yasoob\"): def greet(): return \"now you are in the greet() function\" def welcome(): return \"now you are in the welcome() function\" # if name == \"yasoob\": return greet else: return welcomea = hi()print(a)#outputs: &lt;function greet at 0x7f2143c01500&gt;#上面清晰地展示了`a`现在指向到hi()函数中的greet()函数#现在试试这个print(a())#outputs: now you are in the greet() function 再次看看这个代码。在if/else语句中我们返回greet和welcome，而不是greet()和welcome()。为什么那样？这是因为当你把一对小括号放在后面，这个函数就会执行；然而如果你不放括号在它后面，那它可以被到处传递，并且可以赋值给别的变量而不去执行它。 你明白了吗？让我再稍微多解释点细节。(这段请仔细看，我觉得不错–xuanlong) 当我们写下a = hi()，hi()会被执行，而由于name参数默认是yasoob，所以函数greet被返回了。如果我们把语句改为a = hi(name = “ali”)，那么welcome函数将被返回。我们还可以打印出hi()()，这会输出now you are in the greet() function。 将函数作为参数传给另一个函数12345678910def hi(): return &quot;hi yasoob!&quot;def doSomethingBeforeHi(func): print(&quot;I am doing some boring work before executing hi()&quot;) print(func())doSomethingBeforeHi(hi)# outputs:I am doing some boring work before executing hi()# hi yasoob! 你的第一个装饰器123456789101112131415161718192021222324def a_new_decorator(a_func): def wrapTheFunction(): print(&quot;I am doing some boring work before executing a_func()&quot;) a_func() print(&quot;I am doing some boring work after executing a_func()&quot;) return wrapTheFunctiondef a_function_requiring_decoration(): print(&quot;I am the function which needs some decoration to remove my foul smell&quot;)a_function_requiring_decoration()#outputs: &quot;I am the function which needs some decoration to remove my foul smell&quot;a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration)#now a_function_requiring_decoration is wrapped by wrapTheFunction()a_function_requiring_decoration()#outputs:I am doing some boring work before executing a_func()# I am the function which needs some decoration to remove my foul smell# I am doing some boring work after executing a_func() 你看明白了吗？我们刚刚应用了之前学习到的原理。这正是python中装饰器做的事情！它们封装一个函数，并且用这样或者那样的方式来修改它的行为。现在你也许疑惑，我们在代码里并没有使用@符号？那只是一个简短的方式来生成一个被装饰的函数。这里是我们如何使用@来运行之前的代码12345678910111213@a_new_decoratordef a_function_requiring_decoration(): \"\"\"Hey you! Decorate me!\"\"\" print(\"I am the function which needs some decoration to \" \"remove my foul smell\")a_function_requiring_decoration()#outputs: I am doing some boring work before executing a_func()# I am the function which needs some decoration to remove my foul smell# I am doing some boring work after executing a_func()#the @a_new_decorator is just a short way of saying:a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration) 这样你对装饰器就有一个大致的了解了，同时我也会把里面用到的代码贴到Github里面，但是我还是要说一句，这些代码非常建议初学者自己亲手敲一遍，会理解的更好。 推导式推导式（又称解析式）是Python的一种独有特性，推导式是可以从一个数据序列构建另一个新的数据序列的结构体。总共有三种推导式,会非常大程度简化我们的代码: 列表(list)推导式 字典(dict)推导式 集合(set)推导式 列表推导式（list comprehensions）列表推导式（又称列表解析式）提供了一种简明扼要的方法来创建列表。它的结构是在一个中括号里包含一个表达式，然后是一个for语句，然后是0个或多个for或者if语句。那个表达式可以是任意的，意思是你可以在列表中放入任意类型的对象。返回结果将是一个新的列表，在这个以if和for语句为上下文的表达式运行完成之后产生。 规范：1#variable = [out_exp for out_exp in input_list if out_exp == 2] 这里是另外一个简明例子:123#multiples = [i for i in range(30) if i % 3 is 0]print(multiples)# Output: [0, 3, 6, 9, 12, 15, 18, 21, 24, 27] 这将对快速生成列表非常有用。有些人甚至更喜欢使用它而不是filter函数。列表推导式在有些情况下超赞，特别是当你需要使用for循环来生成一个新列表。 字典推导式（dict comprehensions）字典推导和列表推导的使用方法是类似的。12345678mcase = &#123;'a': 10, 'b': 34, 'A': 7, 'Z': 3&#125;mcase_frequency = &#123; k.lower(): mcase.get(k.lower(), 0) + mcase.get(k.upper(), 0) # for k in mcase.keys()&#125;# mcase_frequency == &#123;'a': 17, 'z': 3, 'b': 34&#125; 在上面的例子中我们把同一个字母但不同大小写的值合并起来了。实际上这个好像不常用，一般列表推导式比较常用，而且codecademy也只是讲了列表推导式。 集合推导式（set comprehensions）它们跟列表推导式也是类似的。 唯一的区别在于它们使用大括号{}。123#squared = &#123;x**2 for x in [1, 1, 2]&#125;print(squared)# Output: &#123;1, 4&#125; 除了上述基本语法以外，我还看到一个比较有意思的特性，就是Python可以通过C扩展，实际上还有一些API供我们使用，我也只是大概瞄了一眼，之后再说吧。 Resource希望这些资源对看到文章的你有用。1.[Intermediate Python中文译本(Python进阶)].中间很大一段我都摘自这个文章，非常好的Blog.2.[Codecademy-在线学习]. 这个我不多说了，真的好用，而且学起来比较简单.3.[Python/C API]. 有兴趣选读，暂时我没什么兴趣。4.[format.()函数].这里面的例子还不错5.[Github-link].本篇博文的代码为了大家不用自己敲一遍，我已经贴到Github供大家食用。 不得不说我现在看python的库只有我不知道的，没有没写的，所以说python的库是真的强大，写一些小程序是非常方便的。对于不懂的函数你直接googe一下”python fun()”看看定义去做是一件非常方便的事，明天应该就转到真机host了好激动。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"类属性、实例属性、类方法、实例方法以及静态方法--Python","slug":"python_class","date":"2017-10-11T12:48:39.857Z","updated":"2017-06-23T02:25:16.000Z","comments":true,"path":"2017/10/11/python_class/","link":"","permalink":"http://yoursite.com/2017/10/11/python_class/","excerpt":"","text":"类属性、实例属性的区别类属性类属性就是类对象所拥有的属性，它被所有类对象的实例对象所共有，在内存中只存在一个副本，这个和C++中类的静态成员变量有点类似。对于公有的类属性，在类外可以通过类对象和实例对象访问。12345678910class people: name = 'Xuanlong' #公有的类属性 __age = 12 #私有的类属性 p = people() print p.name #正确 print people.name #正确 print p.__age #错误，不能在类外通过实例对象访问私有的类属性 print people.__age #错误，不能在类外通过类对象访问私有的类属性 实例属性实例属性是不需要在类中显示定义的，比如：12345678910class people: name = 'Xuanlong' p = people() p.age =24 print p.name #正确 print p.age #正确 print people.name #正确 print people.age #错误 在类外对类对象people进行实例化之后，产生了一个实例对象p，然后p.age = 24这句给p添加了一个实例属性age，赋值为24。这个实例属性是实例对象p所特有的，注意，类对象people并不拥有它（所以不能通过类对象来访问这个age属性）。当然还可以在实例化对象的时候给age赋值。12345678910111213 class people: name = 'Xuanlong' #__init__()是内置的构造方法，在实例化对象时自动调用 def __init__(self,age): self.age = age p = people(12) print p.name #正确 print p.age #正确 print people.name #正确 print people.age #错误 如果需要在类外修改类属性，必须通过类对象去引用然后进行修改。如果通过实例对象去引用，会产生一个同名的实例属性，这种方式修改的是实例属性，不会影响到类属性，并且之后如果通过实例对象去引用该名称的属性，实例属性会强制屏蔽掉类属性，即引用的是实例属性，除非删除了该实例属性。123456789101112class people: country = 'china' print people.country p = people() print p.country p.country = 'Taiwan' print p.country #实例属性会屏蔽掉同名的类属性 print people.country del p.country #删除实例属性 print p.country 类方法、实例方法和静态方法的区别类方法类方法：是类对象所拥有的方法，需要用修饰器”@classmethod”来标识其为类方法，对于类方法，第一个参数必须是类对象，一般以”cls”作为第一个参数（当然可以用其他名称的变量作为其第一个参数，但是大部分人都习惯以’cls’作为第一个参数的名字，就最好用’cls’了），能够通过实例对象和类对象去访问。1234567891011 class people: country = 'china' #类方法，用classmethod来进行修饰 @classmethod def getCountry(cls): return cls.country p = people() print p.getCountry() #可以用过实例对象引用 print people.getCountry() #可以通过类对象引用 类方法还有一个用途就是可以对类属性进行修改：123456789101112131415161718192021 class people: country = 'china' #类方法，用classmethod来进行修饰 @classmethod def getCountry(cls): return cls.country @classmethod def setCountry(cls,country): cls.country = country p = people() print p.getCountry() #可以用过实例对象引用 print people.getCountry() #可以通过类对象引用 p.setCountry('Taiwan') print p.getCountry() print people.getCountry() 运行结果如下：1234china china Taiwan Taiwan 实际上就是调用了类方法p.setCountry（）修改了类属性。在用类方法对类属性修改之后，通过类对象和实例对象访问都发生了改变。 实例方法实例方法：在类中最常定义的成员方法，它至少有一个参数并且必须以实例对象作为其第一个参数，一般以名为’self’的变量作为第一个参数（当然可以以其他名称的变量作为第一个参数）。 在类外实例方法只能通过实例对象去调用，不能通过其他方式去调用。1234567891011class people: country = 'china' #实例方法 def getCountry(self): return self.country p = people() print p.getCountry() #正确，可以用过实例对象引用 print people.getCountry() #错误，不能通过类对象引用实例方法 实例方法在类外和类内不一样，不过我们经常在类内定义方法，在类外实例化进行调用。 静态方法静态方法：需要通过修饰器”@staticmethod”来进行修饰，静态方法不需要多定义参数。123456789class people: country = 'china' @staticmethod #静态方法 def getCountry(): return people.country print people.getCountry() 总结一下： 对于类属性和实例属性，如果在类方法中引用某个属性，该属性必定是类属性，而如果在实例方法中引用某个属性（不作更改），并且存在同名的类属性，此时若实例对象有该名称的实例属性，则实例属性会屏蔽类属性，即引用的是实例属性，若实例对象没有该名称的实例属性，则引用的是类属性；如果在实例方法更改某个属性，并且存在同名的类属性，此时若实例对象有该名称的实例属性，则修改的是实例属性，若实例对象没有该名称的实例属性，则会创建一个同名称的实例属性。想要修改类属性，如果在类外，可以通过类对象修改，如果在类里面，只有在类方法中进行修改。－ 类外实例做的修改不会影响类本身，要想对类对象修改那就需要在类方法里面改。实例属性调用覆盖类属性，说明实例的优先级高。 从类方法和实例方法以及静态方法的定义形式就可以看出来，类方法的第一个参数是类对象cls，那么通过cls引用的必定是类对象的属性和方法；而实例方法的第一个参数是实例对象self，那么通过self引用的可能是类属性、也有可能是实例属性（这个需要具体分析），不过在存在相同名称的类属性和实例属性的情况下，实例属性优先级更高。静态方法中不需要额外定义参数，因此在静态方法中引用类属性的话，必须通过类对象来引用。 下一篇要看看继承和多继承","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"SDN真机环境搭建","slug":"Pica8","date":"2017-10-11T12:48:39.853Z","updated":"2017-06-28T11:01:40.000Z","comments":true,"path":"2017/10/11/Pica8/","link":"","permalink":"http://yoursite.com/2017/10/11/Pica8/","excerpt":"","text":"首先看一下pica8的参数,pica8支持传统网络协议和OpenFlow技术，同时基于专利CrossFlow技术实现两种协议在单台设备间的互通。Pica8 P-5401 40GbE交换机:Pica8交换机运行PicOS™操作系统，高性能硬件平台涵盖1G/10G/25G/40G/100G不同规格，1GbE设备最大交换能力可达176Gbps，10GbE设备最大交换能力可达1.44Tbps,40GbE设备最大交换能力可达2.56Tbps, 25G/100GbE设备最大交换能力可达3.2Tbps。 集成OpenSwitch(OVS)2.3,支持Openflow 1.4 多控制器联通(ODL,ONOS,Ryu,Floodlight,NOX) 多线程无缝添加协议 基本上还是非常土豪的，造价：$11,600.00 大概也就7-8万，走之前去耍一耍那个造价30W的100G，美滋滋。 现在实验环境只分给我一台openflow交换机(不支持P4)，然后通过comport线连接，一条设定主机，一条接到内网，内网是普通交换机大约20台20口左右，看起来ovs还是要在server上做，不知道混合网络效果怎么样。1234567//驱动文件贴到resource里面 这种专门的线还要自己买～$screen /dev/cu.UC-232AC 115200$ovs-vsctl set-controller br0 tcp:127.0.0.1(switch ip) 6633(default)# --wsapi-port(不建议换端口)# testovs-ofctl dump-flows br0#ovs-ofctl 和ovs-vsctl指令集 具体的东西我就不能再贴了，因为清大的网络有受过攻击，我就不贴公网IP了。主要是配置的时候需要一些驱动，和测试所以浪费了很多时间，下面是一些链接，其中有HSNL维护的multi-table和我要做的QOS，还有一些驱动文件以及工作手册，看起来会很有用。 Resource1.[Ryu安装].之前的博文我也有写过怎么搭建Ryu+mininet的环境，但是考虑到虚拟机可能会出现nat的ip分配问题，所以还是考虑在server上重新搭一个环境，同时完善vm migration的迁移场景。2.[Ryu-Book].入门必备3.[vCPE-Hub].据说vcpe的前后端是vicky一个人写的，吓尿了。4.[Ovs-ofctl指令集].5.[Ovs-vsctl指令集].6.[Pica8官方].7.[USB to RS-232 Adapter (35cm)-UC232A].买的时候会送你驱动。1x USB-to-Serial Converter1x Driver Disk1x User Manual接了一晚上真机，觉得真实流量环境还是很爽的，跑起真实流量才感觉网络活起来了。","categories":[],"tags":[{"name":"sdn","slug":"sdn","permalink":"http://yoursite.com/tags/sdn/"}]},{"title":"搜索和冒泡排序－－python","slug":"paixu","date":"2017-10-11T12:48:39.850Z","updated":"2017-07-11T02:03:04.000Z","comments":true,"path":"2017/10/11/paixu/","link":"","permalink":"http://yoursite.com/2017/10/11/paixu/","excerpt":"","text":"当数据项被存储在集合中时,如存储在一个列表中,我们说,它们有一个线性或顺序的关 系。 每一个数据项存储在一个与其他数据项相对的位置。在Python列表,这些相对位置所对应 的是单个项的索引值。由于这些索引值是有一定次序的,可以依次访问它们。这一过程产生了第 一个搜索方法,顺序搜索。 无序列表搜索函数的参数为一个列表和一个我们正在寻找的 数据项,并且返回一个布尔值,判断它是否存在。布尔变量found初始化为False,如果我们发现 我们所要找的数据项在列表中,就将布尔变量赋为True。123456789101112131415'''def sequentialSearch(alist,item): pos = 0 found = False while pos &lt; len(alist) and not found: if alist[pos] == item: found = True else: pos +=1 return found testlist = [1,2,32,8,12,19,42,13,0] print(sequentialSearch(testlist,3)) print(sequentialSearch(testlist,13)) ''' 有序列表搜索我们早先假定我们集合里面的数据项都是被打乱放入的,这样,数据之间便没有相对关系。 如果在某些情况下,数据项是有序的,顺序搜索又会发生什么?我们能让我们的搜索技术更高效 吗? 123456789101112131415161718def orderedSequentialSearch(alist,item):''' pos = 0 found = False stop = False while pos &lt; len(alist) and not found and not stop: if alist[pos] == item: found = True else: if alist[pos] &gt; item: stop = True else: pos += 1 return foundtestlist = [0, 1, 2, 8, 13, 17, 19, 32, 42,]print(orderedSequentialSearch(testlist, 3))print(orderedSequentialSearch(testlist, 13))''' 二分搜索有序列表如果所采用的比较方法更聪明一些,我们可以更好地利用有序表的优势。在顺序搜索中,当 我们和第一项相比较时,如果第一个数据项不是我们要找的项,最多还有n-1项待比对。二分搜 索将从中间项开始检测,而不是按顺序搜索列表。如果查找项与我们刚搜索到的项匹配,则搜索 结束。如果不匹配,我们可以利用列表的有序性来排除掉一半的剩余项。如果查找项比中间项 大,我们可以把列表中较小的那一半全部和中间项可以从接下来的考察中排除了。因为如果查找 项在列表中,那它一定在较大的那一半。12345678910111213141516171819def binarySearch(alist,item): first = 0 last = len(alist) -1 found = False while first &lt;= last and not found: print last midpoint = (first+last)//2 if alist[midpoint] == item: found = True else: if item &lt; alist[midpoint]: last = midpoint-1 # print last else: first = midpoint+1 return foundtestlist = [0, 1, 2, 8, 13, 17, 19, 32, 42,]print(binarySearch(testlist, 3))print(binarySearch(testlist, 13)) 二分法搜索(递归写法)123456789101112131415def binarySearch(alist, item): if len(alist) == 0 : return False else: midpoint = len(alist)//2 if alist[midpoint] == item: return True else: if item &lt; alist[midpoint]: return binarySearch (alist[:midpoint],item) else: return binarySearch (alist[midpoint+1:],item)testlist = [0, 1, 2, 8, 13, 17, 19, 32, 42,] print(binarySearch(testlist, 3))print(binarySearch(testlist, 13)) 冒泡排序(号称最低效的排序)冒泡排序要对一个列表多次重复遍历。它要比较相邻的两项,并且交换顺序排错的项。每对 列表实行一次遍历,就有一个最大项排在了正确的位置。大体上讲,列表的每一个数据项都会在 其相应的位置“冒泡”。它们的顺序是否正确。如果列表有n项,第一次遍历就要比较n-1对数据。需要注意,一旦列 表中最大(按照规定的原则定义大小)的数据是所比较的数据对中的一个,它就会沿着列表一直 后移,直到这次遍历结束123456789101112def bubbleSort(alist): for passnum in range(len(alist)-1,0,-1): print passnum for i in range(passnum): if alist[i] &gt; alist[i+1]: temp = alist[i] alist[i] = alist[i+1] alist[i+1]=tempalist = [54,26,93,17,77,31,44,55,20]bubbleSort(alist)print(alist) 有序表冒泡排序因为冒泡排序必须要在最终位置找到之前不断交换数据项,所以它经常被认为是最低效的排 序方法。这些“浪费式”的交换操作消耗了许多时间。但是,由于冒泡排序要遍历整个未排好的 部分,它可以做一些大多数排序方法做不到的事。尤其是如果在整个排序过程中没有交换,我们 就可断定列表已经排好。因此可改良冒泡排序,使其在已知列表排好的情况下􏰀前结束。这就是 说,如果一个列表只需要几次遍历就可排好,冒泡排序就占有优势:它可以在发现列表已排好时 立刻结束。代码2就是改良版冒泡排序。它通常被称作“短路冒泡排序”。123456789101112def shortBubbleSort(alist): exchanges = True passnum = len(alist)-1 while passnum &gt; 0 and exchanges: exchanges = False for i in range(passnum): if alist[i] &gt; alist[i+1]: exchanges = True temp = alist[i] alist = alist[i+1] alist[i+1] = temp passnum = passnum -1","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"体系结构和操作系统gitbook","slug":"os","date":"2017-10-11T12:48:39.845Z","updated":"2017-07-22T15:09:20.000Z","comments":true,"path":"2017/10/11/os/","link":"","permalink":"http://yoursite.com/2017/10/11/os/","excerpt":"","text":"二叉树部分感觉自己会但是写的不熟，过一周再看吧，先把体系结构和操作系统的部分看看。 体系结构基础位(bit),字节(Byte),字(Word)位：”位(bit)”是电子计算机中最小的数据单位。每一位的状态只能是0或1。 字节：8个二进制位构成1个”字节(Byte)”，它是存储空间的基本计量单位。1个字节可以储存1个英文字母或者半个汉字，换句话说，1个汉字占据2个字节的存储空间。 字：”字”由若干个字节构成，字的位数叫做字长，不同档次的机器有不同的字长。例如一台8位机，它的1个字就等于1个字节，字长为8位。如果是一台16位机，那么，它的1个字就由2个字节构成，字长为16位。字是计算机进行数据处理和运算的单位。 字节序字节顺序是指占内存多于一个字节类型的数据在内存中的存放顺序，通常有小端、大端两种字节顺序。小端字节序指低字节数据存放在内存低地址处，高字节数据存放在内存高地址处；大端字节序是高字节数据存放在低地址处，低字节数据存放在高地址处。从上面两图可以看出，采用Big Endian方式存储数据是符合我们人类的思维习惯的。 所有网络协议也都是采用big endian的方式来传输数据的。所以有时我们也会把big endian方式称之为网络字节序。 联合体union的存放顺序是所有成员都从低地址开始存放，利用该特性，就能判断CPU对内存采用Little-endian还是Big-endian模式读写。 字节对齐现代计算机中内存空间都是按照byte划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但实际情况是在访问特定类型变量的时候经常在特定的内存地址访问，这就需要各种类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就是对齐。 为什么要进行字节对齐？1.某些平台只能在特定的地址处访问特定类型的数据;2.最根本的原因是效率问题，字节对齐能提⾼存取数据的速度。比如有的平台每次都是从偶地址处读取数据,对于一个int型的变量,若从偶地址单元处存放,则只需一个读取周期即可读取该变量，但是若从奇地址单元处存放,则需要2个读取周期读取该变量。 字节对齐的原则1.数据成员对齐规则：结构(struct)(或联合(union))的数据成员，第一个数据成员放在 offset 为0的地方，以后每个数据成员存储的起始位置要从该成员大小或者成员的子成员大小（只要该成员有子成员，比如说是数组，结构体等）的整数倍开始(比如int在32位机为4字节,则要从4的整数倍地址开始存储。2.结构体作为成员:如果一个结构里有某些结构体成员,则结构体成员要从其内部最大元素大小的整数倍地址开始存储。(struct a里存有struct b,b里有char,int ,double等元素,那b应该从8的整数倍开始存储。)3.收尾工作:结构体的总大小，也就是sizeof的结果，必须是其内部最大成员的整数倍，不足的要补齐。 操作系统基础中断与系统调用中断：所谓的中断就是在计算机执行程序的过程中，由于出现了某些特殊事情，使得CPU暂停对程序的执行，转而去执行处理这一事件的程序。等这些特殊事情处理完之后再回去执行之前的程序。中断一般分为三类：1.由计算机硬件异常或故障引起的中断，称为内部异常中断；2.由程序中执行了引起中断的指令而造成的中断，称为软中断（这也是和我们将要说明的系统调用相关的中断）；3.由外部设备请求引起的中断，称为外部中断。简单来说，对中断的理解就是对一些特殊事情的处理。 中断处理程序：当中断发生的时候，系统需要去对中断进行处理，对这些中断的处理是由操作系统内核中的特定函数进行的，这些处理中断的特定的函数就是我们所说的中断处理程序了。 中断的优先级：中断的优先级说明的是当一个中断正在被处理的时候，处理器能接受的中断的级别。中断的优先级也表明了中断需要被处理的紧急程度。每个中断都有一个对应的优先级，当处理器在处理某一中断的时候，只有比这个中断优先级高的中断可以被处理器接受并且被处理。优先级比这个当前正在被处理的中断优先级要低的中断将会被忽略1机器错误 &gt; 时钟 &gt; 磁盘 &gt; 网络设备 &gt; 终端 &gt; 软件中断 当发生软件中断时，其他所有的中断都可能发生并被处理；但当发生磁盘中断时，就只有时钟中断和机器错误中断能被处理了. 系统调用在讲系统调用之前，先说下进程的执行在系统上的两个级别：用户级和核心级，也称为用户态和系统态(user mode and kernel mode)。程序的执行一般是在用户态下执行的，但当程序需要使用操作系统提供的服务时，比如说打开某一设备、创建文件、读写文件等，就需要向操作系统发出调用服务的请求，这就是系统调用。 Linux系统有专门的函数库来提供这些请求操作系统服务的入口，这个函数库中包含了操作系统所提供的对外服务的接口。当进程发出系统调用之后，它所处的运行状态就会由用户态变成核心态。但这个时候，进程本身其实并没有做什么事情，这个时候是由内核在做相应的操作，去完成进程所提出的这些请求。 系统调用和中断的关系就在于，当进程发出系统调用申请的时候，会产生一个软件中断。产生这个软件中断以后，系统会去对这个软中断进行处理，这个时候进程就处于核心态了。 那么用户态和核心态之间的区别是什么呢？(经典问答)1.用户态的进程能存取它们自己的指令和数据，但不能存取内核指令和数据（或其他进程的指令和数据）。然而，核心态下的进程能够存取内核和用户地址2.某些机器指令是特权指令，在用户态下执行特权指令会引起错误对此要理解的一个是，在系统中内核并不是作为一个与用户进程平行的估计的进程的集合，内核是为用户进程运行的。 并发技术多任务多道程序：在上古时代，CPU 资源十分昂贵，如果让 CPU 只能运行一个程序，那么当 CPU 空闲下来（例如等待 I/O 时），CPU就空闲下来了。为了让 CPU得到更好的利用，人们编写了一个监控程序，如果发现某个程序暂时无须使用CPU时，监控程序就把另外的正在等待 CPU 资源的程序启动起来，以充分利用CPU资源。这种方法被称为 多道程序（Multiprogramming）。 分时系统：对于多道程序来说，最大的问题是程序之间不区分轻重缓急，对于交互式程序来说，对于 CPU 计算时间的需求并不多，但是对于响应速度却有比较高的要求。而对于计算类程序来说则正好相反，对于响应速度要求低，但是需要长时间的 CPU 计算。想象一下我们同时在用浏览器上网和听音乐，我们希望浏览器能够快速响应，同时也希望音乐不停掉。这时候多道程序就没法达到我们的要求了。于是人们改进了多道程序，使得每个程序运行一段时间之后，都主动让出 CPU 资源，这样每个程序在一段时间内都有机会运行一小段时间。这样像浏览器这样的交互式程序就能够快速地被处理，同时计算类程序也不会受到很大影响。这种程序协作方式被称为 分时系统（Time-Sharing System）。 多任务系统： (进程概念的提出)在分时系统的帮助下，我们可以边用浏览器边听歌了，但是如果某个程序出现了错误，导致了死循环，不仅仅是这个程序会出错，整个系统都会死机。为了避免这种情况，一个更为先进的操作系统模式被发明出来，也就是我们现在很熟悉的多任务（Multi-tasking）系统。操作系统从最底层接管了所有硬件资源。所有的应用程序在操作系统之上以 进程（Process） 的方式运行，每个进程都有自己独立的地址空间，相互隔离。CPU 由操作系统统一进行分配。每个进程都有机会得到CPU，同时在操作系统控制之下，如果一个进程运行超过了一定时间，就会被暂停掉，失去 CPU资源。这样就避免了一个程序的错误导致整个系统死机。如果操作系统分配给各个进程的运行时间都很短，CPU 可以在多个进程间快速切换，就像很多进程都同时在运行的样子。几乎所有现代操作系统都是采用这样的方式支持多任务，例如 Unix，Linux，Windows 以及 macOS。 进程进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。 进程的概念主要有两点：第一，进程是一个实体。每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。第二，进程是一个“执行中的程序”。程序是一个没有生命的实体，只有处理器赋予程序生命时，它才能成为一个活动的实体，我们称其为进程。 进程的基本状态1.等待态：等待某个事件的完成；2.就绪态：等待系统分配处理器以便运行；3.运行态：占有处理器正在运行。 运行态→等待态 往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。 等待态→就绪态 则是等待的条件已满足，只需分配到处理器后就能运行。 运行态→就绪态 不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。 就绪态→运行态 系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态 进程调度调度种类：高级、中级和低级调度作业从提交开始直到完成，往往要经历下述三级调度： 高级调度：(High-Level Scheduling)又称为作业调度，它决定把后备作业调入内存运行； 中级调度：(Intermediate-Level Scheduling)又称为在虚拟存储器中引入，在内、外存对换区进行进程对换。 低级调度：(Low-Level Scheduling)又称为进程调度，它决定把就绪队列的某进程获得CPU； 非抢占式调度与抢占式调度： 非抢占式：分派程序一旦把处理机分配给某进程后便让它一直运行下去，直到进程完成或发生进程调度进程调度某事件而阻塞时，才把处理机分配给另一个进程。 抢占式：操作系统将正在运行的进程强行暂停，由调度程序将CPU分配给其他就绪进程的调度方式。 调度策略的设计:响应时间: 从用户输入到产生反应的时间周转时间: 从任务开始到任务结束的时间CPU任务可以分为交互式任务和批处理任务，调度最终的目标是合理的使用CPU，使得交互式任务的响应时间尽可能短，用户不至于感到延迟，同时使得批处理任务的周转时间尽可能短，减少用户等待的时间。 调度算法：1.FIFO或First Come, First Served (FCFS)调度的顺序就是任务到达就绪队列的顺序。公平、简单(FIFO队列)、非抢占、不适合交互式。未考虑任务特性，平均等待时间可以缩短 2.Shortest Job First (SJF)最短的作业(CPU区间长度最小)最先调度。可以证明，SJF可以保证最小的平均等待时间。Shortest Remaining Job First (SRJF):SJF的可抢占版本，比SJF更有优势。SJF(SRJF): 如何知道下一CPU区间大小？根据历史进行预测: 指数平均法。 3.优先权调度每个任务关联一个优先权，调度优先权最高的任务。 注意：优先权太低的任务一直就绪，得不到运行，出现“饥饿”现象。FCFS是RR的特例，SJF是优先权调度的特例。这些调度算法都不适合于交互式系统。 4.Round-Robin(RR)设置一个时间片，按时间片来轮转调度（“轮叫”算法）优点: 定时有响应，等待时间较短；缺点: 上下文切换次数较多；如何确定时间片？时间片太大，响应时间太长；吞吐量变小，周转时间变长；当时间片过长时，退化为FCFS。 5.多级队列调度－ 按照一定的规则建立多个进程队列－ 不同的队列有固定的优先级（高优先级有抢占权）－ 不同的队列可以给不同的时间片和采用不同的调度方法存在问题1：没法区分I/O bound和CPU bound；存在问题2：也存在一定程度的“饥饿”现象； 6.多级反馈队列在多级队列的基础上，任务可以在队列之间移动，更细致的区分任务。可以根据“享用”CPU时间多少来移动队列，阻止“饥饿”。最通用的调度算法，多数OS都使用该方法或其变形，如UNIX、Windows等。 进程同步临界资源与临界区：在操作系统中，进程是占有资源的最小单位（线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源）。但对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源。对于临界资源的访问，必须是互斥进行。也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。而进程内访问临界资源的代码被成为临界区。 对于临界区的访问过程分为四个部分：1.进入区:查看临界区是否可访问，如果可以访问，则转到步骤二，否则进程会被阻塞2.临界区:在临界区做操作3.退出区:清除临界区被占用的标志4.剩余区：进程与临界区不相关部分的代码 解决临界区问题可能的方法：1.一般软件方法2.关中断方法3.硬件原子指令方法4.信号量方法 信号量：可以直接指向Semaphore-wiki. 死锁死锁: 多个进程因循环等待资源而造成无法执行的现象。死锁会造成进程无法执行，同时会造成系统资源的极大浪费(资源无法释放)。死锁产生的4个必要条件： 互斥使用(Mutual exclusion)指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。 不可抢占(No preemption)指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。 请求和保持(Hold and wait)指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。 循环等待(Circular wait)指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。 死锁避免——银行家算法思想: 判断此次请求是否造成死锁若会造成死锁，则拒绝该请求. 进程间通信本地进程间通信的方式有很多，可以总结为下面四类： 消息传递（管道、FIFO、消息队列） 同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量） 共享内存（匿名的和具名的） 远程过程调用（Solaris门和Sun RPC） 线程多进程解决了前面提到的多任务问题。然而很多时候不同的程序需要共享同样的资源（文件，信号量等），如果全都使用进程的话会导致切换的成本很高，造成 CPU 资源的浪费。于是就出现了线程的概念。 线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。 线程具有以下属性：1.轻型实体线程中的实体基本上不拥有系统资源，只是有一点必不可少的、能保证独立运行的资源。线程的实体包括程序、数据和TCB。线程是动态概念，它的动态特性由线程控制块TCB（Thread Control Block）描述。2.独立调度和分派的基本单位。在多线程OS中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位。由于线程很“轻”，故线程的切换非常迅速且开销小（在同一进程中的）。3.可并发执行。在一个进程中的多个线程之间，可以并发执行，甚至允许在一个进程中所有线程都能并发执行；同样，不同进程中的线程也能并发执行，充分利用和发挥了处理机与外围设备并行工作的能力。4.共享进程资源。在同一进程中的各个线程，都可以共享该进程所拥有的资源，这首先表现在：所有线程都具有相同的地址空间（进程的地址空间），这意味着，线程可以访问该地址空间的每一个虚地址；此外，还可以访问进程所拥有的已打开文件、定时器、信号量等。由于同一个进程内的线程共享内存和文件，所以线程之间互相通信不必调用内核。 线程共享的环境包括：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。 协程协程，又称微线程，纤程。英文名Coroutine。协程可以理解为用户级线程，协程和线程的区别是：线程是抢占式的调度，而协程是协同式的调度，协程避免了无意义的调度，由此可以提高性能，但也因此，程序员必须自己承担调度的责任，同时，协程也失去了标准线程使用多CPU的能力。 IO多路复用IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合： 1.当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。2.当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。3.如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。4.如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。5.如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。 与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。 Resource1.浅谈进程同步与互斥的概念.2.进程间同步——信号量.3.线程–wiki.4.进程、线程和协程的理解.5.协程–廖雪峰.6.生产消费者问题. 这几个附加的resource我自己也没来得及看，我明天再看吧，有些基础还是难的，重新过一遍还不错。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"虚拟机迁移在传输层(tcp)代码优化部分","slug":"ns3_tcp_optimization","date":"2017-10-11T12:48:39.841Z","updated":"2017-06-05T13:00:18.000Z","comments":true,"path":"2017/10/11/ns3_tcp_optimization/","link":"","permalink":"http://yoursite.com/2017/10/11/ns3_tcp_optimization/","excerpt":"","text":"之前就有讲过因为ns2没有办法外接emulator所以我们使用ns3来做和mininet的连接，至于simulator和emulator之间的差别，嗯，等我写完这篇文章，回来问下Q同学答辩的情况，她要是不开心那我就不写了，毕竟知识是我自己的，想po给你就po给你，不想po给你，你就要自学。 关于ns3部分的tcp部分改进代码，我也会po到我的github上［Xuanlong-Github］.主要的改进点不难，分为两个。 1.如何在正确的地方得到时间 2.如何在正确的地方导入数据接下来我分开讲这两个东西。如何正确的得到时间无论是ns3和ns2都有自己的时钟机制，基本上都是使用simulator::now()这个函数调用，而且ns3的时钟机制更加精确，所以你需要什么精度需要你自己去调用，这个不是重点，重点是在ns2里面时钟的类型就是double型，但是ns3里面不是，ns3里面的时钟是两个参数，所以要转换成double型其实很麻烦。一般用如下方式转12#include \"ns3/time.h\"/*具体是不是这个头文件我记不到了，自己看一下*/double thistime = Simulator::Now().GetSeconds(); 这样调用出来的就是double型，这个时间点插在那里呢？一个是发送SYN包的时候，记下一个点一个是application里面的数据发送完时，记下一个点 /我要说一下，应用发完数据不等同于buffer发完数据，所以这里你要自己计算实际上应用的数据到底发完了没，所以在第一个时间点的时候你还要用序列号和数据长度来验证自己到底发了多少数据/这两个点可以让你获知你现在发送数据用了多久时间 如何正确的导入数据我们的改进本来就是想要抹平轮次间的间隙，在常规的发送方式下，要等buffer数据发送完之后才会下一轮，实际上可能出现的突发性流量和轮次间末尾丢包的问题就是在于要等buffer置0，实际上application扫完第一轮可以直接去第二轮的，所以这才是问题的关键，所以数据的导入应该在第二个点之后立马进入第二轮。 这样算法就比较完整了关于sdn部分等有空再写，这部分的代码等文章发表我再po出来，不然不是雪崩。。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"NS3-integration with mininet","slug":"ns3_mininet_intergation","date":"2017-10-11T12:48:39.839Z","updated":"2017-06-09T03:14:26.000Z","comments":true,"path":"2017/10/11/ns3_mininet_intergation/","link":"","permalink":"http://yoursite.com/2017/10/11/ns3_mininet_intergation/","excerpt":"","text":"这个工作大约在我和敬轩调研了两天之后就放弃了，现在写一下调研的结果,最好还是host过一下realnetwork。 ns3为什么要做intergation？我们之所以这么做是因为ns2没有办法做sdn部分，之前在ns3-introducation部分有看到，ns3下面是通过rawsocket－&gt; realnetwork所以能外接到真实网络。所以才想到换成ns3的方案，于是便在ns3修改vmmodel，准备等mininet那边接过来。但是我们发现事情没有想象的那么简单，之前我门认为根据github上的link-model可以将ns3和mininet的节点绑定起来，然后application直接将数据扔到节点，再接由mininet控制。实际上它是不是这么操作的呢，我们做了以下几件事。 将github里面的代码git到本地进行编译，这个link我会贴出来，因为他类似一篇指导性的文章一样，发现其实里面的ns3的版本和mininet的版本是非常的低的，看了一下大约是14年最后更新的，我们git下来发现其实不能用，然后我们发现一个类似于将各种软件结合的软件OpenNet. OpenNet这个软件集合了Estinet,NS3,Mininet看起来和我们的需求非常近，我们立马git下来发现是可以用的，这大概是最不幸的事情了，然后我们在这里面做ns－intergarion，发现里面的code是和link-model一模一样，编译完成后发现通过了，但是怎么使用呢？ 我将bulk-send的文件执行，可以接受到数据，运行mininet 使用tcpdump监听数据发现没有任何数据？这是非常不正确的行为，这就说明一个问题ns3和mininet没有接起来。接下来的事情就是如何把这两个东西接起来。－ 我们按照link的行为走了一圈，发现有个link模块叫做，btintf.py这个文件是测试文件之一是可以运行的，很明显就是绑定ns的节点和mininet的节点，里面的语句也很清晰，比如说：1h0ns = ns.network.nodes(); 这个模块非常简单，什么内容都没有，只好追根溯源，发现他的模块都来自ns3.py这个文件，（其实有个问题我是比较好奇的，为什么这么多人都是在做wireless network而常用的csma链路没人做，是因为觉得太简单了吗？真是一群扑街，欺负新手！）这个ns3模块我看完之后脑子都懵逼了，没有application的caller function,这个问题太大了，都不知道他正常运行的拓扑函数是数据来自哪里的？－ 这个问题我当时决定撂在这里，因为已经看不出来问题在哪里了，然后我跑回去看架构，我给你们分析一下架构，先把架构图贴一下。左边其实是mininet的部分，右边是ns3部分，中间是靠tap-deviece和tap－bridge这两个接口接在一起的，那tap-bridge是什么，我又跑回去翻看ns-3部分架构确实是有tap-bridge的而且这就是interface的接口，我大概猜到btintf.py的模块可能不是完整的，所以没有应用模块，我就去找了又tap-bridge的文件做测试。－ 有tap-bridge部分的文件在/ns-3.23/src/tar-bridege这个文件夹下面，有两个文件比较有用，一个是tap-csma，一个是tap-wifi－dumbbel文件，第一个是p2p链路，第二个是带有csma子网的链路，所以我先跑第一个，（这个跑的方式和普通不一样，具体怎么跑code里面有写）跑完之后继续用tcpdump监听，发现linux和mininet都收不到数据，但是可以自己ping自己，第二个文件也是这样，但是好消息就是tap-bridge确实会产生一个thetap作为网卡来发送和接收数据，我又去看了tao-bridge，再次ping了linux和ns3确实可以ping过去，但是ns3怎么ping linux呢？因为我要确认ns3可以和外部交换信息，我就去读源码，发现居然没有目的地址，源地址是递加的，卧槽？什么情况，没有目的地址，目的地址是用节点代替，节点的ip递增，我确定代码里没有说往外ping的事情，ok，我这时候怀疑tap-bridge是不是只能模拟网口，在ns3内部使用。好，我们现在总结一下，ns3和mininet做intergation的时候，ns3.py文件里面没有绑定application，同时tap-bridge可能是ns3自己构建的自洽网路。 怎么做integration?OpenNet我觉得link-model既然不能用的话，那么去看OpenNet，我先去查阅了论文，我把这两篇论文贴到resource里面，你们可以直接下载，论文证明了一件事情mininet-wifi via ns3是可行的，我看了下论文的作者，卧槽NCHU，国立交大，在搜了一下作者发现是这边学长的好友，我发了邮件表示想去实验室问问，不得不说台湾做网络还是屌炸天的,柯志亨，陈健老师，曾建超老师，基本上都是这个领域的扛把子，老师们都说这是14年做的，已经毕业了，给我邮箱让我自己联系，不用看了，工作狗是不会理你的，还是自己看吧，继续看OpenNet架构，我忽然看见一个东西如下图。卧槽啊！！！！！！！！！！！！！！！！！！！！！！！！！！！我忽然顿悟了，我应该用emu才对啊，可以把ns3当成一个host流量打到eth0，然后eth0接到mininet，那不就行了，如果host不够，用xen和kvm模拟八个虚拟机啊！！我为自己的弱智震惊了。我这时又一抬头，眼一黑，妈个鸡，tap-brdige是3.16版，现在都用fdNetdevice，这种差个0.1版基本上都会出bug，我顿时觉得我昨天晚上白熬了。 emu模块这个时候就很顺了，下面这个图一看我就知道稳了，我找了下别的文件，发现ping不能算application，但是可以用ns/application－module.h去自己改 怎么改，我发完文章会把代码po上来。好了，我总结一下，ns3－integration其实还不完善，而且mininet和ns3版本老旧，没人维护，还是别用了。 现在采取的做法不如直接把ns3作为一个host打流量到mininet，来实现ns3和mininet的链接。 Resource1.[OpenNet:A simulator for software-defined wireless local area network].2.Evaluation of mininet-wifi integration via ns-3.3.[Link modeling using ns 3-github].4.[OpenNet-github].5.[HOWTO make ns-3 interact with the real world].这个救了我一命，你爱看不看。6.[Emu NetDevice].这是emu部分，看看吧。 作为计算机的我还是要说下我的环境，ns-3.25 mininet 2.2.0，ubuntu 14.04 哎呀，今天的逻辑有些不对，但是就到这里吧，不然吴秉原要喷我了，有什么问题可以email我。如果我还是在校生我会回复你的。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"ns-3网络模拟器基础及应用/NS-3其他模块(TCP 四)","slug":"ns3_linux_tcp","date":"2017-10-11T12:48:39.837Z","updated":"2017-05-24T02:19:44.000Z","comments":true,"path":"2017/10/11/ns3_linux_tcp/","link":"","permalink":"http://yoursite.com/2017/10/11/ns3_linux_tcp/","excerpt":"","text":"TCP协议分析1.对TCP协议的一般性支持。代码存放在src/network中，主要有两个抽象类。 TcpSocket:这个类定义在src/internet/model/tcp-socket.{cc,h}中，这个类的主要作用是用成员变量保存TCP套接字的属性，这样就能保证这些属性的可重用性(虚函数的主要特点)，例如成员变量InitialCwnd可以被每一个从该类继承的任何子类调用。 TcpSocketFactory: 这个类的作用是被later-4 protocal对象用来创建TCP套接字ns-3中有两个版本的TCP：－ 1.TCP－ 2.network simulation cradle(NSC)TCP 2.ns-3 TCPns-3里面有很多tcp类型，但是都是基类为TcpSocketBase，现在的默认版本是TCP NewReno。下面还是举个栗子，如何创建一个TCP接收器：123456uint16_t port =50000;Address sinkLocalAddress(InetSocketAddress (Ipv4Adress::GetAny(),port));PacketSinkHelper sinkHelper(\"ns::TcpSocketFactory\",sinkLocalAddress);ApplicationContainer sinkApp = sinkHelper.Install(serverNode);sinkApp.Start (Seconds(1.0));sinkApp.Stop (Seconds(10.0)); 同样地，创建为服务器端OnOff应用程序发送的TCP数据：12OnOffHelper clientHelper (\"ns3::TcpSocketFactory\",Address()); /*这里没有特殊的要求factory创建的就是默认的TCP*/ 如果用户想要一个套接字的指针以方便设置套接字的属性，那么可以通过Socket::CreateSocket()函数创建套接字，他的返回值就是一个套接字指针，通常会通过配置系统函数Config::Set()把属性和TcpL4Protocol对象相关联。 TCP部分具体的表现形式其实没有太大的意义，主要是这边模块分的很清晰，所以在连接套接字的时候应该不会很难，主要是Cwnd的窗口这么改会比较，这就又牵扯到序列号了和三次握手了。下一篇我想了很久暂时先跳过网络设备模块，直接去看Application是怎么实现的，怎么去实现一个based-sdn的虚拟机模型。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"ns-3网络模拟器基础及应用/NS-3其他模块(应用层模块 五)","slug":"ns3_linux_app","date":"2017-10-11T12:48:39.835Z","updated":"2017-06-22T13:36:02.000Z","comments":true,"path":"2017/10/11/ns3_linux_app/","link":"","permalink":"http://yoursite.com/2017/10/11/ns3_linux_app/","excerpt":"","text":"Application类Application类是所有应用程序的基类，Application类提供了一些行为的基本原型，SetStartTime()、SetStopTime()、GetNode()、SetNode()等。ns-3为用户提供了多种网络应用模型，如下： UdpClientServer; UdpEcho; Radvd; Ping6; PacketSink; OnOffApplication; BulkSendliction; 我们所做的改进都是基于TCP的，所以前面的四个对我现在研究的方向没什么太大帮助，先扔掉，登什么时候我心情好了再写，麻蛋，大家都去California享受阳光了，而我还在划水，说好的California Dreaming呢，蓝瘦，继续写！ 后面的三个中PacketSink这个应用模块的目的是接收远端发来的数据分组，因此大多数情况下是配合其他模块使用，比如OnOffApplication、BulkSendliction等。相关类的API是：1234class PacketSink:public Application &#123; &#125;;class PacketSinkHelpe &#123; &#125;;class OnOffHelper &#123; &#125;;class BulkHelper &#123; &#125;; 上面是主要用到的API。 举两个栗子 example1：tcp-star-server.cc(星型网络结构的脚本) ns-3/examples/tcp创建应用程序，OnOffApplication和PacketSink模块。 12345678910PacketSinkHelper sinkHelper(\"ns::TcpSocketFactory\",sinkLocalAddress);ApplicationContainer sinkApp = sinkHelper.Install(serverNode);sinkApp.Start (Seconds(1.0));sinkApp.Stop (Seconds(10.0));OnOffHelper clientHelper (\"ns::TcpSocketFactory\",Address());clientHelper.SetAttribute(\"OnTime\",StringValue(\"ns3::ConstantRandomVarible[Constant=1]\"));clientHelper.SetAttribute(\"OffTime\",StringValue(\"ns3::ConstantRandomVarible[Constant=0]\"));...这部分是常规的节点属性配置，不会的话自己翻书，或者弃疗，反正要GG，不如不学。 example2tcp-bulk-send.cc ns-3/examples/tcp创建应用程序，BulkSendliction和PacketSink模块。 123456789101112在节点0创建BulkSendliction应用程序uint16_t port = 9;BulkSenderHelper soure(\"ns::TcpSocketFactory\",InetSocketAddress(i.GetAddress(1),port));source.SetAttribute(\"MaxBytes\",UintegerValue(maxBytes));ApplicationContainer sourceApps = source.Install (nodes.Get(0));source.Start (Seconds(1.0));source.Stop (Seconds(10.0));在节点1创建PacketSinkApplication应用程序PacketSinkHelper sink (\"ns::TcpSocketFactory\",InetSocketAddress(Ipv4Address::GetAny(),port))ApplicationContainer sinkApps = source.Install (nodes.Get(1));sinkApps.Start (Seconds(1.0));sinkApps.Stop (Seconds(10.0)); 比较可惜这里面也没有讲具体的Application架构，但是基本的构建方式我已经懂了，明天我会去看源码，早日把Vm migration model写出来。关于其他模块的记录可能要做完实验了，之后应该更新的都是代码部分了。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"ns-3网络模拟器基础及应用/NS-3内核(Tracing系统部分 三)","slug":"ns3_linux_5.6","date":"2017-10-11T12:48:39.830Z","updated":"2017-06-22T13:36:18.000Z","comments":true,"path":"2017/10/11/ns3_linux_5.6/","link":"","permalink":"http://yoursite.com/2017/10/11/ns3_linux_5.6/","excerpt":"","text":"在我们以往的调试的时候都是使用cout语句来进行信息的输出。在ns-3中由于里面的块都是独立的，而且信息很庞杂，所以用cout语句信息量太大，难以辨认一般我会在调试的时候使用一下，在ns-3里面比较常用的是日志系统Logging。 举个栗子：12345678#include \"ns3/core-module.h\"NS_LOG_COMPOENT_DDFINE(ScratchSimultor);using namespace ns3;int main()&#123; NS_LOG_UNCOND(\"Scratch Simulator\"); return 0;&#125; Logging系统的等级制度其实会给予很大的帮助常见的INFO和FUNCTION就够了，但是对于小程序用Logging是适用的，但是大型项目会使用Tracing系统。Tracing不会改变内核代码，不用再次编译就可以允许用户进入系统内核来获取所需要的信息。 综述Tracing 分为Tracing Sources、Tracing Sinks和将Tracing Source和Tracing Sinks关联在一起的3个部分。 Tracing Sources：是一个实体用来标记仿真中发生的时间，也可以提供一个访问底层数据的方法。 Tracing Sink：消费信息。 123456789101112131415class Myobject:public Object&#123;public: static TypeId GetTypeId(void); &#123; static TypeId tid = TypeId (\"Myobject\") .SetParent (Object::GetTypeId()) .AddConstructor&lt;Myobject&gt; () .AddTraceSource(\"Myinteger\",\"An integer value to trace.\", MakeTraceSourceAccessor(&amp;Myobject::m_myInt)); return tid; &#125; Myobject() &#123;&#125; TraceValue&lt;Uint32_t&gt; m_myInt;&#125;; 每一个要追踪的数据都必须属于一个特定的类，这里定义这个类为MyObject,要追踪的数据为m_myInt. 1234567int main(int argc, char *argv[])&#123; Ptr&lt;Myobject&gt; myobject = CreateObject&lt;Myobject&gt; (); myobject -&gt; TraceConnectWithoutContext(\"Myinteger\",MakeCallback(&amp;IntTtace)); myobject -&gt; m_myInt = 1234; return 0;&#125; 因为就是TraceConnectWithoutContext 这个函数将Tracing Source和Tracing Sinks相关联。只要调用这个函数，当Tracing Source数据m_myInt发生改变的时候，IntTrace函数才会被调用。 配置系统上面的TraceConnectWithoutContext函数比较少用，常见的都是使用”config path”的子系统从系统中选取用户所要使用的Trace Sources. 下面这个函数CourseChange就是要定义的Trace Sink.12345void CourseChange(string context,Ptr&lt;const MobilityModel&gt; model)&#123; Vector position = model-&gt;GetPosition(); NS_LOG_UNCOND(context &lt;&lt; \" x= \" &lt;&lt; position.x &lt;&lt; \" y= \" &lt;&lt; position.y);&#125; 下面是使source和sink相关联的函数1234ostringstream oss;oss &lt;&lt; \"/NodeList\" &lt;&lt; wifiStaNodes.Get(nWifi-1)-&gt;GetId() &lt;&lt; \"/$ns3::MobilityModel/CoureChange\";Config::Connect(oss.str(),MakeCallback(&amp;CourseChange));/*使用了类Config的一个静态函数connect将二者关联系起来*/ 如何确定Trace Sourcesns3中是有定义好的可以直接使用的Trace Sources。路径在：ns3/API/Modules/C++ ConstructsUsed By All Modules/The list of all trace sources.考虑到下辈子美利坚，把链接贴出来[link]. 如何确定Tace SinkTace Sink实际上就是一个函数，所以可以参照系统给出的一些函数去写，比如ns-3/examples/wireless/mixed-wireless.cc 里面的CourseChangeCallback函数。要自己去查询一些文档，提高自己的搜索和提高的能力。 下一节就会把中心从ns-3内核部分转移到ns-3其他模块部分，因为做科研还是要把重心放到自己作的部分，我比较关心的两部分分别是Application部分和Tcp部分，所以接下来会对这两部分进行记录，同时在Github上po出code,做完这部分我会考虑整理下ns-2部分的入门和模块分析。 发现ns-3的Modules部分很有意思，查阅起来很方便，也给自己留个[ns-3-modules-link].","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"NS-3网络模拟器基础及应用/ns-3内核(属性系统部分 二)","slug":"ns3_linux_5.5","date":"2017-10-11T12:48:39.828Z","updated":"2017-06-22T13:36:14.000Z","comments":true,"path":"2017/10/11/ns3_linux_5.5/","link":"","permalink":"http://yoursite.com/2017/10/11/ns3_linux_5.5/","excerpt":"","text":"属性系统对象概述 对使用的网络构件进行组织和模拟拓扑 对网络构件中实例化的模型所使用的参数值进行设置 12345678node.cc/*文件对GetTypeId*/class Node : public Object&#123;public: static TypeId GetTypeId (void); ...&#125; 我们去查找一个GetTypeId的定义 1234567891011121314151617181920212223242526272829TypeId Node::GetTypeId (void)&#123; static TypeId tid = TypeId (\"ns3::Node\") .SetParent&lt;Object&gt; () .SetGroupName(\"Network\") .AddConstructor&lt;Node&gt; () .AddAttribute (\"DeviceList\", \"The list of devices associated to this Node.\", ObjectVectorValue (), MakeObjectVectorAccessor (&amp;Node::m_devices), MakeObjectVectorChecker&lt;NetDevice&gt; ()) .AddAttribute (\"ApplicationList\", \"The list of applications associated to this Node.\", ObjectVectorValue (), MakeObjectVectorAccessor (&amp;Node::m_applications), MakeObjectVectorChecker&lt;Application&gt; ()) .AddAttribute (\"Id\", \"The id (unique integer) of this Node.\", TypeId::ATTR_GET, // allow only getting it. UintegerValue (0), MakeUintegerAccessor (&amp;Node::m_id), MakeUintegerChecker&lt;uint32_t&gt; ()) .AddAttribute (\"SystemId\", \"The systemId of this node: a unique integer used for parallel simulations.\", TypeId::ATTR_GET || TypeId::ATTR_SET, UintegerValue (0), MakeUintegerAccessor (&amp;Node::m_sid), MakeUintegerChecker&lt;uint32_t&gt; ()) ; return tid;&#125; 函数SetParent()为该声明的基类，方便在使用GetObject()函数时安全地进行向上或向下类型转换。 属性系统ns-3提出属性系统的机制的目的就是为了管理和组织仿真中的内部对象。主要原因在于，用户在仿真过程中要不断地修改已经存在的仿真脚本，来跟踪、收集和研究仿真程序中变量或数据的变化，比如 想要跟踪第一个接入点的无线接口上的分组 用户想要获取并记录模拟上所有被使用的值分析类DropTailQuenue12345678910111213141516class DropTailQueue : public Queue&#123;public: static TypeId GetTypeId (void); /** * \\brief DropTailQueue Constructor * * Creates a droptail queue with a maximum size of 100 packets by default */ DropTailQueue (); virtual ~DropTailQueue();private: std::queue&lt;Ptr&lt;QueueItem&gt; &gt; m_packets; //!&lt; the items in the queue&#125;; 对于一个已经实例化的对象，设置或获取该对象的值，像上述的情况我们一般用Get()函数来实现，ns-3用TypeId类来实现。 设置默认值 通过指针访问属性值 通过一个脚本例子来说明如何在脚本中操纵属性系统中的数据1.设置默认值12Config::SetDefault (\"ns3::DropTailQueue::MaxPackets\",StringValue(\"80\"));Config::SetDefault (\"ns3::DropTailQueue::MaxPackets\",UintegerValue(80)); 1234567891011121314151617class DropTailQueue : public Queue&#123;public: static TypeId GetTypeId (void); /** * \\brief DropTailQueue Constructor * * Creates a droptail queue with a maximum size of 100 packets by default */ DropTailQueue (); virtual ~DropTailQueue();private: std::queue&lt;Ptr&lt;QueueItem&gt; &gt; m_packets; //!&lt; the items in the queue uint32_t m_maxPackets; /*这就是我们下面说到的默认初始值*/ &#125;; Function:将之后将要声明的DropTailQueue类的实例化设置默认值，如果之后生成一个DropTailQueue对象dtq,那么dtq的成员变量m_maxPackets的默认值是80. 2.设置完默认值以后用户就可以实例化自己的对象1234567Ptr&lt;Node&gt; n0 = CreateObject&lt;Node&gt; ();Ptr&lt;PointToPointNetDevice&gt; net0 = CreateObject&lt;PointToPointNetDevice&gt; ();n0-&gt;AddDevice (net0);Ptr&lt;Queue&gt; q = CreateObject&lt;DropTailQueue&gt; ();net0-&gt;SetQueue (q); Function: 上述代码创建了一个唯一的节点(Node0),并且在这个节点上创建了一个唯一的PointToPointNetDevice网络设备(NetDevice0),然后为其添加了一个尾部分组丢失队列。 通过指针访问属性值首先创建一个指针变量(而不是创建一个指针)。 PointerValue tmp;然后为指针变量赋值： net0-&gt;GetAttribure (“TxQueue”,ptr);获取队列： Ptr txQueue = ptr.Get ();下面通过GetObject函数来安全地把txQueue向下类型转化： Ptr dtq = txQueue-&gt;GetObject &lt;&gt;(DropTailQueue); 3.用户也可以通过基于命名空间的方式访问属性值 1.一个是通过指针访问属性值的方法 2.另一个是通过使用配置命名空间的方法来操作属性值 ns-3的扩展性ns-3作为一个开源的系统，可扩展性是系统必须支持的特性 添加现有类的成员变量到元数据系统中example A： 考虑类TcpSocket的一个成员变量：uint32_tm_cWnd 假设使用TCP模块的某个人想要使用元数据获得或设置该变量的值。如果ns-3还没有提供这个变量，用户可以在元数据系统中添加如下声明：1.AddAttribute (\"Congestion window\",\"Tcp congestion window (byte)\",UintergerValue(1),MakeUintergerAccessor(&amp;TcpSocket::m_cWnd),MakeUintergerChecker&lt;uint16_t&gt;()) 现在用户可以使用指向TcpSocket的指针来执行设置和获取操作，而不是显示的添加这些函数。 向属性系统中添加自定义的类example B:把自定义的类A添加到属性系统中。首先在a.h头文件中声明类A12345678910class A:public Object &#123;public: ... static TypeId GetTypeId(void); ...private: int16_t m_int16; ...&#125;;NS_OBJECT_ENSURE_REGISTERED(A); 上述函数使用了默认构造函数，除了要声明函数GetTypeId和NS_OBJECT_ENSURE_REGISTERED(A)；和标准C++类有区别意外，别的都一样。然后在a.cC文件里定义GetTypeId，如下：123456static TypeId GetTypeId (void) &#123; static TypeId tid = TypeId(\"ns3::A\") .SetParent&lt;object&gt;() .addAttribute(\"TestInt16\",\"help text\",InterValue(-2),MakeIntergerAccessor(&amp;A::m_int16),MakeInterChecker&lt;int16_t&gt;); return tid;&#125; 下一节我会记录ns3提供的Tracing系统。 以下链接或许对你有用：1.[ns-3-dev/API].2.[Wiki-nsnam].","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"NS-3网络模拟器基础及应用/ns-3内核(对象模型部分 一)","slug":"ns3_linux","date":"2017-10-11T12:48:39.820Z","updated":"2017-06-22T13:36:24.000Z","comments":true,"path":"2017/10/11/ns3_linux/","link":"","permalink":"http://yoursite.com/2017/10/11/ns3_linux/","excerpt":"","text":"对象模型ns-3 中的变量说明和初始化的语法规则在ns3中同样适用，同时ns3在原有的基础上增加了标准C++的特征，亦即ns3中特有的对象模型。ns-3中使用的设计模式包括经典的面向对象设计、接口与实现分离、非虚拟的公共借口设计模式，对象聚合以及引用计数内存管理模式。 面向对象编程这部分请自学= =！ 对象基类ns-3中提供了3个对象基类供用户继承，这三个类是： Object ObjectBase SimpleRefCount ns-3不强迫每个类都继承这3个类，但是这3各类包含了ns-3的所有特性。 内存管理与引用计数指针(Ptr) 引用计数指针(Ptr) CreateObject和Create在ns-3中针对包含引用计数的对象，就是通过模板函数CreateObject和Create来创建。对于基类为Object的类创建对象的方法是：1Ptr&lt;Myobject&gt; mo = CreateObject&lt;Myobject&gt;(); 聚合查询接口设计模式，ns-3中类Node是使用聚合的一个很好的例子 ns-3中没有Node子类，所以任何终端使用相同的Node，但是构建协议则是聚合起来的。1234567891011static voidAddIpv4Stack(Ptr&lt;Node&gt; Node)&#123; Ptr&lt;Ipv4L3Protocol&gt; ipv4 = CreateObject&lt;IPv4L3Protocol&gt; (); /*创建一个IPV4协议的指针独享，接着把IPV4协议聚合到节点中*/ ipv4-&gt;SetNode (node); node-&gt;AggregateObject (ipv4); Ptr&lt;IPv4Impl&gt; ipv4Impl = CreateObject&lt;IPv4Impl&gt; (); ipv4Impl-&gt;SetIPv4 (ipv4); node-&gt;AggregateObject (ipv4Impl)&#125; －－－下一节会介绍ns-3的属性系统","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"NS2构建以及关于虚拟机模型和tcp的改进","slug":"ns_vmmodel_tcp","date":"2017-10-11T12:48:39.818Z","updated":"2017-06-01T14:59:40.000Z","comments":true,"path":"2017/10/11/ns_vmmodel_tcp/","link":"","permalink":"http://yoursite.com/2017/10/11/ns_vmmodel_tcp/","excerpt":"","text":"ns2 simulator关于搭建ns2模拟器没什么好说的，不会的话建议转行。讲一下比较关键的路径配置，常见的配置是123$ 1.cd ~$ 2.gedit .bashrc /*这是linux的PATH，所以一般是配置在这里，但是可能会出现问题，等下我讲可能会出什么问题*/$ 3.export PATH=/home/balabala;/*这里就是＝号两边不要有空格，linux路径就两种一种是带$一种是不带直接用“/”的，理论上没什么差，你怕出问题就按这个配*/ 这么配置可能你新开terminal执行ns的时候可用，但是也有另一种可能，就是你的路径其实错了，这样你的终端执行什么都会显示错误，所以一般我们开调试的时候会开一个root权限的端口用来回退，所以在执行第二条指令的时候你其实可以开一个root终端。上面这个路径很多人这么配没有错，我的是错的，但是因为我还有环境所以我不可能重装我的PATH的路径是:1$ gedit /root/.bashrc 上面的环境变量之后变了之后你都要执行1$ source .bashrc 在新开终端执行ns看见％就表示成功，如果发现报错或者功能不全那就是你的依赖包没装好，你可以整个update下，最稳定的版本还是ubuntu 14.04,如果这种环境都出问题，以后的环境出问题的概率会更大，还是把基本的jdk什么的调好了，再来使用ubuntu较好。 vm_model这部分的代码我会po到我的github［Xuanlong-Github］.采用的模型是华中科技大学刘海坤老师的performance and energy model。这篇文章来自paper［Performance and energy modeling for live migration virtual］.刘海坤老师人非常好，学术上也很严谨，我也像他请教过这篇文章的内容，所以有什么关于vm live migration问题你也可以给我或者刘老师发邮件。刘海坤老师主页[HaiKun-Liu],实验室主页[Lab-CGCL－Cluster and Grid Computing Lab]. 哈哈上次去他主页他还不是副教授，我还没有女朋友，现在他是副教授了，我他么还是没有女朋友～。 application这部分的主要贡献在于轮次的流量产生，实际上我们在做的时候用的就是ftp的源，他就是不断的发送数据，所以通过一个processVM进行模型的迭代和抽象，做一个应用分发。 tcp部分这个部分主要是能找到buffer变空的位置，把时间点打下去，simulator::now()这个位置找好，然后把队长序列号都扔去，就可以大概知道每一轮的传输时间和buffer大小，具体的实现可以看我的github在tcp部分上的实现。 tcl语言部分这个部分主要是脚本编辑拓扑，但是怎么把参数传进去就涉及到参数的bind实际上ns2看起来只有c++和TCL的两种绑定实际上，他是有两个绑定口的，嗯 我要不要写呢，太麻烦了～我大致讲一下，就不画图了，实际上两个口在哪里呢？1.tcl本身是构成ns2的一个重要部分，很大一部分关键内核是tcl写的，这里会有一个绑定，即tcl bind c++2.另外就是你实验要传参，你也需要绑定，为什么呢？因为你的实验脚本是tcl但是你的实现语言是c++，所以有两个绑定机制。总结就是 TCL －－ C++ －－ TCL其实我现在觉得ns2没那么难，ns3 挖槽，真难！！ 关于ns2如果你的硬件条件实在不够可以考虑去做，实际上ns3虽然难，但是模块很细很散，虽然难但是是值得一学的，希望大家都加入ns3我就去去加入SDN (逃…. 6.15的HPCC做完，两个月就开始校招了，慌成马了！唉，如果在深圳的话，我就要更加努力才能进好地方啊，但是要不要选深圳呢，Q同学看你给不给这个机会咯～ 顺祝母校生快，每年的六一都是我们的Cumter的节日","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"树形的数据结构 -- Python","slug":"mytree","date":"2017-10-11T12:48:39.813Z","updated":"2017-07-19T02:10:48.000Z","comments":true,"path":"2017/10/11/mytree/","link":"","permalink":"http://yoursite.com/2017/10/11/mytree/","excerpt":"","text":"实现二叉树主要通过两种方式，一个是通过嵌套列表，一个是通过节点的引用，下面分开讲这两种方式。 通过嵌套列表实现二叉树在用嵌套列表实现树时,我们将用 Python 的列表数据结构来编写上面定义的功能。虽然把 界面 写成列表的一系列方法与我们已实现的其他抽象数据类型有些不同,但这样做的是有趣 的,因为它 为我们􏰁供一个简单、可以直接检查的递归数据结构。在列表实现树时,我们将存储根节点的值作 为列表的第一个元素。列表的第二个元素是一个表示其左子树的列表,第三个元素是表示其右子树 的另一个列表。 BinaryTree 功能只是构建包含一个根节点和两个表示子节点的空列表的列表。给左子树添加到树 的根,我们需要插入一个新的列表到根列表的第二个位置。我们必须注意,如果列表中已经有元素 在第二个位置,我们需要跟踪它,并将新节点插入树中作为其左子节点。 123456789101112myTree = [&apos;a&apos;, [&apos;b&apos;, [&apos;d&apos;,[],[]], [&apos;e&apos;,[],[]] ], [&apos;c&apos;, [&apos;f&apos;,[],[]], []] ]def insertLeft(root,newBranch): t = root.pop(1) if len(t) &gt; 1: root.insert(1,[newBranch,t,[]]) else: root.insert(1,[newBranch, [], []]) return root - 请注意,插入一个左子节点前,我们首先应获取对应于当前左子节点的列表(可能是空的)。 - 然后,我们添加新的左子节点,将原来的左子结点作为新节点的左子节点。 pop() 函数用于移除列表中的一个元素（默认最后一个元素），并且返回该元素的值。 完整的树的基本功能模块如下：123456789101112131415161718192021222324252627282930313233343536373839def BinaryTree(r): return [r,[],[]]def insertLeft(root,newBranch): t = root.pop(1) if len(t) &gt; 1: root.insert(1,[newBranch,t,[]]) else: root.insert(1,[newBranch,[],[]]) return rootdef insertRight(root,newBranch): t = root.pop(2) if len(t) &gt; 1: root.insert(2,[newBranch,[],t]) else: root.insert(2,[newBranch,[],[]]) return rootdef getRootVal(root): return root[0]def setRootVal(root,newVal): root[0] = newValdef getLeftChild(root): return root[1]def getRightChild(root): return root[2]r= BinaryTree(3)insertLeft(r,4)insertLeft(r,5)insertRight(r,6)insertRight(r,7)I = getLeftChild(r)print (I)setRootVal(I,9)print (r)insertLeft(I,11)print (r)print(getRightChild(getRightChild(r))) 通过节点和引用来实现二叉树代码如下123456789101112131415161718192021222324252627282930313233343536373839class BinaryTree: def __init__(self,rootObj): self.key = rootObj self.leftChild = None self.rightChild = None def InsertLeft(self,newNode): if self.leftChild == None: self.leftChild = BinaryTree(newNode) else: t = BinaryTree(newNode) t.leftChild = self.leftChild self.leftChild = t def InsertRight(self,newNode): if self.rightChild == None: self.rightChild = BinaryTree(newNode) else: t = BinaryTree(newNode) t.rightChild = self.rightChild self.rightChild = t def getRightChild(self): return self.rightChild def getLeftChild(self): return self.leftChild def setRootVal(self,obj): self.key = obj def getRootVal(self): return self.keyr = BinaryTree(&apos;a&apos;)print (r.getRootVal())print (r.getLeftChild())print (r.getRightChild())","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"科研进度","slug":"multi-path","date":"2017-10-11T12:48:39.808Z","updated":"2017-08-07T12:16:34.000Z","comments":true,"path":"2017/10/11/multi-path/","link":"","permalink":"http://yoursite.com/2017/10/11/multi-path/","excerpt":"","text":"2017年7月27日Github-Computerscience.这周的进度时关于选路和选流的survey总结。 2017年8月7日考虑到XEN的两段式特征，和老板讨论过后觉得这个可能是一个可以改进的点，因为Xen－4.6的版本改进修复了之前说的速率不匹配的问题，所以xen的行为现在就分为pre-copy和stop-and-copy两个大过程，而前面一段是throughoutput sensitive 而停机拷贝时latency sensitive的，所以我们分开进行流调度。 同时选流和选路并不是矛盾的，基本的Hedrea方案是有效的，所以在如何辨识Xen的流量似乎是可行的。先在真机里面进行操作。长短流的辨识我再调研一下。Mahout: Low-Overhead Datacenter Traffic Management using End-Host-Based Elephant Detection.2011 INFOCOM","categories":[],"tags":[{"name":"Personal","slug":"Personal","permalink":"http://yoursite.com/tags/Personal/"}]},{"title":"MySQL多表连接查询","slug":"multilst","date":"2017-10-11T12:48:39.803Z","updated":"2017-08-04T08:12:16.000Z","comments":true,"path":"2017/10/11/multilst/","link":"","permalink":"http://yoursite.com/2017/10/11/multilst/","excerpt":"","text":"很多业务中需要多表联合在一起查询才能有结果，而多表联合查询的本质是：表连接。本文主要列举两张和三张表来讲述多表连接查询。新建两张表： 12345表1:student 表2:courseID Name ID Cname1 张三 1 足球2 李四 2 音乐3 王二 4 美术 外连接外连接可分为：左连接、右连接、完全外连接。1.左连接 left join 或 left outer joinSQL语句：select * from student left join course on student.ID=course.ID执行结果：1234ID Name ID Cname1 张三 1 足球2 李四 2 音乐3 王二 NULL NULL 左外连接包含left join左表所有行，如果左表中某行在右表没有匹配，则结果中对应行右表的部分全部为空(NULL). 注：此时我们不能说结果的行数等于左表数据的行数。当然此处查询结果的行数等于左表数据的行数，因为左右两表此时为一对一关系。 2.右连接 right join 或 right outer joinSQL语句：select * from student right join course on student.ID=course.ID执行结果：1234ID Name ID Cname1 张三 1 足球2 李四 2 音乐NULL NULL 4 美术 右外连接包含right join右表所有行，如果左表中某行在右表没有匹配，则结果中对应左表的部分全部为空(NULL)。 注：同样此时我们不能说结果的行数等于右表的行数。当然此处查询结果的行数等于左表数据的行数，因为左右两表此时为一对一关系。 3.完全外连接 full join 或 full outer joinSQL语句：select * from student full join course on student.ID=course.ID执行结果：12345ID Name ID Cname1 张三 1 足球2 李四 2 音乐3 王二 NULL NULLNULL NULL 4 美术 完全外连接包含full join左右两表中所有的行，如果右表中某行在左表中没有匹配，则结果中对应行右表的部分全部为空(NULL)，如果左表中某行在右表中没有匹配，则结果中对应行左表的部分全部为空(NULL)。 内连接 join 或 inner joinSQL语句：select * from student inner join course on student.ID=course.ID执行结果：123ID Name ID Cname1 张三 1 足球2 李四 2 音乐 inner join 是比较运算符，只返回符合条件的行。此时相当于：select * from student,course where student.ID=course.ID 交叉连接cross join1.概念：没有 WHERE 子句的交叉联接将产生连接所涉及的表的笛卡尔积。第一个表的行数乘以第二个表的行数等于笛卡尔积结果集的大小。SQL语句：select * from student cross join course执行结果：12345678910ID Name ID Cname1 张三 1 足球2 李四 1 足球3 王二 1 足球1 张三 2 音乐2 李四 2 音乐3 王二 2 音乐1 张三 4 美术2 李四 4 美术3 王二 4 美术 如果我们在此时给这条SQL加上WHERE子句的时候比如SQL:select * from student cross join course where student.ID=course.ID 此时将返回符合条件的结果集，结果和inner join所示执行结果一样。 两表关系为一对多，多对一或多对多时的连接语句当然上面两表为一对一关系，那么如果表A和表B为一对多、多对一或多对多的时候，我们又该如何写连接SQL语句呢？其实两表一对多的SQL语句和一对一的SQL语句的写法都差不多，只是查询的结果不一样，当然两表也要略有改动。比如表1的列可以改为：Sno Name Cno表2的列可以改为：Cno CName这样两表就可以写一对多和多对一的SQL语句了，写法和上面的一对一SQL语句一样。下面介绍一下当两表为多对多的时候我们该如何建表以及些SQL语句。新建三表：一个学生可以选择多门课程，一门课程可以被多个学生选择，因此学生表student和课程表course之间是多对多的关系。当两表为多对多关系的时候，我们需要建立一个中间表student_course，中间表至少要有两表的主键，当然还可以有别的内容。SQL语句：select s.Name,C.Cname from student_course as sc left join student as s on s.Sno=sc.Sno left join course as c on c.Cno=sc.Cno执行结果：此条SQL执行的结果是学生选课的情况。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"Leetcode-628--Python","slug":"leetcode 628","date":"2017-10-11T12:48:39.797Z","updated":"2017-08-03T06:57:16.000Z","comments":true,"path":"2017/10/11/leetcode 628/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 628/","excerpt":"","text":"628. Maximum Product of Three Numbers题目大意：从数组里找三个值，然后找出最大值。 这道题会出现问题就是因为可能会出现负值，所以排完序不能直接取最大的三个。 如果所有的list都大于0，那么直接排序取最大。如果有小于0的话，则取下列算法： product1 = max1 max2 max3 product2 = max1 min1 min2 然后返回两个中的最大值就好：123456nums.sort()number1 = nums[-1] * nums[-2] * nums[-3]number2 = nums[0] * nums[1] * nums[-1]# product1 = max1 * max2 * max3# product2 = max1 * min1 * min2return max(number1,number2) Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-617/561--Python","slug":"leetcode 617","date":"2017-10-11T12:48:39.795Z","updated":"2017-06-22T15:17:28.000Z","comments":true,"path":"2017/10/11/leetcode 617/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 617/","excerpt":"","text":"617.Merge Two Binary Trees给出两个二叉树想要合并，有一些结点会重叠而有一些不会，现在想把重叠的结点值变为两者值相加，不重叠的直接用，构建出新的树。Note:合并都从两个二叉树根部开始 思路考察的就是二叉树的遍历，遍历每个结点然后如果重叠（两个二叉树结点都不为空）新结点值便为两者和，不重叠（只有一个结点为空）新结点值为不为空的值，全为空到达底部返跳出。按照这个逻辑进行迭代 联想：二叉树遍历方式有深度优先和广度优先，深度（纵向）优先在Python中一般使用列表，广度优先（横向）一般使用迭代。 //注意深度优先和广度优先的区别 1234567891011121314151617181920212223242526272829303132# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def mergeTrees(self, t1, t2): #:type t1: TreeNode #:type t2: TreeNode #:rtype: TreeNode #t1和t2是代表两颗树，先对根节点进行运算 #两个都节点都是空 #if t1 is None and t2 is None: (把这行注释去了) return None #只有一个节点为空 #if t1 is None: (把这行注释去了) return t2 #if t2 is None: (把这行注释去了) return t1 #结点重叠时 t1.val += t2.val #进行迭代 t1.right = self.mergeTrees(t1.right, t2.right) t1.left = self.mergeTrees(t1.left,t2.left) return t1注：这个题主要是用了广度优先遍历，所以使用了迭代，一颗树做完之后，可以迭代左子树和右子树。 561. Array Partition I对数组排序，两两一组，取每组的第一个数求和Note：实际上题目不是说要对数组排序而是要求最小值的最大和，看不太懂什么意思，看他的示例似乎是要先排序，我查了了下其他博客主的文章都是先排序，然后去小的值，而且judge后发现accepted所以应该是要先排序。用了两种方法。法一：先排序，然后每隔2个值就输出一下加到sum里，代码12345678910111213class Solution(object): def arrayPairSum(self, nums): #\"\"\" :type nums: List[int] :rtype: int #\"\"\" nums.sort() i = 0 sum = 0 while i &lt; len(nums): sum += nums[i] i += 2 return sum 法二：这个方法比较取巧就是，看出规律输出偶数个位就行，因为是从0开始计算的，所以2就是第三个，输出的就相当于第二组数的第一个。12345678class Solution(object): def arrayPairSum(self, nums): #\"\"\" :type nums: List[int] :rtype: int #\"\"\" nums.sort() return sum(nums[::2]) 法二就两行比较取巧，但是你要对python内置函数要熟一些。今天先刷两道题。考虑到ryu就是拿python写的，所以项目可能要偏python一些，所以leetcode拿py刷，c++刷了30道还是太难了。 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-599--Python","slug":"leetcode 599","date":"2017-10-11T12:48:39.789Z","updated":"2017-07-07T01:55:12.000Z","comments":true,"path":"2017/10/11/leetcode 599/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 599/","excerpt":"","text":"599. minimum index sum of two lists这道题题目就是找出两个list的交集，return type：list[int]这道题看起来不是很难，就是这个测试的时候除了问题，这个能想到的方法还挺多，常见的简单的法一就是取差集，还有一个就是循环找，时间复杂度都比较高，昨天看数据结构的时候有个O(n)的解法，但是写起来比较长，我就贴两个算法就好。法一：使用set求差集123456class Solution(object): def intersection(self, nums1, nums2): num1 = set(nums1) num2 = set(nums2) num = num1 &amp; num2 return list[num] 法二：使用循环迭代，但是这里有一个问题，是在测试的时候发现的，就是当nums1 = []和nums2 = []的时候，使用循环迭代，返回的事null而不是[]，也不知为啥。因为我开始初始化的时候就是result=[],而且我return的就是result.所以不知道为啥，我就又写了个分支都为[]返回[]，发现还是返回none。GG12345678910class Solution(object): def intersection(self, nums1, nums2): result = [] for num1 in nums1: for num2 in nums2: if num1 == num2 and (1,2非空)： result.append(num1) return result elif num1,num2为[]: //实在懒得写了，代码在github里面 return num1 这种边界条件还是有意思，反正遇到这种情况转成list()就行。 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-566--Python","slug":"leetcode 566","date":"2017-10-11T12:48:39.786Z","updated":"2017-06-25T09:43:44.000Z","comments":true,"path":"2017/10/11/leetcode 566/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 566/","excerpt":"","text":"566. Reshape the Matrix给定二维矩阵nums，将其转化为r行c列的新矩阵。若无法完成转化，返回原矩阵。Note: 给定矩阵的高度和宽度范围[1, 100] r和c都是正数这道题我能想到的就是把输入前的矩阵填到输入后的矩阵，所以方法一就是直接去解，我看了下网上还有别的解法，一个是使用一个公式直接转换，还有一个就是使用numpy模块里面的reshape函数，实际上我觉得，第三种方法才是最常用的吧。法一：12345678910111213141516171819202122class Solution(object): def matrixReshape(self, nums, r, c): \"\"\" :type nums: List[List[int]] :type r: int :type c: int :rtype \"\"\" #if len(nums)*len(nums[0]) != r*c: # return nums # result = [[0 for row in range(r)]for col in range(c)] temp_row = 0 temp_col = 0s # for i in nums: # for j in i: result[temp_row][temp_col] = j temp_col += 1 # if temp_col == c: temp_row +=1 temp_col =0 return resultPS:因为排版的问题，所以我在前面加了\"＃\"号，所以代码不要直接拷贝这个bash里面的代码，去我的github上粘贴复制会比较好，因为python对缩进的要求太严格了，所以粘贴的时候出问题，代码跑不了，我不接锅. 法二：这个方法主要就是怎么找到转换后的公式的算法比较难，我没想到，但是验证了发现确实是对的，对于计算机取余”%”和取除”/“有了新的看法。先说一下取余我们知道10％3 ＝ 1，那么3%10 ＝？123456&gt;&gt;&gt; print 3%10&gt;&gt;&gt; 3&gt;&gt;&gt; print 0%10&gt;&gt;&gt; 0&gt;&gt;&gt; print 10%10&gt;&gt;&gt; 0 我第一次看这个算法没看明白是因为，不知道当分子％分母，（分子 &lt; 分母）得出的结果是分子本身。所以我在第一行的时候有疑惑。先看下代码123456789class Solution(object): def matrixReshape(self, nums, r, c): # if len(nums)*len(nums[0]) != r*c: return nums #result = [[0 for row in range(r)] for col in range(c)] # for i in range(r*c): result [i/c][i%c] = nums[i/len(nums[0])][i%len(nums[0])] //上面这句大家可能看不懂，实际上他就是现在的矩阵怎么通过原来的矩阵转换得来的算法. return result 我来讲下这一句：1result [i/c][i%c] = nums[i/len(nums[0])][i%len(nums[0])] 先看下普通矩阵［1，2］［3，4］这是一个2x2矩阵，我们要变成 ［1，2，3，4］这样的1*4矩阵那第一个矩阵的元素分别是：[(0,0) (0,1)][(1,0) (1,1)] 转化后的矩阵是 [(0,0),(0,1),(0,2),(0,3)]再看看我们上面的取余，他传进来的参数比如第一行1/12 ＝ 0 (这是因为两个都是整型所以为0)，1%12＝1，所以这样就完成了矩阵的转换。由于是以list的方式传输的，所以用for range的方式。i =0时 ，result[0][0] = nums[0][0]i =1时 ，result[0][1] = nums[0][1]i =2时 ，result[0][2] = nums[1][0]i =3时 ，result[0][3] = nums[0][1]太巧妙了，服气。 法三：这个方法就是直接使用了numpy模块，直接使用里面的reshape函数123456import numpyclass Solution(object): def matrixReshape(self, nums, r, c): # if len(nums)*len(nums[0]) != r*c： return nums return numpy.reshape(nums,(r,c)).tolist() tolist函数用于把一个矩阵转化成为list列表. Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-557/500--Python","slug":"leetcode 557","date":"2017-10-11T12:48:39.784Z","updated":"2017-06-24T12:15:42.000Z","comments":true,"path":"2017/10/11/leetcode 557/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 557/","excerpt":"","text":"557. Reverse Words in a String III给定字符串，将每个单词逐字符逆置，返回新字符串。这个和普通的输出还是有一点差别的，比如我们要输出：“let’s watch tv Eva” 他不是直接输出倒序，而是在里面的单个元素倒叙，输出的是：“s’let hctaw vt avE”,所以当时脑子想过两种方式，要么先全部倒置，然后分割，然后最后一位和第一位换，用append添加进去，要么先分割，再倒置，再用append添加，后来我一写发现第一种方法和第二种是一样的方法，倒叙天假我也不会啊，所以就只写法一了。法一：123456def reverseWords(s): new = [] #for word in s.split(): s= word[::-1] new.append(s) print ' '.join(new) 实际上主要是split和join函数的使用： Splitsplit()通过指定分隔符对字符串进行切片，如果参数num 有指定值，则仅分隔 num 个子字符串.str.split(str=””, num=string.count(str)). str – 分隔符，默认为所有的空字符，包括空格、换行(\\n)、制表符(\\t)等。 num – 分割次数。1.按某一个字符分割，如‘.’1234567str = ('www.google.com')print strstr_split = str.split('.')print str_split结果：［'www','google','com'］ 2.按某一个字符分割，且分割n次。如按‘.’分割1次1234567891011121314151617str = ('www.google.com')print strstr_split = str.split('.'，1)print str_split结果：['www','google.com']按字符串分割也是同理，也可以把分割后的字符赋给多个变量。str1, str2 = url.split('.', 1)print str1print str2结果：&gt;&gt;&gt; print str1&gt;&gt;&gt; www&gt;&gt;&gt; print str2&gt;&gt;&gt; google.com JoinPython join() 方法用于将序列中的元素以指定的字符连接生成一个新的字符串str.join(sequence) sequence – 要连接的元素序列。1234567str = \"-\";seq = (\"a\", \"b\", \"c\"); # 字符串序列print str.join( seq );结果：\"a-b-c\"实际上我们通常用的时候都是直接return ' '.join(seq). 这一题没什么好说的。 500. Keyboard Row给出n个字符串，从而判断每个字符串中的字符是否来自美式键盘上的同一行，若来自同一行，返回该string。逐个word去比较即可。实际上这题最简单就是看把输入逐个比较看在不在这一行，在的话就输出这个word不在就跳过，主要是用到了set这个函数，用来取交集，另一种方法就是把键盘行第一行的字母用1表示，第二行用2表示，第三行用三表示，再逐个输入自己的input，从第一个开始后面的比较，只要出现和第一个字符不一样的数字，那就说明不在同一行，直接break，进行下一个word的判断。下面将这两个方法。方法一：这个方法先讲两个函数set()和map set() python的set和其他语言类似, 是一个无序不重复元素集, 基本功能包括关系测试和消除重复元素.输出代码可能会更好理解一点 123&gt;&gt;&gt; t = set (\"Hello\")&gt;&gt;&gt; print t &gt;&gt;&gt; set (['H','e','l','o']) 集合对象还支持union(联合), intersection(交), difference(差)和sysmmetric difference(对称差集)等数学运算.只有你先经过set之后才可以使用集合对象功能 “&amp;”交集，”|”并集,”#”差集。举个栗子： 1234&gt;&gt;&gt; t = set (\"hello\")&gt;&gt;&gt; b = set (\"hihi\")&gt;&gt;&gt; print t &amp; b&gt;&gt;&gt; set (['h']) 这道题就用了这个特性，代码如下：12345678910111213def findWords(words): a = set (\"qwertyuiop\") b = set (\"asdfghjkl\") c = set (\"zxcvbnm\") ans = [] # for word in words: # 这里是为了输入大小写都可以识别，但是注意直接直接赋值和直接.lower()区别，等下再讲 # t = set (word.lower()) # if (a&amp;t == t) or (b&amp;t == t) or (c&amp;t == t): ans.append(word) return ansprint findwords(input) 这个题还有两个扩展一个就是map函数，一个就是.lower() map()map(function, sequence)：对sequence中的item依次执行function(item)，将执行结果组成一个List返回，测试如下：123456&gt;&gt;&gt; a = [1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; def fn(x):... return x*2&gt;&gt;&gt; c = map(fn, a)&gt;&gt;&gt; print c &gt;&gt;&gt; [2, 4, 6, 8, 10, 12, 14, 16, 18] .lower()很多题都是需要不区分大小写，或者在找交集的时候无论输出大小写我们都使用小写或者大写匹配。而python的变量是允许存入两个变量的。还是看测试代码123456789101112def findwords(): # for word in words: $1. word.lower() &gt;&gt;&gt; print word &gt;&gt;&gt; XuanLONG $2. word = word.lower() &gt;&gt;&gt; print word &gt;&gt;&gt; xuanlongfindwords(\"XuanLONG\")$2 里面相当于直接把所有字符变成小写，进行赋值，所以这个时候word里的值已经变了。$1 里面word却还是XuanLONG。但是这个可以区分大小写 方法二：这个就是先把某一行里面所有字母用数字代替(字典)，直接比较数字看是否在一行，直接看代码吧。findWords(words):12345678910111213141516171819 pattern = &#123;&#125; for i in &quot;qwertyuiop&quot;: List [i] = 1 for i in &quot;asdfghjkl&quot;: List [i] = 2 for i in &quot;zxcvbnm&quot;: List [i] = 3 ans = [] for word in words: category = pattern[word.lower(0)]//每个输入的字符串第一个字母置为category is_word = True for w in word://对每个字母迭代 if pattern[w] != category: // w就相当于key值 is_word = False break if is_word: ans.append(word)print findwords(input) 注意的是pattern是一个字典，复习一下字典 dict()dict = {key1 : value1, key2 : value2 } 键必须是唯一的，但值则不必。 值可以取任何数据类型，但键必须是不可变的，如字符串，数字或元组。通过key来访问value的值，如下:1234dict1 = &#123;\"xuanlong\":24,\"qiu\":23&#125;&gt;&gt;&gt; print dict1[\"qiu\"]&gt;&gt;&gt; 23del dict['key1']; # 删除键是'key1'的条目 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-521/520--Python","slug":"leetcode 521520","date":"2017-10-11T12:48:39.781Z","updated":"2017-06-30T11:29:38.000Z","comments":true,"path":"2017/10/11/leetcode 521520/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 521520/","excerpt":"","text":"今天的OJ我就是按照题目的意思写的，四点半写到五点半就写了两道，我都惊了，要不是第二题我想用ASCII码解估计半小时就做完了，做完我就发现不对了，这就是暴力膜啊，暴力膜不可取，我去看了OJ的答案发现基本上都是用的py的内置函数，很少有用到算法的，时间复杂度都比较靠近，我想着不然自己想想新的方法，这种老方法看看就行。 基本上现在只要能看懂题目基本上都可以暴力膜出来。 521. Longest Uncommon Subsequence I题目大意就是，比较两个字符串的长度，若不相等，则返回长度的较大值，若相等则再判断两个字符串是否相同，若相同则返回-1，否则返回长度。这个我都不知道怎么想算法，需要算法吗？直接贴了1234567891011121314def findles(a,b):''' if len(a)!=len(b): if len(a) &gt; len(b): return len(a) else: return len(b) if len(a)==len(b): if a == b: return -1 else: return len(a)'''print (\"abc\",\"aba\") 520. Detect Capital这个题目意思比较简单，如果全是大写，就return True，如果全是小写，就return True,如果第一个字母是大写，其他字母小写也可以return Ture,不然就return False.法一：实际上这道题我知道他有内建的函数isupper()和islower()之类的，但是我想着这么做就没意思了，然后就用ascii码自己写了个。可能有人不知道这两个函数，我就写一下吧。 islower()str.islower()如果字符串中包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是小写，则返回 True，否则返回 False isupper()str.isupper()如果字符串中包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是大写，则返回 True，否则返回 False 用这个方法的代码比较没什么创意啦，我还是ac了～但是我第二个也ac了～12345678910class Solution(object): def detectCapital(self,word): ''' if word.islower() or word.isupper(): return True if word[0].isupper and word[1:].islower(): return True else: return False ''' 法二：这个是我自己想的，但是也比较傻，就是用ascii码，比较好的是py里面有自带的转换函数。ord()：就是把字符转换成ascii码，比如ord(a)=97.有一点计算机知识的人都了解‘a’ = 97 ‘z’ = 122 ‘A’ ＝ 65 ‘Z’=90 这个解法就是判别你输入的字符里到底有多少个大写，我增加一个计数的变量，用这个变量来判别是否满足题目要求。代码如下：1234567891011class Solution(object): def detectCapital(self,word):''' cnt =0 if i in range(0,len(word)): if ord(word[i]) &gt;= 65 and ord(word[i] &lt;= 90): cnt += 1 return (cnt==0) or (cnt == len(word)) or (cnt ==1 and ord(word[0])&gt;=65 and ord(word[0])&lt;=90)''' #这三个条件就是没有大写字母，全是大写字母，只有第一个是大写字母 法三：这个方法，我实在是饿的不行了，就没细想了，但是是用ascii码暴力膜。就是一次判定题目的条件，但是发现只要一进if循环就直接return了，估摸着逻辑或者缩紧不对，也懒得改了。po一下简单代码1234567891011121314class Solution(object): def detectCapitalUse(self, word): if ord(word[0]) &lt;=90 and ord(word[0]) &gt;=65: #第一个字母为大写 for i in word[1:]: if ord(i) &lt;= 122 and ord(i) &gt;=97: return True if ord(i) &lt;= 90 and ord(i) &gt;= 65: return True if ord(word[0]) &gt;= 97 and ord(word[0]) &lt;= 122: for i in word[1:]: if ord(i) &lt;= 122 and ord(i) &gt;=97: return True else: return False 但是用ascii码去判别大小肯定是没有问题的，因为方法二已经被AC了。 最近越来越喜欢暴力膜解法了，不行啊，看来得把数据结构拾起来了。吃饭的时候看到彩虹了，难得，风云际会，水木清华…喝茶喝茶 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-506--Python","slug":"leetcode 506","date":"2017-10-11T12:48:39.774Z","updated":"2017-07-28T10:02:02.000Z","comments":true,"path":"2017/10/11/leetcode 506/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 506/","excerpt":"","text":"题目大意：前三名运动员获得前三名，用“金牌”，“银牌”和“铜牌”置换。对于其余运动员，输出相对排名。 这道题我也懒得想了，复制了一个数组，然后排序，这样就知道了名次index(),然后把前三名用金牌，银牌，铜牌置换了，其余的不变，(AC的时候说要字符串，数字再转一下字符串)。 直接贴代码：1234567891011121314151617181920212223242526272829303132333435class Solution(object): def findRelativeRanks(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[str] &quot;&quot;&quot; list1 = sorted(nums) list1.reverse() result = [] for i in nums: result.append(list1.index(i)+1) new_res = [] for j in result: if j == 1: j = &quot;Gold Medal&quot; elif j == 2: j = &quot;Silver Medal&quot; elif j == 3: j = &quot;Bronze Medal&quot; else: j = str(j) new_res.append(j) return new_res print new_res # list1[0] = &quot;Gold Medal&quot; # list1[1] = &quot;Silver Medal&quot; # list1[2] = &quot;Bronze Medal&quot;P = Solution()nums = [5,4,3,2,1]P.findRelativeRanks(nums) 也可以考虑拿字典做，我就不写了。 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-476--Python","slug":"leetcode 476","date":"2017-10-11T12:48:39.768Z","updated":"2017-06-23T14:24:00.000Z","comments":true,"path":"2017/10/11/leetcode 476/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 476/","excerpt":"","text":"476. Number Complement给定一个正整数，输出其补数.题目意思就是将10进制转换成2进制，取反，再换为10进制。实际上不能直接用“~”按位取反符号来做，主要原因是他的前缀也会被取反，比如我们是32bit的那么5的二进制是“0000 0000 0000 0000 0000 0000 00000 0101”取反就变成“1111 1111 1111 1111 1111 1111 1111 1010”那就多了29个1，这么做还得把前面的1去掉，所以就衍生出两种做法。 Note： 给定正数确保是32位带符号整数。 可以假设整数的二进制表示不包含前导0。 法一：这个方法比较笨，我把他按照list的格式输入进去，我一个一个的去读里面的数，那因为是取反，所以我读一个“0”我自己新建一个列表存个1进去，读个“1”我存个“0”进去，遍历完整个列表那我们也得到取反的二进制数，再使用int(arg,x)来转换进制就好。代码如下：1234567891011121314class Solution(object): def findComplement(num): bn = bin(num[2:]) #把bin里面的0b去掉 rlist = list(bn) //这个地方用的是list（） orilist = [] #for number in rlist: # if number == \"1\": orilist.append[\"0\"] else: orilist.append[\"1\"] r = ''.join(orilist) return int(r,2)P = Solution()print P.findComplement(5) 把元组换成list这个用的()不是［］list( seq )seq – This is a tuple to be converted into list. append是[]的属性。 注意区分()和[] 法二：第二个方法比较巧妙，就是用异或“^”的特性。异或可以看成是将两个值交换。如果两个相应位相同，则结果为0，否则为1。即：0^0=0， 1^0=1， 0^1=1， 1^1=0－ 0异或任何数＝任何数－ 1异或任何数－任何数取反－ 任何数异或自己＝把自己置0 考虑到这个特性 5 是 “101” ，2 是“010”，1异或任意数等于取反，所以我们要异或111这就是101 ^ 111 = 010这样就代表取反，那我们如何得到111.这就是这个算法的精髓，111是1000 －1 ，就是说所有位都为1时，那么加1，必然会进位，就变成多一位的最小值，我们要做的就是把多一位的最小值－1就能得到少一位的最大值。代码如下：1234567891011def findComplement(num): value =1 # if num == 1: return 0 else: while value &lt;= num: value &lt;&lt; = 1 //这里就是一直循环，直到我的value的位数大于num，不够的话就一直左移 new_value = value - 1 //这里时，已经比num多一位，所以－1就是num位数的1. return new_value ^ numprint findComplement(5) 关于value &lt;&lt;= 1其实“&lt;&lt;= ”的操作是等同于 value = value &lt;&lt; 1和 “＋＝”，“－＝”一样通常我们在对单个量才会只用“&lt;&lt;”来看值是否左移。 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-463--Python","slug":"leetcode 463","date":"2017-10-11T12:48:39.762Z","updated":"2017-07-23T14:25:00.000Z","comments":true,"path":"2017/10/11/leetcode 463/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 463/","excerpt":"","text":"463. Island Perimeter题目的意思是求岛的周长，给出一个list，如果a[i][j]== 1则表明他是陆地，然后计算陆地加起来的周长。 这题我也是用的暴力膜法：主要是下面的边界条件相了很久看了别人的才想出来的。 如果格子超出边界，则周长+1； 如果格子是水，则周长+1这样最终得到的周长就是结果了。下面直接po代码了，照旧可以在github上找到我的代码，ac过了。12345678910111213141516171819202122class Solution(object): def islandPerimeter(self, grid): parameters = 0 m = len(grid[0]) n = len(grid)''' for i in range(0,len(grid)): for j in range(0,len(grid[0]))://这两个语句是用来遍历整个列表，下面是把判断条件加进去。 if grid[i][j] == 1://首先要是一个海岛 if i == 0 or grid[i-1][j] == 0: 第一行，上面是水 parameters +=1 if i == n-1 or grid[i+1][j] ==0: 最后一行，下面是水 paremeters +=1 if j == 0 or grid[i][j-1] == 0:第一列，左边是水 parameters +=1 if j = m-1 or grid[i][j+1] == 0:最后一列，右边是水 parameters +=1 return parameters'''P = Solution()test = [[1,0,0,1],[1,1,0,0],[0,0,1,0]]print P.islandPerimeter(test) 基本上就是一个暴力解法，也懒得想了。 今天实在没什么尽头了，上午开了paper meeting和sdn meeting下午还有mooc meeting 累的要死，但是基本上把vm migration部分找人接下来了，现在就专心刷刷题，学学sdn，做做毕业设计，如果hpcc中了，加上之前的一篇会议，一篇期刊，和十月在议程上的ICC基本上还是可以申请到一个还不错的博士的，不过既然不准备读了，就反而没有那么大压力了，回头文章让敬轩投了，我挂个2作就行，那我也就不用写文章了，调研的事情反而就不急了，这样子我就在科研上划划水，可以好好学技术啦。 忽然倦了，唉，炸酱面～～ Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-448--Python","slug":"leetcode 448","date":"2017-10-11T12:48:39.755Z","updated":"2017-07-25T03:29:14.000Z","comments":true,"path":"2017/10/11/leetcode 448/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 448/","excerpt":"","text":"448. Find All Numbers Disappeared in an Array给定一个长度为n的数组，数组元素是1~n。但是有些元素出现一次，有些元素出现两次，从而也会导致有些元素不出现。现在让我们找到哪些元素没有出现。 这个我觉得没那么难啊，就两种方法一种直接用差集，一种暴力解，但是看了下top soluation看不太懂，觉得自己是个zz。暴力解超时不可取。 法一：123456789def findDisappearedNumbers(nums): result = [] list1 =[] for i in range(1,len(nums)+1): result.append(i) #print result if i not in nums and i in result: list1.append(i) return list1 这个解法没啥说的啊，做一个1-n的数列，在这个数列但是不在nums这个数列就把他添加到result. 法二：用差集：这个是我ac的答案：123def findDisappearedNumbers(nums): news = xrange(1,len(nums)+1) return list(set(news)-set(nums)) 前面的博客又讲差，并，交，知道这个函数就没什么说的了。 法三：(top soluation)不懂，丢出来看看将元素对应的位置取负：简单一句话可能不好理解，我们举个例子。假设在位置k放了元素i，则在取负的过程中i的取值有两种可能：为正，表示当前尚未遇到元素k将该位置取负；为负，表示当前已经有元素k出现，并将元素取负。但是我们不关心k，我们关心元素i。元素i既然出现，我们就看一下位置i：为正，表示这是元素i第一次出现，我们将位置i取负；为负，表示元素i已经出现过一次，我们不做任何操作。不管一个元素出现一次还是两次，只要出现它对应的位置就会被取负。当某个元素不出现的时候，该元素对应的位置始终访问不到，所以还是正值，通过这种方法我们就可以找到哪些元素没有出现。通过上面的分析我们也很容易知道，在取负的过程中，如果发现要取负的位置已经为负，说明这个元素已经出现过，也即该元素出现了两次，我们可以将该元素保留下来。 实现代码写起来很简单逻辑自己看：12345for i in xrange(len(nums)): index = abs(nums[i]) - 1 nums[index] = - abs(nums[index]) return [i + 1 for i in range(len(nums)) if nums[i] &gt; 0] Python 4 lines with short explanation牛逼！ Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-283/492--Python","slug":"leetcode 283492","date":"2017-10-11T12:48:39.752Z","updated":"2017-07-04T04:06:20.000Z","comments":true,"path":"2017/10/11/leetcode 283492/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 283492/","excerpt":"","text":"刷easy越刷越慌，早上看了下BAT的面经，感觉题目都很难，有些东西都不太会，leetcode上的easy题我也觉得效果不一定有想象中的好，而且自从会用暴力解题法以后，基本上很少动脑子，或者就是直接下笔写，感觉很不好，还是要多复习复习基础的数据结构和算法知识。leetcode做快一点，之前以为刷easy就够了，现在感觉至少要刷到medium。 283. Move Zeroes给定一个数字数组，写一个方法将所有的“0”移动到数组尾部，同时保持其余非零元素的相对位置不变。 例如，给定nums = [0, 1, 0, 3, 12]，在调用你的函数之后，nums应该变为[1, 3, 12, 0, 0]。 备注：你必须就地完成，不得复制该数组。最小化总共的操作数。 这道题看他们好像有挺多算法的，我就懒的想了，遇到0，就删掉，同时后面加个0，然后直接return了，比较急着做实验，所以直接ac了123456789class Solution(object): def moveZeroes(self, nums): ''' for num in nums: if num == 0: nums.remove(num) nums.append(0) return nums ''' 492. Construct the Rectangle这道题的做法，千篇一律有什么平方根，确实时间上用的比我短，我用的是暴力法，就是从1-area开始算出所有的W和L，虽然可能会出现(1，4)和(4,1)这种情况～但是demo里没出现，也不知为啥123456class Solution(object): def moveZeroes(self, nums): for W in range(1,area): if area%W == 0 ＃其实是为了保证为int型，不然range里面是浮点数，这也是他们用开方根的原因。 L＝ area / W return L,W 逻辑是这个逻辑，但是具体代码我就扔到github了，太困了 我要回去睡觉了。 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-268--Python","slug":"leetcode 268","date":"2017-10-11T12:48:39.745Z","updated":"2017-08-06T11:50:00.000Z","comments":true,"path":"2017/10/11/leetcode 268/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 268/","excerpt":"","text":"268. Missing Number题目大意就是找出漏掉的那个数，这道题其实很简单，陷入了思维定势，就是简单的数理统计，而且看他的返回类型：:rtype: int所以就是简单计算出少了那个数就好。那就是n*(n+1) - sum(nums) 方法一：12345678class Solution(object): def missingNumber(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; n = len(nums) return n*(n+1)/2 - sum(nums) 方法二：这个做法超时了，想法也是比较简单，就是用后一个数减掉前一个数，如果不等于1，如果这个数就漏了，就输出他的值。12345678910111213class Solution(object): def missingNumber(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; nums.sort() for i in range(len(nums)+1): if len(nums) == 1: return 1 if nums[i+1] - nums[i] != 1: #print nums[i+1]-1 return nums[i+1]-1 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-168/171--Python","slug":"leetcode 217","date":"2017-10-11T12:48:39.740Z","updated":"2017-08-01T12:35:00.000Z","comments":true,"path":"2017/10/11/leetcode 217/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 217/","excerpt":"","text":"217. Contains Duplicate给定一个整数数组，判断其中是否包含重复元素。你要写的函数，当包含重复元素时返回 true，否则返回 false。 方法一：对列表排序，比较i和i+1大小：1234567891011121314class Solution(object): def containsDuplicate(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: bool &quot;&quot;&quot; nums.sort() if nums == [] or len(nums)==1: return False for i in range(0,len(nums)-1): # print i if nums[i] == nums[i+1]: return True return False 最后自己加一些边界条件 方法二：是leetcode的top solution,就是用差集比较大小。1return len(nums) != len(set(nums)) 方法三：就是用一个数组从头和尾开始比较，遇到相等就返回True，否则返回False。1234567891011121314left = 0right = len(nums) - 1if nums == [] and len(nums) - 1 == 0: return Falsewhile left &lt; right and nums != []: if nums[left] == nums[right]: print True return True elif nums[left] &gt; nums[right]: left += 1 else: right -= 1 return False Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-278/189--Python","slug":"leetcode 189278","date":"2017-10-11T12:48:39.735Z","updated":"2017-08-11T13:30:58.000Z","comments":true,"path":"2017/10/11/leetcode 189278/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 189278/","excerpt":"","text":"278. First Bad Version题目大意就是找一个坏的版本，假设你有n个版本号 [1, 2, …, n]， 其中从某个版本号开始往后的所有版本都是错误版本，你想找到第一个错误的版本号。简单而言就是找一个特殊的数：实际上就是暴力法，一个一个比较，存在就输出，但是这样是AC不了的。法一：或者它是第一个版本号，或者它是错误版本号且它前一个版本号是正确版本号。123456789101112131415class Solution(object): def firstBadVersion(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; left, right = 1, n while True: mid = (left + right) / 2 if isBadVersion(mid): if mid == 1 or not isBadVersion(mid - 1): return mid right = mid - 1 else: left = mid + 1 法二：其实可以不对错误的版本号进行特殊的判断操作，而是在缩小搜索范围时仍将当前错误版本号包含在新的区间内，那么最终区间只有一个元素时即为所求。1234567891011121314class Solution(object): def firstBadVersion(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; left, right = 1, n while left &lt; right: mid = (left + right) / 2 if isBadVersion(mid): right = mid else: left = mid + 1 return left 189. Rotate Array题目大意，就是给一个列表list = [1，2，3，4，5]再给你个数比如2，你把列表下标2之前的数贴到列表后面变成［4，5，1，2，3］法一：12345678if k &gt; 0 and n &gt; 1: ans = nums1[k:] for i in nums1[0:k]: ans.append(i)# ans.append(new) print anselse: return [1] //判定的时候边界条件显示的 法二：直接把前面的截了后面的截了，拼成一个1234def rotate(self, nums, k): n = len(nums) if k &gt; 0 and n &gt; 1: nums[:] = nums[n - k:] + nums[:n - k] Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-168/171--Python","slug":"leetcode 168171","date":"2017-10-11T12:48:39.733Z","updated":"2017-07-31T14:30:10.000Z","comments":true,"path":"2017/10/11/leetcode 168171/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 168171/","excerpt":"","text":"171.Excel Sheet Column Number给定一个Excel表格中的列标题，求其对应的列数字。比如：A -&gt; 1B -&gt; 2C -&gt; 3…Z -&gt; 26AA -&gt; 27AB -&gt; 28 从A-Z对应1-26，当列标题进一位变成AA时，列对应的数字变成27，这本质上是一个26进制转10进制的问题，不过A对应的是1而不是0，要注意。12345678910class Solution(object): def titleToNumber(self, s): &quot;&quot;&quot; :type s: str :rtype: int &quot;&quot;&quot; sum = 0 for i in s: sum = sum*26 + ord(i)-64 return sum 168.Excel Sheet Column Title给定一个正整数，返回其在Excel表格中作为列序号时对应的列标题。比如：1 -&gt; A2 -&gt; B3 -&gt; C…26 -&gt; Z27 -&gt; AA28 -&gt; AB 从A-Z对应1-26，当列标题进一位变成AA时，列对应的数字变成27。所以这个题本质上是一个10进制转26进制的问题，不过A对应的是1而不是0，要注意。 12345678910class Solution(object): def convertToTitle(self, n): &quot;&quot;&quot; :type n: int :rtype: str &quot;&quot;&quot; result = &apos; &apos; while n : result = chr((n-1)%26+65)+ result n = (n-1)/26 主要思想都是递归，和机制转换，主要是二进制不同。 顺手贴一下二进制转换：1234def convert(num): if num//2: convert(num//2) print (num%2) Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-167/387--Python","slug":"leetcode 167387","date":"2017-10-11T12:48:39.730Z","updated":"2017-07-31T14:26:58.000Z","comments":true,"path":"2017/10/11/leetcode 167387/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 167387/","excerpt":"","text":"167. Two Sum II - Input array is sorted题目大意就是给你一个target，然后找到是由那两个数组合的，输出序列号。注意题目说了两个重要条件：1，有序数组；2，有唯一解。所以解的两个数一定都是数组中唯一存在的数。1234567891011121314151617181920212223class Solution(object): def twoSum(self, numbers, target): &quot;&quot;&quot; :type numbers: List[int] :type target: int :rtype: List[int] &quot;&quot;&quot; # for i in numbers: # val = target - i # if val in numbers: # print numbers.index(i)+1,numbers.index(val)+1 left = 0 right = len(numbers) - 1 while left &lt; right: if numbers[left] +numbers[right] == target: print [left+1,right+1] return [left+1,right+1] elif numbers[left] + numbers[right] &gt; target: right -= 1 else: left += 1 主要是有序的，且唯一，所以遍历就不太方便。 387. First Unique Character in a String给定一个字符串，找出其中第一个不重复出现的字符，返回其位置索引。如果不存在，则返回-1。注意：假定字符串中只包含小写字母。方法一：先将所有字符出现的次数统计出来，再重新遍历原字符串中的字符，直到发现一个字符只出现一次，返回其下标。下面的代码用字典统计。12345678910111213141516class Solution(object): def firstUniqChar(self, s): &quot;&quot;&quot; :type s: str :rtype: int &quot;&quot;&quot; letters = &#123;&#125; for c in s: if c in letters: letters[c] = letters[c] + 1 else: letters[c] = 1 for i in xrange(len(s)): if letters[s[i]] == 1: return i return -1 方法二：就是暴力法，就是一样找出次数唯一的，用find()找出序号，然后输出最小的值，就是第一次出现的，但是这个方法超时了。没有A掉。1234567letters = &apos;abcdefghijklmnopqrstuvwxyz&apos; res = [] for c in letters: if s.count(c) == 1: d = s.find(c) res.append(d) return min(res) Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-136--Python","slug":"leetcode 136","date":"2017-10-11T12:48:39.727Z","updated":"2017-06-29T14:53:42.000Z","comments":true,"path":"2017/10/11/leetcode 136/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 136/","excerpt":"","text":"136. Single Number这道题好蠢，我做了半天发现自己做的是对的，脑子一抽筋，又改了，好蠢。幸好这两个都做出来了，第三种方法就是暴力膜，今天晚上暴力膜的有点多，头有点晕，结果超时了。但是我还是会说下暴力膜法。 题目的意思是给你一个list，里面所有的数字都出现了两遍，只有一个数字出现了一遍，让你找出这个只出现了一次的数。 法一：这个方法是比较常见的异或的方法，就是要了解一下异或的特性。 一个和自己异或的结果是0，a^a = 0 一个整数和0异或得到的值是自己， a^0=a 异或满足交换律，a^b = b^a 所以这个办法就是说因为是两两成双，那么所有的数遍历异或完得到的就是那个剩下的数，因为0^x = x直接贴代码：123456789101112class Solution(object): def singleNumber(self, nums): ''' result = nums[0] for i in nums[1:]: result ^= i return result '''P = Solutionnums = [2,2,1,1,3,4,4,5,5]print P.singleNumber(nums) 法二：这就是我头晕的地方，我傻了，实际上为什么要用nums[i]的元素呢，虽然这很保险，实际上因为0和任何数异或都是那个数，上面的方法中差点写成nums[0:]所以，我觉得大家可以更加简单的实现它，就用0去异或，然后遍历整个list效果是一样的。代码如下：123456class Solution(object): def singleNumber(self, nums): result = 0 for i in nums: result ^= 0 return result 法三：这个方法蠢是蠢点，但是可以暴力膜这个方法就是你先进行排序，然后用1-2 3-4 如果出现不等于0，那么必然就是少的那个数，但是这个runtime N/A了，写出来意义不是很大，主要是要看一下python的自带排序的功能的使用。举个栗子：1234567891011121314151617181920212223a = [5,2,1,9,6]&gt;&gt;&gt; sorted(a) #将a从大到小排序，不影响a的结构[1,2,5,6,9]&gt;&gt;&gt; b = sorted(a)&gt;&gt;&gt; b[1,2,5,6,9]&gt;&gt;&gt; a&gt;&gt;&gt; [5,2,1,9,6]##########################这个还是要区分一下的&gt;&gt;&gt; sorted(a,reverse = True) #将a从大到小排序,不影响a本身结构 [9, 6, 5, 2, 1] &gt;&gt;&gt; a.sort() #将a从小到大排序,影响a本身结构 [1, 2, 5, 6, 9]&gt;&gt;&gt; a.sort(reverse = True) #将a从大到小排序,影响a本身结构 [9, 6, 5, 2, 1] &gt;&gt;&gt; c = a.sort()&gt;&gt;&gt; 这个时候c不输出值，是错误的赋值方式注意，a.sort() 已改变其结构，b = a.sort() 是错误的写法! 还有一个就是分清 sorted()和sort()差别。 还有一个就是不要用set差集去做，因为差集相同的元素都会被t出去，所以你的重复元素去交集的时候其实是().对set的理解还是不够啊我。暴力解法就是先排序在用前一个减后一个＝0则是相同的，那么i＋2，3和4相减，不一样的话就输出这个值，说明它落单。12345678910111213class Solution(object):''' def singleNumber(self, nums): nums.sort() for i in range(0,len(nums)): if num[i]-nums[i+1]==0: i+=2 else: return nums[i+2]'''P = Solutionnums = [2,2,1,1,3,4,4,5,5]print P.singleNumber(nums) 暴力膜不可取，纯做参考。 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-136--Python","slug":"leetcode 104","date":"2017-10-11T12:48:39.720Z","updated":"2017-07-19T14:14:50.000Z","comments":true,"path":"2017/10/11/leetcode 104/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 104/","excerpt":"","text":"题目大意：求一颗二叉树的最大深度，最大深度指跟节点到最底层叶子节点的距离。 这种打卡题没什么说的，只是想把今天的更新刷到绿的而已～ 用递归的方法，当前节点的最大深度就是左节点的最大深度和右节点的最大深度之中取大的加一。 123456789101112131415class Solution(object): def maxDepth(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: int &quot;&quot;&quot; if root == None: return 0 leftdep = self.maxDepth(root.left) rightdep = self.maxDepth(root.right) if leftdep &gt;= rightdep: return leftdep + 1 else: return rightdep + 1 看了几道二叉树的题目，感觉BFS和DFS应用很广，学会了能很好的理解树的遍历！但是写代码不带大括号好不爽啊。 Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-9/258--Python","slug":"leetcode 9258","date":"2017-10-11T12:48:39.714Z","updated":"2017-07-05T14:23:46.000Z","comments":true,"path":"2017/10/11/leetcode 9258/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 9258/","excerpt":"","text":"接上篇的回文词，这里面有一道是整型的回文词，主要是这两道题都用到“/”和“％”的技巧。 258. Add Digits将每个数字的每个位相加，直到剩个位数为止。这道题举个简单的例子就是123 ＝ 1 ＋ 2 ＋ 3 ＝ 6实际上我们做的时候就是，大于10的数对10求余就是他的个位。所以我们123%10 ＝ 3就是个位主要是怎么获得百位，我们用除法，123/10 ＝ 12 (我们都取整型)做法就是取出个位数： // 取出每个位数的值 // ex. n = 138, 138%10 = 8, sum = 8, n = 13 // n = 13, 13%10 = 3, sum =11, n = 1法一：123456def addDigits(num): while (num &gt;= 10): num = num/10 + num%10 #138/10 = 13 138%10 = 8 #其实就是逐位加 return num 法二：这个相当于第一种方法的分解1234567891011def addDigits(num): temp = 0 while (num &gt;= 10): temp += num % 10 num = num/10 #上面相当于做了一轮 138 8 13 3 11 1 -&gt;return 11，11之后还有轮次，所以要赋值给temp # print 的值是11 num = temp return num 9.palindrome number这道题就是给你一个回文的整型，让你判断是不是回文词，本来想用队列做的，但是题目要求不允许你转换成列表，所以就通过四则运算来做。123456789101112def ispali(x):''' if x &lt; 0 : return False tmp = x y = 0 while tmp: y = y * 10 + tmp %10 #这里还是很巧妙的 tmp = tmp /10 return y == x''' 这就相当于倒序输出这个整型数据。 好方啊，时间不够了！！！ Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"Leetcode-7--Python","slug":"leetcode 7","date":"2017-10-11T12:48:39.705Z","updated":"2017-08-11T13:30:34.000Z","comments":true,"path":"2017/10/11/leetcode 7/","link":"","permalink":"http://yoursite.com/2017/10/11/leetcode 7/","excerpt":"","text":"7. Reverse Integer题目大意就是把一个整数反转，每一位都进行求解123456def reverse(x):ans = 0while (x != 0): ans = ans * 10 + (x % 10) x = x / 10return ans 主要是当超过边界条件时我们需要return 0123456789const int int_max=0x7fffffff;const int int_min=0x80000000;if(anwser&lt;int_min || anwser&gt;int_max) &#123; anwser=0; &#125; return anwser; Resource代码还是会扔到[Github-link].","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"HTTP的特性-Python","slug":"http","date":"2017-10-11T12:48:39.703Z","updated":"2017-07-25T01:52:08.000Z","comments":true,"path":"2017/10/11/http/","link":"","permalink":"http://yoursite.com/2017/10/11/http/","excerpt":"","text":"HTTP构建于TCP/IP协议之上，默认端口是80HTTP是无连接状态的 HTTP报文请求报文HTTP 协议是以 ASCII 码传输，建立在 TCP/IP 协议之上的应用层规范。规范把 HTTP 请求分为三个部分：状态行、请求头、消息主体。类似于下面这样：1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; HTTP定义了与服务器交互的不同方法，最基本的方法有4种，分别是GET，POST，PUT，DELETE。URL全称是资源描述符，我们可以这样认为：一个URL地址，它用于描述一个网络上的资源，而 HTTP 中的GET，POST，PUT，DELETE就对应着对这个资源的查，增，改，删4个操作。1.GET用于信息获取，而且应该是安全的 和 幂等的。所谓安全的意味着该操作用于获取信息而非修改信息。换句话说，GET 请求一般不应产生副作用。就是说，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态。幂等的意味着对同一URL的多个请求应该返回同样的结果。GET请求报文示例：12345GET /books/?sex=man&amp;name=Professional HTTP/1.1Host: www.example.comUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.7.6)Gecko/20050225 Firefox/1.0.1Connection: Keep-Alive 2.POST表示可能修改变服务器上的资源的请求。123456789POST / HTTP/1.1 Host: www.example.com User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.7.6) Gecko/20050225 Firefox/1.0.1 Content-Type: application/x-www-form-urlencoded Content-Length: 40 Connection: Keep-Alive sex=man&amp;name=Professional 3.注意 GET 可提交的数据量受到URL长度的限制，HTTP 协议规范没有对 URL 长度进行限制。这个限制是特定的浏览器及服务器对它的限制 理论上讲，POST 是没有大小限制的，HTTP 协议规范也没有进行大小限制，出于安全考虑，服务器软件在实现时会做一定限制 参考上面的报文示例，可以发现 GET 和 POST 数据内容是一模一样的，只是位置不同，一个在URL里，一个在 HTTP 包的包体里 响应报文HTTP 响应与 HTTP 请求相似，HTTP响应也由3个部分构成，分别是： 状态行 响应头(Response Header) 响应正文状态行由协议版本、数字形式的状态代码、及相应的状态描述，各元素之间以空格分隔。常见的状态码有如下几种： 200 OK 客户端请求成功 301 Moved Permanently 请求永久重定向 302 Moved Temporarily 请求临时重定向 304 Not Modified 文件未修改，可以直接使用缓存的文件。 400 Bad Request 由于客户端请求有语法错误，不能被服务器所理解。 401 Unauthorized 请求未经授权。这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden 服务器收到请求，但是拒绝提供服务。服务器通常会在响应正文中给出不提供服务的原因 404 Not Found 请求的资源不存在，例如，输入了错误的URL 500 Internal Server Error 服务器发生不可预期的错误，导致无法完成客户端的请求。 503 Service Unavailable 服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常。 条件GETHTTP 条件 GET 是 HTTP 协议为了减少不必要的带宽浪费，提出的一种方案。1.HTTP 条件 GET 使用的时机？客户端之前已经访问过某网站，并打算再次访问该网站。2.HTTP 条件 GET 使用的方法？客户端向服务器发送一个包询问是否在上一次访问网站的时间后是否更改了页面，如果服务器没有更新，显然不需要把整个网页传给客户端，客户端只要使用本地缓存即可，如果服务器对照客户端给出的时间已经更新了客户端请求的网页，则发送这个更新了的网页给用户。 持久连接我们知道 HTTP 协议采用“请求-应答”模式，当使用普通模式，即非 Keep-Alive 模式时，每个请求/应答客户和服务器都要新建一个连接，完成之后立即断开连接（HTTP协议为无连接的协议）；当使用 Keep-Alive 模式（又称持久连接、连接重用）时，Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接。 在 HTTP 1.0 版本中，并没有官方的标准来规定 Keep-Alive 如何工作，因此实际上它是被附加到 HTTP 1.0协议上，如果客户端浏览器支持 Keep-Alive ，那么就在HTTP请求头中添加一个字段 Connection: Keep-Alive，当服务器收到附带有 Connection: Keep-Alive 的请求时，它也会在响应头中添加一个同样的字段来使用 Keep-Alive 。这样一来，客户端和服务器之间的HTTP连接就会被保持，不会断开（超过 Keep-Alive 规定的时间，意外断电等情况除外），当客户端发送另外一个请求时，就使用这条已经建立的连接。 在 HTTP 1.1 版本中，默认情况下所有连接都被保持，如果加入 “Connection: close” 才关闭。目前大部分浏览器都使用 HTTP 1.1 协议，也就是说默认都会发起 Keep-Alive 的连接请求了，所以是否能完成一个完整的 Keep-Alive 连接就看服务器设置情况。 由于 HTTP 1.0 没有官方的 Keep-Alive 规范，并且也已经基本被淘汰，以下讨论均是针对 HTTP 1.1 标准中的 Keep-Alive 展开的。tips:1.HTTP Keep-Alive 简单说就是保持当前的TCP连接，避免了重新建立连接。 2.HTTP 长连接不可能一直保持，例如 Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100，表示这个长连接最多接收100次请求就断开。 3.HTTP是一个无状态协议，这意味着每个请求都是独立的，Keep-Alive没能改变这个结果。另外，Keep-Alive也不能保证客户端和服务器之间的连接一定是活跃的，在HTTP1.1版本中也如此。唯一能保证的就是当连接被关闭时你能得到一个通知，所以不应该让程序依赖于Keep-Alive的保持连接特性，否则会有意想不到的后果。 4.使用长连接之后，客户端、服务端怎么知道本次传输结束呢？两部分：1. 判断传输数据是否达到了Content-Length 指示的大小；2. 动态生成的文件没有 Content-Length ，它是分块传输（chunked），这时候就要根据 chunked 编码来判断，chunked 编码的数据在最后有一个空 chunked 块，表明本次传输数据结束。 HTTP Pipelining (HTTP管线化)默认情况下 HTTP 协议中每个传输层连接只能承载一个 HTTP 请求和响应，浏览器会在收到上一个请求的响应之后，再发送下一个请求。在使用持久连接的情况下，某个连接上消息的传递类似于请求1 -&gt; 响应1 -&gt; 请求2 -&gt; 响应2 -&gt; 请求3 -&gt; 响应3。 HTTP Pipelining（管线化）是将多个 HTTP 请求整批提交的技术，在传送过程中不需等待服务端的回应。使用 HTTP Pipelining 技术之后，某个连接上的消息变成了类似这样请求1 -&gt; 请求2 -&gt; 请求3 -&gt; 响应1 -&gt; 响应2 -&gt; 响应3。 注意下面几点： 管线化机制通过持久连接（persistent connection）完成，仅 HTTP/1.1 支持此技术（HTTP/1.0不支持） 只有 GET 和 HEAD 请求可以进行管线化，而 POST 则有所限制 初次创建连接时不应启动管线机制，因为对方（服务器）不一定支持 HTTP/1.1 版本的协议 管线化不会影响响应到来的顺序，如上面的例子所示，响应返回的顺序并未改变 HTTP /1.1 要求服务器端支持管线化，但并不要求服务器端也对响应进行管线化处理，只是要求对于管线化的请求不失败即可 由于上面提到的服务器端问题，开启管线化很可能并不会带来大幅度的性能提升，而且很多服务器端和代理程序对管线化的支持并不好，因此现代浏览器如 Chrome 和 Firefox 默认并未开启管线化支持. 会话跟踪1.什么是会话？客户端打开与服务器的连接发出请求到服务器响应客户端请求的全过程称之为会话。2.什么是会话跟踪？会话跟踪指的是对同一个用户对服务器的连续的请求和接受响应的监视。3.为什么需要会话跟踪？浏览器与服务器之间的通信是通过HTTP协议进行通信的，而HTTP协议是”无状态”的协议，它不能保存客户的信息，即一次响应完成之后连接就断开了，下一次的请求需要重新连接，这样就需要判断是否是同一个用户，所以才有会话跟踪技术来实现这种要求。4.会话跟踪常用的方法:4.1 URL重写：URL(统一资源定位符)是Web上特定页面的地址，URL重写的技术就是在URL结尾添加一个附加数据以标识该会话,把会话ID通过URL的信息传递过去，以便在服务器端进行识别不同的用户。 4.2 隐藏表单域将会话ID添加到HTML表单元素中提交到服务器，此表单元素并不在客户端显示 4.3 CookieCookie是Web服务器发送给客户端的一小段信息，客户端请求时可以读取该信息发送到服务器端，进而进行用户的识别。对于客户端的每次请求，服务器都会将Cookie发送到客户端,在客户端可以进行保存,以便下次使用。客户端可以采用两种方式来保存这个Cookie对象，一种方式是保存在客户端内存中，称为临时Cookie，浏览器关闭后这个Cookie对象将消失。另外一种方式是保存在客户机的磁盘上，称为永久Cookie。以后客户端只要访问该网站，就会将这个Cookie再次发送到服务器上，前提是这个Cookie在有效期内，这样就实现了对客户的跟踪。Cookie是可以被禁止的 4.4 Session每一个用户都有一个不同的session，各个用户之间是不能共享的，是每个用户所独享的，在session中可以存放信息。 在服务器端会创建一个session对象，产生一个sessionID来标识这个session对象，然后将这个sessionID放入到Cookie中发送到客户端，下一次访问时，sessionID会发送到服务器，在服务器端进行识别不同的用户。 Session的实现依赖于Cookie，如果Cookie被禁用，那么session也将失效。(Session要有额外的返回机制) Cookie和Session差别当你在浏览网站的时候，WEB 服务器会先送一小小资料放在你的计算机上，Cookie 会帮你在网站上所打的文字或是一些选择，都纪录下来。当下次你再光临同一个网站，WEB 服务器会先看看有没有它上次留下的 Cookie 资料，有的话，就会依据Cookie里的内容来判断使用者，送出特定的网页内容给你。 Cookie 的使用很普遍，许多有提供个人化服务的网站，都是利用 Cookie来辨认使用者，以方便送出使用者量身定做的内容，像是 Web 接口的免费 email 网站，都要用到 Cookie。 同时我们也看到，由于采用服务器端保持状态的方案在客户端也需要保存一个标识，所以session机制可能需要借助于cookie机制来达到保存标识的目的，但实际上它还有其他选择。 cookie机制名字，值，过期时间，路径和域。路径与域一起构成cookie的作用范围。若不设置过期时间，则表示这个cookie的生命期为浏览器会话期间，关闭浏览器窗口，cookie就消失。这种生命期为浏览器会话期的cookie被称为会话cookie。会话cookie一般不存储在硬盘上而是保存在内存里，当然这种行为并不是规范规定的。若设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie仍然有效直到超过设定的过期时间。存储在硬盘上的cookie可以在不同的浏览器进程间共享，比如两个IE窗口。而对于保存在内存里的cookie，不同的浏览器有不同的处理方式。 session机制session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。当程序需要为某个客户端的请求创建一个session时，服务器首先检查这个客户端的请求里是否已包含了一个session标识（称为session id），如果已包含则说明以前已经为此客户端创建过session，服务器就按照session id把这个session检索出来使用（检索不到，会新建一个），如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保存。保存这个session id的方式可以采用cookie，这样在交互过程中浏览器可以自动的按照规则把这个标识发送给服务器。一般这个cookie的名字都是类似于SEEESIONID。但cookie可以被人为的禁止，则必须有其他机制以便在cookie被禁止时仍然能够把session id传递回服务器。 经常被使用的一种技术叫做URL重写，就是把session id直接附加在URL路径的后面。还有一种技术叫做表单隐藏字段。就是服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器。比如：1234&lt;form name=\"testform\" action=\"/xxx\"&gt; &lt;input type=\"hidden\" name=\"jsessionid\" value=\"ByOK3vjFD75aPnrF7C2HmdnV6QZcEbzWoWiBYEnLerjQ99zWpBng!-145788764\"&gt; &lt;input type=\"text\"&gt; &lt;/form&gt; 实际上这种技术可以简单的用对action应用URL重写来代替。cookie 和session 的区别：1、cookie数据存放在客户的浏览器上，session数据放在服务器上。2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗 考虑到安全应当使用session。3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能考虑到减轻服务器性能方面，应当使用COOKIE。4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。 tips: 将登陆信息等重要信息存放为SESSION 其他信息如果需要保留，可以放在COOKIE中","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"Hello Puli & Hello Xuanlong!","slug":"Hello-Puli","date":"2017-10-11T12:48:39.694Z","updated":"2017-07-27T14:47:44.000Z","comments":true,"path":"2017/10/11/Hello-Puli/","link":"","permalink":"http://yoursite.com/2017/10/11/Hello-Puli/","excerpt":"","text":"这是继我的域名消失后又想重新拾起来的契机，可能是因为想留下念想纪录下生活，也可能是因为我划水划的太久了想收手了，不管怎么样今天是2017/05/21，开始新的纪录和生活，this is my life ! 埔里的夜晚 《海龟先生》虽然歌名不是海龟先生但是我想叫你海龟先生～～ ｀｀｀｀｀｀｀ 我跟你描述一个灵魂 它拥有不谢的青春 每当夜色降临 就会轻轻歌唱 它唱着一个新鲜的故事 里面的人们相互微笑 是不是每个夜晚都要这样 为了爱 去用清醒交换 男孩别哭 美丽世界的孤儿 可 我的心 我的家 在哪里 在哪里呢我的朋友 静静的听 有个声音在说爱你 闭上眼 跟随她 跟随她 就像跟着希望 那些城市上空飘着一颗颗不安的心 她一定也曾在这儿跳过欢快的舞蹈 清风吹来让我感到一阵迷醉 那婆娑的身影 太阳般光洁 ｀｀｀｀｀｀","categories":[],"tags":[{"name":"Personal","slug":"Personal","permalink":"http://yoursite.com/tags/Personal/"}]},{"title":"栈内存和堆内存的一点小结","slug":"heap","date":"2017-10-11T12:48:39.688Z","updated":"2017-08-04T08:35:54.000Z","comments":true,"path":"2017/10/11/heap/","link":"","permalink":"http://yoursite.com/2017/10/11/heap/","excerpt":"","text":"栈内存和堆内存 形象化的理解：Object obj = new Object();以上这句话,会把obj这个引用放进栈内存,再说白一点,就是这个对象的名字obj放进栈内存,栈内存运行速度较快,用于查找索引(也就是名字) 而new Object()会在堆内存中开辟一块空间给这个对象,对象几乎所有的属性啊,方法啊,全都在里面了,也就是对象的实体都在堆内存中,堆内存速度慢但是成本低,空间较大,用以存放程序 具体分析 内存分配策略按照编译原理的观点,程序运行时的内存分配有三种策略,分别是静态的,栈式的,和堆式的。如下：1.静态存储分配是指在编译时就能确定每个数据目标在运行时刻的存储空间需求,因而在编译时就可以给他们分配固定的内存空间.这种分配策略要求程序代码中不允许有可变数据结构(比如可变数组)的存在,也不允许有嵌套或者递归的结构出现,因为它们都会导致编译程序无法计算准确的存储空间需求。2.栈式存储分配也可称为动态存储分配,是由一个类似于堆栈的运行栈来实现的.和静态存储分配相反,在栈式存储方案中,程序对数据区的需求在编译时是完全未知的,只有到运行的时候才能够知道,但是规定在运行中进入一个程序模块时,必须知道该程序模块所需的数据区大小才能够为其分配内存.和我们在数据结构所熟知的栈一样,栈式存储分配按照先进后出的原则进行分配。3.堆式存储(Heap)分配则专门负责在编译时或运行时模块入口处都无法确定存储要求的数据结构的内存分配,比如可变长度串和对象实例.堆由大片的可利用块或空闲块组成,堆中的内存可以按照任意顺序分配和释放。 举例分析当编译一个C++程序时，计算机的内存被分成了4个区域，一个包括程序的代码，一个包括所有的全局变量，一个是堆栈（Stack），还有一个是堆（Heap） 全局变量是静态存储的（但不是静态的，不能用static进行修饰）。用static声明局部变量“的目的是使局部变量在调用完函数后仍不释放空间，而全局变量完全能做到这点。（当然，能不用试最好不要去用全局变量，它会造成很多干扰） 栈的概念是从日常生活中货物在货栈种的存取过程抽象出来的，即最后存放入栈的货物（堆在靠出口处）先被提取出去，符合“先进后出，后进先出”的原则。这种结构犹如子弹夹。 堆是自由的内存区域，我们可以通过new和delete把对象放在这个区域。你可以在任何地方分配和释放自由存储区。 总结从堆和栈的功能和作用来通俗的比较,堆主要用来存放对象的，栈主要是用来执行程序的.而这种不同又主要是由于堆和栈的特点决定的: 在编程中，例如C/C++中，所有的方法调用都是通过栈来进行的,所有的局部变量,形式参数都是从栈中分配内存空间的。实际上也不是什么分配,只是从栈顶向上用就行,就好像工厂中的传送带(conveyor belt)一样,Stack Pointer会自动指引你到放东西的位置,你所要做的只是把东西放下来就行.退出函数的时候，修改栈指针就可以把栈中的内容销毁.这样的模式速度最快,当然要用来运行程序了.需要注意的是,在分配的时候,比如为一个即将要调用的程序模块分配数据区时,应事先知道这个数据区的大小,也就说是虽然分配是在程序运行时进行的,但是分配的大小多少是确定的,不变的,而这个”大小多少”是在编译时确定的,不是在运行时。 堆是应用程序在运行的时候请求操作系统分配给自己内存，由于从操作系统管理的内存分配,所以在分配和销毁时都要占用时间，因此用堆的效率非常低.但是堆的优点在于,编译器不必知道要从堆里分配多少存储空间，也不必知道存储的数据要在堆里停留多长的时间,因此,用堆保存数据时会得到更大的灵活性。事实上,面向对象的多态性,堆内存分配是必不可少的,因为多态变量所需的存储空间只有在运行时创建了对象之后才能确定.在C++中，要求创建一个对象时，只需用new命令编制相关的代码即可。执行这些代码时，会在堆里自动进行数据的保存.当然，为达到这种灵活性，必然会付出一定的代价:在堆里分配存储空间时会花掉更长的时间！这也正是导致我们刚才所说的效率低的原因。","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"二叉搜索树＋平衡树＋图算法（广度和深度）","slug":"graph","date":"2017-10-11T12:48:39.684Z","updated":"2017-07-18T15:26:24.000Z","comments":true,"path":"2017/10/11/graph/","link":"","permalink":"http://yoursite.com/2017/10/11/graph/","excerpt":"","text":"基本上python的数据结构，比较基础的就是这么多，大约入学前看过之后基本上都没怎么用到，虽然概念上感觉还挺清晰，但是自己徒手写就觉得不行，大约复习之后，还是把方向放到leetcode，上面的题可能会帮助的理解快一点，基本数据结构的知识就更新这么多，不自己写感觉效率好低，还要穿插着看论文，蓝瘦！ 二叉搜索树左子树中键值key都小于父节点，右子树的键值key都大于父节点称为BST搜索树。因为我们必须能够创建和使用一个空二叉搜索树,所以我们的实现将使用两个类: 第一个类我们称为BinarySearchTree,第二个类我们称之为TreeNode。BinarySearchTree类有一个引用指向TreeNode即二叉搜索树的根。在大多数情况下,外部方法中要定义一个函数, 以便在类外看看子树是否是空的,如果在子树上有节点,要求有基本的方法,在BinarySearchTree类中,把根定义为一个参数。在树是空或者我们想删除根节点键值的情况下, 我们就必须采取特别行动。 12345678910111213class BinarySearchTree: def __init__(self): self.root = None self.size = 0 def length(self): return self.size def __len__(self): return self.size def __iter__(self): return self.root__iter__() 这些辅助函数,可以根据节点的位置辨别该节点属于何类子节点(左或右),以及该节点的子节点属于何类子节点(左或右)。TreeNode类也将明确地为每个节点追踪对父节点的引用。 1234567891011121314151617181920212223#TreeNodedef replaceNodeData(self,key,value,lc,rc): self.key = key self.payload = value self.leftChild = lc self.rightChild = rc if self.hasLeftChild(): self.leftChild.parent = self if self.hasRightChild(): self.rightChild.parent = selfdef isLeftChild(self): return self.parent and self.parent.leftChild == selfdef isRightChild(self): return self.parent and self.parent.rightChild == selfdef isRoot(self): return not self.parentdef isLeaf(self): return not (self.rightChild or self.leftChild)def hasAnyChildren(self): return self.rightChild or self.leftChilddef hasBothChildren(self): return self.rightChild and self.leftChild Alg:它将检查树是否已经有根节点。如果没有,put将创建一个新的，并把它作为树的根节点,作为子树的根。如果一个根节点已经到位,我们就调用它自 己,进行递归,用辅助功能_put按下列算法来搜索树: 从树的根开始搜索,比较新的键值,如果新的键值是小于当前节点,搜索左子树.如果新的键值是大于当前节点,搜索右子树。 当无左(或右)子树的搜索,我们发现的位置就是应该在子树中安装新节点的位置。 向树添加一个节点,在上一步发现插入对象的位置创建一个新的TreeNode。1234567891011121314def put(self,key,value): if self.root: self._put(key,val,self.root) else: self.root = TreeNode(key,val) self.size = self.size+1def _put(self,key,val,currentNode): if key &lt; currentNode.key: if currentNode.hasLeftChild(): self._put(key,val,currentNode.leftChild) else: currentNode.leftChild = TreeNode(key,val,parent = currentNode) else: 删除二叉搜索树如果树有一个以上的节点,我们使用_get方法搜索找到需要删除的TreeNode;如果树只有一个节点,这意味着我们要移除树的根,但是我们仍然必须检查以确保根的键是否匹配要删除的键。在以上两种情况下,如果未发现键值,del操作符就会报错。 一旦我们发现含有要删除的键的节点,有三种情况,我们必须考虑: 要删除的节点没有子树如果当前节点没有子树,所有我们需要做的是删除该节 点并把指向该节点的引用移动给其父节点 12345if currentNode.isLeaf(): if currentNode == currentNode.parent.leftChild: currentNode.parent.leftChild = None else: currentNode.parent.rightChild = None 如果一个节点只有一个子节点,那我们可以􏰀提升子树以代替其父树的位置由于有一个左或右子树的情况是对称的,我们将只讨论在当前节点有左子树的情况下,然后做对称对称。决策过程如下:1.如果当前节点是左子节点,那我们只需要更新当前节点的左子节点指向当前节点的父节点引用,然后将父节点对左子节点的引用更新到当前节点的左子节点。2.如果当前节点是一个右节点,那我们只需要更新当前节点的左子节点指向当前节点的父节点引用,然后将父节点对右子节点的引用更新到当前节点的左子节点。3.如果当前节点没有父树节点,它必须是根节点。在这种情况下,我们只需更换键,有效载荷,左子节点和右子节点,方法是调用根节点的replaceNodeData方法。 如果一个节点有两个子节点,我们不可能简单 地其中一个作为􏰀升至父节点的位置,这就需要寻找一个节点,用来代替一个计划删除的节点,我们需要的这个节点,需要保存现有的左、右子树以及二叉搜索树关系。符合该要求的节点有树中第二大的键。我们称这个节点为继任者,然后我们将一路寻找继任者,继任者保证没有一个以上的子节点,所以我们知道如何用已经知道的两种情况实现它。一旦继任者被移动,我们把它放在将被删除的子节点处。 平衡二叉树当树变得不平衡时 get 和 put 操作会 使二叉搜索树的性能降低到 O(n) 。在这一节中我们将看到一种特殊的二叉搜索树,它可以自动进 行调整,以确保树时时保持平衡。这种树被称为 AVL 树。AVL 树实现图(Map)的抽象数据类型,就像一个普通的二叉搜索树,唯一不同的是这棵树的 工作方式。为实现 AVL 树我们需要在树中的每个节点加入一个平衡因子(balance factor)以跟踪其变化情况。我们通过比较每个节点的左右子树的高度完成比较。更正式的定义是,一个节点的平衡因子定义为左子树的高度和右子树的高度之差。balanceFactor = height(leftSubTree)-height(rightSubTree)利用以上的平衡因子的定义,如果平衡因子小于零,我们称子树“左重” (left-heavy) 。 如果平衡因子小于零,那么子树是“右重” (right-heavy)。如果平衡因子是零,树是完美的平衡。为实现AVL 树的目的,并获得具有平衡的树,我们将定义如果平衡因子是-1,0或1,那么这个树是平衡的。一旦树中的节点的平衡因子超出了这个范围, 我们需要将树恢复平衡。 旋转二叉树 不会！回头再看 图和图算法图的实现有两个著名的方法,邻接矩阵 adjacency matrix 和邻接表 adjacency list。邻接矩阵,邻接矩阵的优点是简单,对于简单的图来说很容易看出节点之间的联系状态。然而,我们也注意到大部分的矩阵分量是空的,这种情况我们称矩阵是“稀疏”的。矩阵并不是一个储存稀疏数据的有效途径。邻接表,主列表中的每个顶点,再关联一个与自身有边连接的所有 顶点的列表。 邻接表的实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Vertex: def __init__ (self,key): self.id = key self.connectedTo = &#123;&#125; def addNeighbor(self,nbr,weight = 0): self.connectedTo[nbr] = weight def __str__(self): return str(self.id) + &apos;connectedTo:&apos; +str([x.id for x in self.connectedTo]) def getConnections(self): return self.connectedTo.keys() def getID(self): return self.id def getWeight(self,nbr): return self.connectedTo[nbr]class Graph: def __init__(self): self.vertList = &#123;&#125; self.numVertList = 0 def addVertex(self,key): self.numVertices = self.numVertices + 1 newVertex = Vertex(key) self.vertList[key] = newVertex def getVertex(self,n): if n in self.vertList: return self.vertList[n] else: return None def __contains__(self,n): return n in self.vertList def addEdge(self,f,t,cost = 0): if f not in self.vertList: nv = self.addVertex(f) if t not in self.vertList: nv = self.addVertex(t) self.vertList[f].addNeighbor(self.vertList[t],cost) def getVertices(self): return self.vertList.keys() def __iter__(self): return iter(self.vertList.values()) 词梯问题如何算出从开始单词到目标单词所需要的最小转换 次数。 以图的形式􏰁绘出单词之间的关系 利用被称作广度优先搜索(BFS)的图算法找到一条从开始单词到目标单词的最短路径。假设我们有非常多的桶,每个桶外都贴有一个四个字母的 单词标签,并且标签上有且仅有一个字母被‘ ’(通配符)所代替。我们就可能 会将一个桶贴上“ pop”, 当我们处理我们的列表中的每个词,都将其与每个桶比较,使用“”作为一个通配符,那么“pope” 和“ pops” 都与“ pop”匹配。每次我们找到一个匹配的桶,我们把单词放在桶里。一旦我们把所有单词都放在适当的桶里,我们便知道,同一个桶里的所有单词 都是相互连接的。 广度优先搜索（这个代码我明天自己写写看，北大的书上写的感觉好复杂）广度优先搜索算法(Breadth First Search)，又称为”宽度优先搜索”或”横向优先搜索”，简称BFS。 它的思想是：从图中某顶点v出发，在访问了v之后依次访问v的各个未曾访问过的邻接点，然后分别从这些邻接点出发依次访问它们的邻接点，并使得“先被访问的顶点的邻接点先于后被访问的顶点的邻接点被访问，直至图中所有已被访问的顶点的邻接点都被访问到。如果此时图中尚有顶点未被访问，则需要另选一个未曾被访问过的顶点作为新的起始点，重复上述过程，直至图中所有顶点都被访问到为止。 换句话说，广度优先搜索遍历图的过程是以v为起点，由近至远，依次访问和v有路径相通且路径长度为1,2…的顶点。 无向图的广度优先搜索第1步：访问A。第2步：依次访问C,D,F。 在访问了A之后，接下来访问A的邻接点。前面已经说过，在本文实现中，顶点ABCDEFG按照顺序存储的，C在”D和F”的前面，因此，先访问C。再访问完C之后，再依次访问D,F。第3步：依次访问B,G。 在第2步访问完C,D,F之后，再依次访问它们的邻接点。首先访问C的邻接点B，再访问F的邻接点G。第4步：访问E。 在第3步访问完B,G之后，再依次访问它们的邻接点。只有G有邻接点E，因此访问G的邻接点E。 因此访问顺序是：A -&gt; C -&gt; D -&gt; F -&gt; B -&gt; G -&gt; E 有向图的广度优先搜索第1步：访问A。第2步：访问B。第3步：依次访问C,E,F。 在访问了B之后，接下来访问B的出边的另一个顶点，即C,E,F。前面已经说过，在本文实现中，顶点ABCDEFG按照顺序存储的，因此会先访问C，再依次访问E,F。第4步：依次访问D,G。 在访问完C,E,F之后，再依次访问它们的出边的另一个顶点。还是按照C,E,F的顺序访问，C的已经全部访问过了，那么就只剩下E,F；先访问E的邻接点D，再访问F的邻接点G。 因此访问顺序是：A -&gt; B -&gt; C -&gt; E -&gt; F -&gt; D -&gt; G 深度优先搜索图的深度优先搜索(Depth First Search)，和树的先序遍历比较类似。 它的思想：假设初始状态是图中所有顶点均未被访问，则从某个顶点v出发，首先访问该顶点，然后依次从它的各个未被访问的邻接点出发深度优先搜索遍历图，直至图中所有和v有路径相通的顶点都被访问到。 若此时尚有其他顶点未被访问到，则另选一个未被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。 显然，深度优先搜索是一个递归的过程。 无向图的深度优先搜索第1步：访问A。第2步：访问(A的邻接点)C。 在第1步访问A之后，接下来应该访问的是A的邻接点，即”C,D,F”中的一个。但在本文的实现中，顶点ABCDEFG是按照顺序存储，C在”D和F”的前面，因此，先访问C。第3步：访问(C的邻接点)B。 在第2步访问C之后，接下来应该访问C的邻接点，即”B和D”中一个(A已经被访问过，就不算在内)。而由于B在D之前，先访问B。第4步：访问(C的邻接点)D。 在第3步访问了C的邻接点B之后，B没有未被访问的邻接点；因此，返回到访问C的另一个邻接点D。第5步：访问(A的邻接点)F。 前面已经访问了A，并且访问完了”A的邻接点B的所有邻接点(包括递归的邻接点在内)”；因此，此时返回到访问A的另一个邻接点F。第6步：访问(F的邻接点)G。第7步：访问(G的邻接点)E。 因此访问顺序是：A -&gt; C -&gt; B -&gt; D -&gt; F -&gt; G -&gt; E 有向图的深度优先搜索第1步：访问A。第2步：访问B。 在访问了A之后，接下来应该访问的是A的出边的另一个顶点，即顶点B。第3步：访问C。 在访问了B之后，接下来应该访问的是B的出边的另一个顶点，即顶点C,E,F。在本文实现的图中，顶点ABCDEFG按照顺序存储，因此先访问C。第4步：访问E。 接下来访问C的出边的另一个顶点，即顶点E。第5步：访问D。 接下来访问E的出边的另一个顶点，即顶点B,D。顶点B已经被访问过，因此访问顶点D。第6步：访问F。 接下应该回溯”访问A的出边的另一个顶点F”。第7步：访问G。 因此访问顺序是：A -&gt; B -&gt; C -&gt; E -&gt; D -&gt; F -&gt; G 代码明天一定会po！！！！","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"递归和汉尼塔问题 -- Python","slug":"digui","date":"2017-10-11T12:48:39.675Z","updated":"2017-07-09T07:55:00.000Z","comments":true,"path":"2017/10/11/digui/","link":"","permalink":"http://yoursite.com/2017/10/11/digui/","excerpt":"","text":"本来我对递归还是有理解的，但是看了一下反而晕了，实际上还是要有图才行。看一下汉尼塔问题 汉尼塔这是个比较常见的问题 我就直接说了，应该都懂。 我们如何用递归解决这个问题呢?我们又如何完全解决这一类问题?基本情况又是什么?让我 们从递归调用的最底端入手。假设你有一个五个圆盘组成的塔,最开始在一号杆上。如果你已经知 道如何将有四个圆盘的小塔从一号杆移到二号杆,就可以很容易地将第五个圆盘移动到三号杆,然后将 四个圆盘的塔从二号杆移动到三号杆。但是如果你不知道如何移动有四个圆盘的塔呢?这时又假设 你知道如何将有三个圆盘的塔移到三号杆;然后你就可以将第四个圆盘移动到二号杆,然后再将位 于三号杆的有三个圆盘的塔移到其上。但是如果你不知道如何移动有三个圆盘的小塔又怎么办呢? 那考虑先将有两个圆盘的小塔移动到二号杆,再将第三个圆盘移动到三号杆,最后将两个圆盘的小塔移 动到三号杆会如何呢?但如果你连这个也不会,该如何处理?显然你知道将单个圆盘移到三号杆十 分简单甚至可以说无需思考,似乎这就是这一问题最基础的部分。 下面是关于将塔经由中间杆,从起始杆移到目标杆的抽象概述:1、把圆盘数减一层数的小塔经过目标杆移动到中间杆2、把剩下的圆盘移动到目标杆3、把圆盘数减一层数的小塔从中间杆,经过起始杆移动到目标杆 只要我们一直遵循大的圆盘保持在底层的规则,我们就能用以上的三步来递归, 很容易地处理任 意多圆盘的问题。上述概要唯一缺少的是对基本情况的识别。最简单的河内塔问题是只有一个圆盘 时的情况,在这种情况下,我们只需要将单个圆盘移动到它的目标杆。所以只有一个圆盘的情况是 我们的基本情况。此外,上述步骤可以通过减少1、3步中小塔的高度使问题向基本情况靠近。 12345def moveTower(height,fromPole, toPole, withPole): if height &gt;= 1: moveTower(height-1,fromPole,withPole,toPole) moveDisk(fromPole,toPole) moveTower(height-1,withPole,toPole,fromPole) 第三行中,我们把起始杆上的除了最下面的圆盘全部移动到中间杆,下一行 将原来在最底层的最大圆盘移动到目标杆,之后在第五行,我们将位于中间杆的圆盘移动到最大圆 盘的上面。当小塔高度为0即为最简情况,在这种情况下无需继续,函数可以直接返回. 比较关键的一点是，moveTower的返回是moveDisk被调用的先决条件。就是说movetower执行完之后才执行moveDisk。 moveDisk函数非常简单,它所做的事情就是输出一个圆盘从一根杆移动到另一根杆的过程。 12def moveDisk(fp,tp): print(&quot;moving disk from&quot;,fp,&quot;to&quot;,tp) 完整的代码如下：12345678910def moveTower(height,fromPole, toPole, withPole): if height &gt;= 1: moveTower(height-1,fromPole,withPole,toPole) moveDisk(fromPole,toPole) moveTower(height-1,withPole,toPole,fromPole)def moveDisk(fp,tp): print(&quot;moving disk from&quot;,fp,&quot;to&quot;,tp) moveTower(3,&quot;A&quot;,&quot;B&quot;,&quot;C&quot;) 递归的要点如下： 所有递归算法必须剧本基本结束条件 递归算法必须要减小规模，改变状态，向基本结束条件演进 递归算法必须调用自身(递归地) 某些情况下，递归可以代替循环迭代 递归算法通常能够跟所要解决的问题的表述很自然的契合 递归不总是最适合的方法，有时候递归算法肯呢过会引发巨量的重复计算。(比如计算硬币最少数，使用动态规划)","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-10-11T06:05:39.942Z","updated":"2017-05-21T14:58:32.000Z","comments":true,"path":"2017/10/11/hello-world/","link":"","permalink":"http://yoursite.com/2017/10/11/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[{"name":"programming","slug":"programming","permalink":"http://yoursite.com/tags/programming/"}]}]}